{"cells":[{"cell_type":"markdown","metadata":{"id":"G3tb146HKUGS"},"source":["# [ì´ˆê¸‰ í”„ë¡œì íŠ¸] 4íŒ€_ê¹€ëª…í™˜"]},{"cell_type":"markdown","metadata":{"id":"hmaVeBaGKUGW"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"KzN8SzLMKgH1"},"source":["# í”„ë¡œê·¸ë˜ë°"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":44052,"status":"ok","timestamp":1758005640498,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ECzUDN-OzK99","outputId":"57c60d01-66f0-4d8c-ef8e-95be20c13c4e"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m117.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hë¡œë”©ì™„ë£Œ\n"]}],"source":["!pip install -q gdown\n","!pip install -q albumentations\n","!pip install -q ultralytics\n","!pip install -q -U ultralytics\n","!pip install -q nbformat\n","!pip install -q roboflow\n","!pip install -q opencv-python\n","!pip install -q opencv-python-headless\n","!pip install -q wandb\n","print(\"ë¡œë”©ì™„ë£Œ\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2799,"status":"ok","timestamp":1758005643303,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"OAK5c2b2zK9-","outputId":"f91ea15a-fec0-41d8-dff9-cecd472632ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["!wandb login 86a7b8c07184b2efdfb116546a17b1905e41cb5d"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12913,"status":"ok","timestamp":1758005656222,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"47-Qf8TYKUGW","outputId":"8616bf83-0cb5-4401-e71b-eea1198dd107"},"outputs":[{"output_type":"stream","name":"stdout","text":["ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:cuda\n"]}],"source":["# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n","import cv2\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Subset\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import Dataset\n","from collections import OrderedDict\n","from pycocotools.coco import COCO\n","from pycocotools import mask as coco_mask\n","\n","# --- ê¸°íƒ€ ---\n","import re\n","import os\n","import csv  # ì¶”ê°€ í•„ìš”\n","import sys\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import requests\n","import pandas as pd\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","from pathlib import Path\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU ì„¤ì •\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:{__device}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":250980,"status":"ok","timestamp":1758005907204,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"gDTmqQCCrBWm","outputId":"daac6944-d7bb-4547-f61c-3bc50cdcf9f7"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","install fonts-nanum...\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":4}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":439},"executionInfo":{"elapsed":27,"status":"error","timestamp":1758005907237,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"WE6336hF11C5","outputId":"223117f0-fdcb-4c79-c8ee-fe05d58cdb14"},"outputs":[{"output_type":"stream","name":"stdout","text":["utils_dir: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\n","sys.path: ['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmp3roqoc_9', '/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils']\n"]},{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'health_ea_utils'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-385067442.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"sys.path:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mhealth_ea_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mheu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhealth_ea_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'health_ea_utils'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os, sys\n","from pathlib import Path\n","\n","utils_dir = None\n","if helper.is_colab:\n","    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n","else:\n","    utils_dir = os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n","\n","print(\"utils_dir:\", utils_dir)\n","\n","sys.path.append(str(utils_dir))\n","print(\"sys.path:\", sys.path)\n","import importlib\n","import health_ea_utils as heu\n","importlib.reload(heu)\n","from health_ea_utils import *\n","\n","print(\"helper.__file__:\", helper.__file__)\n","print(\"health_ea_utils.__file__:\", heu.__file__)\n"]},{"cell_type":"markdown","metadata":{"id":"20rBdRxvKUGZ"},"source":["# 1. í•™ìŠµìš© ë°ì´íƒ€ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í’€ê¸°"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":310913,"status":"aborted","timestamp":1758005907214,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"A3JHrVMkzK9_"},"outputs":[],"source":["def get_tqdm_kwargs():\n","    \"\"\"Widget ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ tqdm ì„¤ì •\"\"\"\n","    return {\n","        'disable': False,\n","        'leave': True,\n","        'file': sys.stdout,\n","        'ascii': True,  # ASCII ë¬¸ìë§Œ ì‚¬ìš©\n","        'dynamic_ncols': False,\n","#        'ncols': 80  # ê³ ì • í­\n","    }\n","\n","def drive_root():\n","    root_path = os.path.join(\"D:\\\\\", \"GoogleDrive\")\n","    if helper.is_colab:\n","        root_path = os.path.join(\"/content/drive/MyDrive\")\n","    return root_path\n","\n","def get_path_modeling(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def get_path_modeling_release(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def print_dir_tree(root, max_depth=2, list_count=3, indent=\"\"):\n","    import os\n","    if max_depth < 0:\n","        return\n","    try:\n","        items = os.listdir(root)\n","    except Exception as e:\n","        print(indent + f\"[Error] {e}\")\n","        return\n","\n","    img_count = len([f for f in os.listdir(root) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","    for item in items:\n","        path = os.path.join(root, item)\n","        if os.path.isdir(path):\n","            print(indent + \"|-- \"+ item)\n","            # ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ë§Œ ì¶œë ¥\n","            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","            if img_count > list_count:\n","                print(indent + \"   \"+ f\"[ë°ì´í„°íŒŒì¼: {img_count}ê°œ]\")\n","            print_dir_tree(root=path, max_depth=max_depth-1, list_count=list_count, indent=indent + \"   \")\n","        else:\n","            if list_count < img_count and item.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt')):\n","                continue\n","            print(indent + \"|-- \"+ item)\n","\n","def save_model_dict(model, path, pth_name, kwargs=None):\n","    \"\"\"ëª¨ë¸ state_dictì™€ ì¶”ê°€ ì •ë³´ë¥¼ ì €ì¥\"\"\"\n","    def safe_makedirs(path):\n","        \"\"\"ì•ˆì „í•œ ë””ë ‰í† ë¦¬ ìƒì„±\"\"\"\n","        if os.path.exists(path) and not os.path.isdir(path):\n","            os.remove(path)  # íŒŒì¼ì´ë©´ ì‚­ì œ\n","        os.makedirs(path, exist_ok=True)\n","\n","    # ë””ë ‰í† ë¦¬ ìƒì„±\n","    safe_makedirs(path)\n","\n","    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n","    model_info = {\n","        'class_name': model.__class__.__name__,\n","        'init_args': {},\n","        'str': str(model),\n","        'repr': repr(model),\n","        'modules': [m.__class__.__name__ for m in model.modules()],\n","    }\n","\n","    # ìƒì„±ì ì¸ì ìë™ ì¶”ì¶œ(ê°€ëŠ¥í•œ ê²½ìš°)\n","    if hasattr(model, '__dict__'):\n","        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n","            if hasattr(model, key):\n","                model_info['init_args'][key] = getattr(model, key)\n","\n","    # kwargs ì²˜ë¦¬\n","    extra_info = {}\n","    if kwargs is not None:\n","        if isinstance(kwargs, str):\n","            extra_info = json.loads(kwargs)\n","        elif isinstance(kwargs, dict):\n","            extra_info = kwargs\n","\n","    model_info.update(extra_info)\n","\n","    # ì €ì¥í•  dict êµ¬ì„±\n","    save_dict = {\n","        'model_state': model.state_dict(),\n","        'class_name': model.__class__.__name__,\n","        'model_info': model_info,\n","    }\n","\n","    save_path = os.path.join(path, f\"{pth_name}.pth\")\n","    torch.save(save_dict, save_path)\n","    return save_path\n","\n","def load_model_dict(path, pth_name=None):\n","    \"\"\"\n","    save_model_dictë¡œ ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n","    ë°˜í™˜ê°’: (model_state, model_info)\n","    \"\"\"\n","    import torch\n","    load_path = path\n","    if pth_name is not None:\n","        load_path = os.path.join(path, f\"{pth_name}.pth\")\n","    checkpoint = torch.load(load_path, map_location='cpu', weights_only=False)  # <-- ì—¬ê¸° ì¶”ê°€\n","    model_state = checkpoint.get('model_state')\n","    model_info = checkpoint.get('model_info')\n","    model_info['file_name'] = os.path.basename(load_path)\n","    return model_state, model_info\n","\n","\n","def search_pth_files(base_path):\n","    \"\"\"\n","    ì…ë ¥ëœ ê²½ë¡œì˜ í•˜ìœ„ í´ë”ë“¤ì—ì„œ pth íŒŒì¼ë“¤ì„ ê²€ìƒ‰\n","    \"\"\"\n","    pth_files = []\n","\n","    if not os.path.exists(base_path):\n","        print(f\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_path}\")\n","        return pth_files\n","\n","    print(f\"pth íŒŒì¼ ê²€ìƒ‰ ì‹œì‘: {base_path}\")\n","\n","    # í•˜ìœ„ í´ë”ë“¤ì„ ìˆœíšŒí•˜ë©° pth íŒŒì¼ ê²€ìƒ‰\n","    for root, dirs, files in os.walk(base_path):\n","        for file in files:\n","            if file.endswith('.pth'):\n","                pth_path = os.path.join(root, file)\n","                pth_files.append(pth_path)\n","\n","    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥\n","    if pth_files:\n","        print(f\"\\në°œê²¬ëœ pth íŒŒì¼ë“¤ ({len(pth_files)}ê°œ):\")\n","        for i, pth_file in enumerate(pth_files, 1):\n","            # ìƒëŒ€ ê²½ë¡œë¡œ í‘œì‹œ (base_path ê¸°ì¤€)\n","            rel_path = os.path.relpath(pth_file, base_path)\n","            print(f\" {i:2d}. {rel_path}\")\n","    else:\n","        print(\"pth íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","\n","    return pth_files\n","\n","def print_json_tree(data, indent=\"\", max_depth=4, _depth=0, list_count=2, print_value=True):\n","    \"\"\"\n","    JSON ê°ì²´ë¥¼ ì§€ì •í•œ ë‹¨ê³„(max_depth)ê¹Œì§€ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\n","    - list íƒ€ì…ì€ 3ê°œ ì´ìƒì¼ ë•Œ ê°œìˆ˜ë§Œ ì¶œë ¥\n","    - í•˜ìœ„ ë…¸ë“œê°€ ê°’ì¼ ê²½ìš° key(type) í˜•íƒœë¡œ ì¶œë ¥\n","    - print_value=Trueì¼ ë•Œ key(type): ê°’ í˜•íƒœë¡œ ì¶œë ¥\n","    \"\"\"\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            if isinstance(value, (dict, list)):\n","                print(f\"{indent}|-- {key}\")\n","                print_json_tree(value, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","            else:\n","                if print_value:\n","                    print(f\"{indent}|-- {key}({type(value).__name__}): {value if len(str(value)) < 100 else f'{str(value)[:30]}...'}\")\n","                else:\n","                    print(f\"{indent}|-- {key}({type(value).__name__})\")\n","    elif isinstance(data, list):\n","        if len(data) > list_count:\n","            print(f\"{indent}|-- [list] ({len(data)} items)\")\n","        else:\n","            for i, item in enumerate(data):\n","                if isinstance(item, (dict, list)):\n","                    print(f\"{indent}|-- [{i}]\")\n","                    print_json_tree(item, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","                else:\n","                    if print_value:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__}): {item if len(str(item)) < 100 else f'{str(item)[:30]}...'}\")\n","                    else:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__})\")\n","    else:\n","        if print_value:\n","            print(f\"{indent}{type(data).__name__}: {data if len(str(data)) < 100 else f'{str(data)[:30]}...'}\")\n","        else:\n","            print(f\"{indent}{type(data).__name__}\")\n","\n","def print_git_tree(data, indent=\"\", max_depth=3, _depth=0):\n","    \"\"\"\n","    PyTorch tensor/ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ë¥¼ git tree ìŠ¤íƒ€ì¼ë¡œ ì¶œë ¥\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            print(f\"{indent}â”œâ”€ {key} [{type(value).__name__}]\")\n","            print_git_tree(value, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif isinstance(data, (list, tuple)):\n","        for i, item in enumerate(data):\n","            print(f\"{indent}â”œâ”€ [{i}] [{type(item).__name__}]\")\n","            print_git_tree(item, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif torch.is_tensor(data):\n","        shape = tuple(data.shape)\n","        dtype = str(data.dtype)\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ Tensor shape={shape} dtype={dtype} preview={preview_str}\")\n","    elif isinstance(data, np.ndarray):\n","        shape = data.shape\n","        dtype = data.dtype\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ ndarray shape={shape} dtype={dtype} preview={preview_str}\")\n","    else:\n","        val_str = str(data)\n","        print(f\"{indent}â””â”€ {type(data).__name__}: {val_str[:80]}{'...' if len(val_str)>80 else ''}\")\n","\n","\n","print(\"ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"]},{"cell_type":"markdown","metadata":{"id":"1B4qELHp5E9D"},"source":["# ë°ì´íƒ€ ë‹¤ìš´ë¡œë“œ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0o9rB50tzK-A","executionInfo":{"status":"aborted","timestamp":1758005907226,"user_tz":-540,"elapsed":310924,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# download_files={\n","#     'yolo_label_one_class' : r'https://drive.google.com/file/d/177_86k4BuT6JnFnq7ZHJtEjp7jaRbCl2/view?usp=sharing',\n","#     'yolo_label' : r'https://drive.google.com/file/d/1nc-WFcw7lCS7s7VGzN9Kxh80PiBBggez/view?usp=sharing',\n","#     'yolo_resize_one_class' : r'https://drive.google.com/file/d/1Ak0EvkMnuwvcAFvTO-zovIgVcNlROjsS/view?usp=sharing',\n","#     'yolo_resize' : r'https://drive.google.com/file/d/1kpo57qOJhEhrkuzUCEh57ILB5xSPVoFv/view?usp=sharing',\n","# }\n","\n","# download_files={\n","#     'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n","#     'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n","#     'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n","#     'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n","# }\n","\n","download_files={\n","    # 'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n","    # 'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n","    # 'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n","    # 'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n","    # 'yolo_noresize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107',\n","    'yolo_noresize_one_class':r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDgwMDcxODk0NHxGfDA&svcType=MYBOX-WEB&time=1757893856220',\n","}\n","# yolo_noresize = https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107\n","# yolo_noresize_one_class = https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDgwMDcxODk0NHxGfDA&svcType=MYBOX-WEB&time=1757893856220\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":310931,"status":"aborted","timestamp":1758005907234,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"pdLVsfpwzK-A"},"outputs":[],"source":["import gdown\n","def download_gdrive_file(url, output_path, ignore=True):\n","    # ê³µìœ  ë§í¬ì—ì„œ íŒŒì¼ ID ì¶”ì¶œ\n","    if os.path.exists(output_path):\n","        if ignore:\n","            os.remove(output_path)\n","        else:\n","            return\n","\n","    file_id_match = re.search(r'/d/([a-zA-Z0-9_-]+)', url)\n","    if not file_id_match:\n","        raise ValueError(\"Google Drive íŒŒì¼ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","    file_id = file_id_match.group(1)\n","    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n","\n","def download_http(url, target, ignore=True):\n","    \"\"\"\n","    HTTP íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ì§„í–‰ë¥  í‘œì‹œ)\n","    url: ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ URL\n","    target: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n","    ignore: Trueë©´ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ í›„ ë‹¤ìš´ë¡œë“œ, Falseë©´ íŒŒì¼ ìˆìœ¼ë©´ ê±´ë„ˆëœ€\n","    \"\"\"\n","    if os.path.exists(target):\n","        if ignore:\n","            os.remove(target)\n","        else:\n","            print(f\"ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {target}\")\n","            return target\n","\n","    response = requests.get(url, stream=True)\n","    total = int(response.headers.get('content-length', 0))\n","    with open(target, 'wb') as file, tqdm(\n","        desc=f\"Downloading {os.path.basename(target)}\",\n","        total=total,\n","        unit='B',\n","        unit_scale=True,\n","        unit_divisor=1024,\n","        ascii=True\n","    ) as bar:\n","        for data in response.iter_content(chunk_size=1024):\n","            size = file.write(data)\n","            bar.update(size)\n","    print(f\"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target}\")\n","    return target\n","\n","# local_code_it_ai04 = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\'\n","#                                   ,'temp'\n","#                                   , 'code_it_ai04')\n","\n","if helper.is_colab:\n","    local_code_it_ai04 = os.path.join( '/content/', 'code_it_ai04')\n","else:\n","    local_code_it_ai04 = os.path.join( Path.cwd().drive + '\\\\', 'temp', 'code_it_ai04')\n","\n","print(\"local_code_it_ai04:\", local_code_it_ai04)\n","\n","os.makedirs(local_code_it_ai04, exist_ok=True)  # í´ë” ìƒì„± ì½”ë“œ ì¶”ê°€\n","unzip_paths = []\n","for key, url in download_files.items():\n","    print(f\"{key}: {url}\")\n","    zipfile = os.path.join(local_code_it_ai04, f'{key}.zip')\n","    unzip_path = os.path.join(local_code_it_ai04, f'{key}.zip.unzip')\n","    if os.path.exists(unzip_path):\n","        print(f\"ì´ë¯¸ ì••ì¶•í•´ì œëœ í´ë”ê°€ ì¡´ì¬í•©ë‹ˆë‹¤: {unzip_path}\")\n","        print('unzipfile:', unzip_path)\n","        unzip_paths.append(unzip_path)\n","        continue\n","    #download_gdrive_file(url, os.path.join(local_code_it_ai04, f'{key}.zip'), ignore=False)\n","    download_http(url, zipfile, ignore=False)\n","    unzip_path_list = heu.unzip([os.path.join(local_code_it_ai04, f'{key}.zip')])\n","    # for p in unzip_path_list:\n","    #     unzip_paths.append(p)\n","    print('unzip_path_list:', unzip_path_list)\n","    unzip_paths.extend(unzip_path_list)\n"]},{"cell_type":"markdown","metadata":{"id":"JfapF4EsMlGp"},"source":["### > ì„¤ì • < í”Œë ˆê·¸"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":12,"status":"aborted","timestamp":1758005907384,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"PjxsUVjUMlGq"},"outputs":[],"source":["# google drive rootì— keggle.json íŒŒì¼ í•„ìš”í•©ë‹ˆë‹¤.\n","for path in unzip_paths:\n","    print(\"ì••ì¶•í•´ì œëœ í´ë”:\", path)\n","\n","yolo_dataset_path = os.path.join(local_code_it_ai04, f'yolo_label_one_class.zip.unzip')\n","yaml_path = os.path.join(yolo_dataset_path, \"dataset.yaml\")\n","\n","def get_path_data():\n","    path = yolo_dataset_path\n","    return path\n","\n","print(\"yaml_path:\", yaml_path)\n","print(\"get_path_data:\", get_path_data())"]},{"cell_type":"markdown","metadata":{"id":"ZRk0o5CUMlGq"},"source":["## YOLO ëª¨ë¸ë§"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311083,"status":"aborted","timestamp":1758005907391,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"tTZrT8TLMlGq"},"outputs":[],"source":["from pathlib import Path\n","from ultralytics import YOLO\n","\n","# GPU í™•ì¸\n","device = __device\n","print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n","print(f\"CUDA ë²„ì „: {torch.version.cuda}\")"]},{"cell_type":"markdown","metadata":{"id":"d_ZyKQe7MlGu"},"source":["### 3.3 ëª¨ë¸ë§ ì—”ì§„"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311085,"status":"aborted","timestamp":1758005907395,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Jv-fWI-wzK-B"},"outputs":[],"source":["for path in unzip_paths:\n","    print(f\"ì••ì¶•í•´ì œëœ í´ë”: {path}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311088,"status":"aborted","timestamp":1758005907399,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"d1nUkIOuzK-B"},"outputs":[],"source":["def extract_folder_key(folder_path):\n","    \"\"\"\n","    í´ë” ê²½ë¡œì—ì„œ yolo_label_one_class ë“± ì£¼ìš” ëª…ì¹­ë§Œ ì¶”ì¶œ\n","    ì˜ˆì‹œ: 'd:\\\\temp\\\\code_it_ai04\\\\yolo_label_one_class.zip.unzip' â†’ 'yolo_label_one_class'\n","    \"\"\"\n","    # ê²½ë¡œì—ì„œ ë§ˆì§€ë§‰ í´ë”/íŒŒì¼ëª… ì¶”ì¶œ\n","    base = os.path.basename(folder_path)\n","    # .zip ë˜ëŠ” .zip.unzip ë“± í™•ì¥ì ì œê±°\n","    key = re.sub(r'\\.zip(\\.unzip)?$', '', base)\n","    return key\n","\n","def update_yaml_paths_to_absolute(yaml_path):\n","    with open(yaml_path, 'r') as f:\n","        data = yaml.safe_load(f)\n","\n","    yaml_dir = os.path.dirname(yaml_path)\n","    data['path'] = os.path.normpath(os.path.join(yaml_dir, data['path']))\n","    # for key in ['train', 'val', 'test']:\n","    #     if key in data and not os.path.isabs(data[key]):\n","    #         data[key] = os.path.normpath(os.path.join(yaml_dir, data[key]))\n","\n","    with open(yaml_path, 'w') as f:\n","        yaml.dump(data, f, allow_unicode=True)\n","\n","import wandb\n","wandb.login()  # ë˜ëŠ” wandb.init(project=\"your_project_name\")\n","plt.rcParams['font.family'] = 'DejaVu Sans'\n","plt.rcParams['axes.unicode_minus'] = False\n"]},{"cell_type":"markdown","metadata":{"id":"CYCxlr34zK-B"},"source":["# ëª¨ë¸ í•™ìŠµ"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FCF9j_pf5E9E","executionInfo":{"status":"aborted","timestamp":1758005907406,"user_tz":-540,"elapsed":311094,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def log_training_metrics(results, model_name):\n","    \"\"\"\n","    YOLO í›ˆë ¨ ê²°ê³¼ì—ì„œ ë©”íŠ¸ë¦­ì„ ì¶”ì¶œí•˜ì—¬ WandBì— ë¡œê·¸\n","    \"\"\"\n","    try:\n","        # results.csv íŒŒì¼ì—ì„œ ë©”íŠ¸ë¦­ ì½ê¸°\n","        csv_path = os.path.join(results.save_dir, 'results.csv')\n","        if os.path.exists(csv_path):\n","            df = pd.read_csv(csv_path)\n","            df.columns = df.columns.str.strip()  # ê³µë°± ì œê±°\n","\n","            # ê° ì—í¬í¬ë³„ ë©”íŠ¸ë¦­ ë¡œê·¸\n","            for idx, row in df.iterrows():\n","                epoch = idx + 1\n","\n","                # ë©”íŠ¸ë¦­ ë”•ì…”ë„ˆë¦¬ ìƒì„±\n","                metrics = {\n","                    \"epoch\": epoch,\n","                    \"train/box_loss\": row.get('train/box_loss', 0),\n","                    \"train/cls_loss\": row.get('train/cls_loss', 0),\n","                    \"train/dfl_loss\": row.get('train/dfl_loss', 0),\n","                    \"val/box_loss\": row.get('val/box_loss', 0),\n","                    \"val/cls_loss\": row.get('val/cls_loss', 0),\n","                    \"val/dfl_loss\": row.get('val/dfl_loss', 0),\n","                    \"metrics/precision(B)\": row.get('metrics/precision(B)', 0),\n","                    \"metrics/recall(B)\": row.get('metrics/recall(B)', 0),\n","                    \"metrics/mAP50(B)\": row.get('metrics/mAP50(B)', 0),\n","                    \"metrics/mAP50-95(B)\": row.get('metrics/mAP50-95(B)', 0),\n","                }\n","\n","                # NaN ê°’ ì²˜ë¦¬\n","                metrics = {k: (v if not pd.isna(v) else 0) for k, v in metrics.items()}\n","\n","                wandb.log(metrics)\n","\n","            print(f\"í›ˆë ¨ ë©”íŠ¸ë¦­ì´ WandBì— ë¡œê·¸ë˜ì—ˆìŠµë‹ˆë‹¤: {len(df)}ê°œ ì—í¬í¬\")\n","\n","        # ì¶”ê°€ ì‹œê°í™”: í˜¼ë™ í–‰ë ¬, PR ì»¤ë¸Œ ë“±\n","        log_additional_plots(results)\n","\n","    except Exception as e:\n","        print(f\"ë©”íŠ¸ë¦­ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}\")\n","\n","def log_additional_plots(results):\n","    \"\"\"\n","    ì¶”ê°€ í”Œë¡¯ë“¤ì„ WandBì— ë¡œê·¸\n","    \"\"\"\n","    try:\n","        save_dir = results.save_dir\n","\n","        # 1. í›ˆë ¨ ê²°ê³¼ í”Œë¡¯\n","        plots_to_log = [\n","            ('results.png', 'Training Results'),\n","            ('confusion_matrix.png', 'Confusion Matrix'),\n","            ('PR_curve.png', 'Precision-Recall Curve'),\n","            ('F1_curve.png', 'F1 Curve'),\n","        ]\n","\n","        for plot_file, title in plots_to_log:\n","            plot_path = os.path.join(save_dir, plot_file)\n","            if os.path.exists(plot_path):\n","                wandb.log({f\"plots/{title}\": wandb.Image(plot_path)})\n","\n","        # 2. ê²€ì¦ ë°°ì¹˜ ì´ë¯¸ì§€\n","        val_batch_path = os.path.join(save_dir, 'val_batch0_pred.jpg')\n","        if os.path.exists(val_batch_path):\n","            wandb.log({\"validation/predictions\": wandb.Image(val_batch_path)})\n","\n","        print(\"ì¶”ê°€ í”Œë¡¯ë“¤ì´ WandBì— ë¡œê·¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    except Exception as e:\n","        print(f\"ì¶”ê°€ í”Œë¡¯ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}\")\n","\n","def log_comprehensive_metrics(results, model, yaml_path):\n","    \"\"\"\n","    í¬ê´„ì ì¸ ë©”íŠ¸ë¦­ ë° ì‹œê°í™” ë¡œê¹…\n","    \"\"\"\n","    try:\n","        # 1. ê¸°ë³¸ í›ˆë ¨ ë©”íŠ¸ë¦­\n","        log_training_metrics(results, \"comprehensive\")\n","\n","        # 2. ëª¨ë¸ ìš”ì•½ ì •ë³´\n","        model_summary = {\n","            \"model/parameters\": sum(p.numel() for p in model.model.parameters()),\n","            \"model/layers\": len(list(model.model.modules())),\n","        }\n","\n","        # ëª¨ë¸ íŒŒì¼ í¬ê¸° (best.pt)\n","        best_pt_path = os.path.join(results.save_dir, 'weights', 'best.pt')\n","        if os.path.exists(best_pt_path):\n","            model_summary[\"model/size_mb\"] = os.path.getsize(best_pt_path) / (1024*1024)\n","\n","        wandb.log(model_summary)\n","\n","        # 3. ë°ì´í„°ì…‹ ì •ë³´\n","        with open(yaml_path, 'r') as f:\n","            dataset_config = yaml.safe_load(f)\n","\n","        dataset_info = {\n","            \"dataset/classes\": dataset_config['nc'],\n","            \"dataset/names\": str(dataset_config['names'])\n","        }\n","        wandb.log(dataset_info)\n","\n","        # 4. ìµœì¢… ì„±ëŠ¥ ìš”ì•½\n","        if hasattr(results, 'results_dict'):\n","            final_metrics = {\n","                \"final/best_mAP50\": results.results_dict.get('metrics/mAP50(B)', 0),\n","                \"final/best_mAP50-95\": results.results_dict.get('metrics/mAP50-95(B)', 0),\n","                \"final/best_precision\": results.results_dict.get('metrics/precision(B)', 0),\n","                \"final/best_recall\": results.results_dict.get('metrics/recall(B)', 0)\n","            }\n","            wandb.log(final_metrics)\n","\n","        print(\"í¬ê´„ì ì¸ ë©”íŠ¸ë¦­ì´ WandBì— ë¡œê·¸ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","    except Exception as e:\n","        print(f\"í¬ê´„ì  ë©”íŠ¸ë¦­ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"30gJXO2S5E9E","executionInfo":{"status":"aborted","timestamp":1758005907437,"user_tz":-540,"elapsed":311125,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def train_yolo_model(yaml_path=yaml_path, data_set_name=None,\n","                    model_name=\"yolov8m\", epochs=30, batch_size=16,\n","                    wandb_project=\"codeit-ai-04-01\", use_wandb=True):\n","    \"\"\"\n","    í–¥ìƒëœ WandB í†µí•©ì´ í¬í•¨ëœ YOLO ëª¨ë¸ í›ˆë ¨\n","    \"\"\"\n","    model_save_name = f\"{model_name}_{data_set_name}_{datetime.now(__kst).strftime('%Y%m%d_%H%M')}\"\n","\n","    print(f\"model: {model_name}\")\n","    print(f\"yaml_path: {yaml_path}\")\n","    print(f\"data_set_name: {data_set_name}\")\n","    print(f\"model_save_name: {model_save_name}\")\n","    print(f\"use_wandb: {use_wandb}\")\n","\n","    # WandB ì´ˆê¸°í™”\n","    if use_wandb:\n","        run = wandb.init(\n","            project=wandb_project,\n","            name=model_save_name,\n","            config={\n","                \"model\": model_name,\n","                \"epochs\": epochs,\n","                \"batch_size\": batch_size,\n","                \"dataset\": data_set_name,\n","                \"imgsz\": 640,\n","                \"iou\": 0.75,\n","                \"optimizer\": \"AdamW\",\n","                \"lr0\": 0.01\n","            },\n","            reinit=True\n","        )\n","\n","    try:\n","        model = YOLO(f'{model_name}.pt')\n","\n","        # í›ˆë ¨ ì‹¤í–‰\n","        results = model.train(\n","            data=yaml_path,\n","            epochs=epochs,\n","            imgsz=640,\n","            batch=batch_size,\n","            iou=0.75,\n","            device=__device,\n","            project=get_path_modeling(),\n","            name=model_save_name,\n","            save_period=-1,\n","            patience=10,\n","            resume=False,\n","            verbose=False,\n","        )\n","\n","        # í›ˆë ¨ í›„ ìƒì„¸ ë©”íŠ¸ë¦­ ë¡œê¹…\n","        if use_wandb and wandb.run is not None:\n","            log_comprehensive_metrics(results, model, yaml_path)\n","\n","        return model, results, os.path.join(get_path_modeling(), model_save_name)\n","\n","    except Exception as e:\n","        print(f\"í›ˆë ¨ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n","        raise\n","    finally:\n","        if use_wandb and wandb.run is not None:\n","            wandb.finish()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311125,"status":"aborted","timestamp":1758005907439,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"7bTLvDRK80lv"},"outputs":[],"source":["print(unzip_paths)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311126,"status":"aborted","timestamp":1758005907442,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"fKLBgIwtzK-B"},"outputs":[],"source":["os.environ['YOLO_VERBOSE'] = 'False'\n","os.environ['ULTRALYTICS_LOG_LEVEL'] = 'WARNING'  # ë˜ëŠ” 'ERROR'\n","\n","model_paths = []\n","#unzip_paths_sample = unzip_paths[:1]\n","unzip_paths_sample = unzip_paths\n","for path in unzip_paths_sample:\n","    key = extract_folder_key(path)\n","    yaml_path = os.path.join(path, \"dataset.yaml\")\n","    print(\"yaml_path:\", yaml_path)\n","    print(\"path:\", path)\n","    print(\"key:\", key)\n","    update_yaml_paths_to_absolute(yaml_path)\n","\n","    #model, train_results, model_path= train_yolo_model(model_name=\"yolov8n\", yaml_path=yaml_path, data_set_name=key)\n","    model, train_results, model_path= train_yolo_model(model_name=\"yolov8m\", yaml_path=yaml_path, data_set_name=key)\n","    #model, train_results, model_path= test_on_samples_with_wandb(yaml_path=yaml_path, data_set_name=key)\n","\n","    model_res={\n","        'key': key,\n","        'data_set_name' : key,\n","        'yolo_dataset_path': path,\n","        'yaml_path' : yaml_path,\n","        'model_path' : model_path,\n","    }\n","    model_paths.append(model_res)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311128,"status":"aborted","timestamp":1758005907445,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"sEu2CIwWzK-B"},"outputs":[],"source":["for m in model_paths:\n","    print_json_tree(m)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311132,"status":"aborted","timestamp":1758005907450,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"WgESZb5vzK-B"},"outputs":[],"source":["\n","# ë°ì´í„° ë¶„í¬ í™•ì¸\n","def print_dataset_info(yaml_path=yaml_path):\n","    with open(yaml_path, 'r') as f:\n","        dataset_config = yaml.safe_load(f)\n","\n","    print('image:', os.path.join(dataset_config['path'], 'images'))\n","    train_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['train'])).glob(\"*.png\")]\n","    val_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['val'])).glob(\"*.png\")]\n","    test_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['test'])).glob(\"*.png\")]\n","\n","    train_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['train'])).glob(\"*.jpg\")]\n","    val_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['val'])).glob(\"*.jpg\")]\n","    test_images = [str(p) for p in Path(os.path.join(dataset_config['path'], dataset_config['test'])).glob(\"*.jpg\")]\n","\n","    print('label:', os.path.join(dataset_config['path'], 'labels'))\n","    train_labels = [str(p) for p in Path(os.path.join(dataset_config['path'], 'labels', 'train')).glob(\"*.txt\")]\n","    val_labels = [str(p) for p in Path(os.path.join(dataset_config['path'], 'labels', 'val')).glob(\"*.txt\")]\n","    test_labels = [str(p) for p in Path(os.path.join(dataset_config['path'], 'labels', 'test')).glob(\"*.txt\")]\n","\n","    return train_images, val_images,test_images, train_labels, val_labels, test_labels\n","\n","# ì œì•½ì½”ë“œë¥¼ ì¹´í…Œê³ ë¦¬ IDë¡œ ë³€í™˜\n","def drug_to_category_id(drug_name):\n","    \"\"\"ì•½í’ˆëª…ì„ ì¹´í…Œê³ ë¦¬ IDë¡œ ë³€í™˜\"\"\"\n","    if type(drug_name) is int:\n","        return drug_name\n","    if drug_name.startswith('K-'):\n","        return int(drug_name[2:]) - 1\n","    else:\n","        raise ValueError(f\"Unexpected drug name format: {drug_name}\")\n","\n","def result_save_csv(csv_rows, save_csv_path):\n","    save_dir = os.path.dirname(save_csv_path)\n","    if save_dir and not os.path.exists(save_dir):\n","        os.makedirs(save_dir, exist_ok=True)\n","    with open(save_csv_path, \"w\", newline=\"\", encoding=\"utf-8\") as f:\n","        writer = csv.writer(f)\n","        writer.writerow([\"annotation_id\", \"image_id\", \"category_id\", \"bbox_x\", \"bbox_y\", \"bbox_w\", \"bbox_h\", \"score\"])\n","        writer.writerows(csv_rows)\n","    print(f\"ì˜ˆì¸¡ ê²°ê³¼ê°€ {save_csv_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","\n","def plot_result_view(results, class_names):\n","    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","    axes = axes.flatten()\n","    for idx, (result, ax) in enumerate(zip(results, axes)):\n","        img = result[0].orig_img\n","        annotated = result[0].plot()\n","        ax.imshow(annotated)\n","        ax.axis('off')\n","        if len(result[0].boxes) > 0:\n","            conf = result[0].boxes.conf[0].item()\n","            cls = int(result[0].boxes.cls[0].item())\n","            pred_class = class_names[cls] if cls < len(class_names) else 'unknown'\n","            ax.set_title(f'{pred_class} ({conf:.2f})')\n","        else:\n","            ax.set_title('No Detection')\n","    plt.tight_layout()\n","    plt.show()\n","\n","def plot_result_save(results, class_names, save_dir=\"submission\"):\n","    import os\n","    import cv2\n","    import random\n","\n","    # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ ìƒì„± (ê³ ì •)\n","    random.seed(42)\n","    color_map = {}\n","    for i, cname in enumerate(class_names):\n","        color_map[i] = tuple(random.choices(range(50, 256), k=3))\n","\n","    save_dir = os.path.dirname(save_dir) if not os.path.isdir(save_dir) else save_dir\n","    if save_dir and not os.path.exists(save_dir):\n","        os.makedirs(save_dir, exist_ok=True)\n","\n","    from tqdm import tqdm  # tqdm ì„í¬íŠ¸\n","    pbar = tqdm(enumerate(results), total=len(results), ascii=True, desc=\"Saving results\")\n","    for idx, result in pbar:\n","        img = result[0].orig_img.copy()\n","        for box in result[0].boxes:\n","            xyxy = box.xyxy[0].cpu().numpy().astype(int)\n","            cls = int(box.cls.item())\n","            conf = box.conf.item()\n","            class_name = class_names[cls] if cls < len(class_names) else 'unknown'\n","            label = f\"{class_name} {conf:.2f}\"\n","            color = color_map.get(cls, (0,255,0))\n","\n","            # ë°•ìŠ¤ ê·¸ë¦¬ê¸°\n","            cv2.rectangle(img, (xyxy[0], xyxy[1]), (xyxy[2], xyxy[3]), color, 2)\n","\n","            # ë¼ë²¨ ìœ„ì¹˜ ê²°ì •\n","            label_size, _ = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)\n","            label_y = xyxy[1] - 10\n","            if label_y < 0:\n","                label_y = xyxy[1] + label_size[1] + 5\n","\n","            # ë¼ë²¨ ë°°ê²½\n","            cv2.rectangle(\n","                img,\n","                (xyxy[0], label_y - label_size[1] - 5),\n","                (xyxy[0] + label_size[0], label_y + 5),\n","                color,\n","                -1\n","            )\n","            # ë¼ë²¨ í…ìŠ¤íŠ¸\n","            cv2.putText(img, label, (xyxy[0], label_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,0), 2)\n","\n","        img_path = result[-1]\n","        img_name = os.path.basename(img_path).split('.')[0]\n","\n","        # file_path = os.path.join(save_dir, f\"result_{idx}.png\")\n","        file_path = os.path.join(save_dir, f\"result_{img_name}_yolo.jpg\")\n","        cv2.imwrite(file_path, cv2.cvtColor(img, cv2.COLOR_RGB2BGR))\n","        pbar.set_postfix_str(f\"Saved: {os.path.basename(file_path)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311148,"status":"aborted","timestamp":1758005907467,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"YZ7c_YUCzK-B"},"outputs":[],"source":["for m in model_paths:\n","    print_json_tree(m)\n","\n","    model_path = os.path.join(m['model_path'], \"weights\", \"best.pt\")\n","    yaml_path = os.path.join(m['yolo_dataset_path'], \"dataset.yaml\")\n","    print(\"model_path:\", model_path)\n","    print(\"yaml_path:\", yaml_path)\n","\n","    # path ê°’ì„ ì ˆëŒ€ê²½ë¡œë¡œ ë³€ê²½í•œë‹¤.\n","    update_yaml_paths_to_absolute(yaml_path)\n","\n","    with open(yaml_path, 'r') as f:\n","        dataset_config = yaml.safe_load(f)\n","\n","    train_images, val_images, test_images, train_labels, val_labels, test_labels = print_dataset_info(yaml_path=yaml_path)\n","    class_names = dataset_config['names']\n","    # categories = {}\n","    # for cname in class_names:\n","    #     try:\n","    #         cid = drug_to_category_id(cname)\n","    #         categories[cname] = cid\n","    #     except ValueError as e:\n","    #         print(f\"Warning: {e}\")\n","\n","    print(\"ë°ì´í„°ì…‹ ì„¤ì •:\")\n","    print(f\"í´ë˜ìŠ¤ ìˆ˜: {dataset_config['nc']}\")\n","    print(f\"í´ë˜ìŠ¤ ì´ë¦„: {dataset_config['names']}\")\n","    # print(f\"ì¹´í…Œê³ ë¦¬: {categories}\")\n","    print(f\"í›ˆë ¨ ê²½ë¡œ: {dataset_config['train']}\")\n","    print(f\"ê²€ì¦ ê²½ë¡œ: {dataset_config['val']}\")\n","    print(f\"í…ŒìŠ¤íŠ¸ ê²½ë¡œ: {dataset_config['test']}\")\n","\n","    print(f\"í›ˆë ¨ ì´ë¯¸ì§€: {len(train_images)}ê°œ (ë¼ë²¨: {len(train_labels)}ê°œ)\")\n","    print(f\"ê²€ì¦ ì´ë¯¸ì§€: {len(val_images)}ê°œ (ë¼ë²¨: {len(val_labels)}ê°œ)\")\n","    print(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_images)}ê°œ (ë¼ë²¨: {len(test_labels)}ê°œ)\")\n"]},{"cell_type":"markdown","metadata":{"id":"hEEAOgmozK-B"},"source":["# TEST"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311153,"status":"aborted","timestamp":1758005907473,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"HpkPd2sTzK-B"},"outputs":[],"source":["#def test_on_samples(model, class_names, categories, test_files: list):\n","def test_on_samples(model, class_names, test_files: list):\n","    \"\"\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì—ì„œ ìƒ˜í”Œ ì˜ˆì¸¡ ë° ê²°ê³¼ CSV ì €ì¥\"\"\"\n","    if not test_files:\n","        print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        return\n","\n","    print(f\"{len(test_files)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ===\")\n","\n","    pbar = tqdm(test_files, **get_tqdm_kwargs())\n","    results = []\n","    csv_rows = []\n","    json_rows = []\n","    annotation_id = 1\n","\n","    for img_path in pbar:\n","        pbar.set_description(f\"Processing {img_path}\")\n","        res = model(img_path, verbose=False)\n","        results.append(res)\n","\n","        # ì´ë¯¸ì§€ íŒŒì¼ëª…ì—ì„œ ìˆ«ì ì¶”ì¶œ (ì˜ˆ: '1.png' â†’ 1)\n","        image_id = int(''.join(filter(str.isdigit, img_path)))\n","\n","        # ê° ë°•ìŠ¤ë³„ë¡œ ê²°ê³¼ ì €ì¥\n","        for box in res[0].boxes:\n","            cls = int(box.cls.item())\n","            class_name = class_names[cls] if cls < len(class_names) else 'unknown'\n","            category_id = class_name\n","            # if class_name.startswith('K-'):\n","            #     category_id = categories[class_name]\n","            # else:\n","            #     raise ValueError(f\"Unexpected class name format: {class_name}\")\n","\n","            score = box.conf.item()\n","            # bbox: [x_center, y_center, w, h] â†’ [x, y, w, h]ë¡œ ë³€í™˜\n","            xywh = box.xywh[0].cpu().numpy()\n","            bbox_x = int(xywh[0] - xywh[2] / 2)\n","            bbox_y = int(xywh[1] - xywh[3] / 2)\n","            bbox_w = int(xywh[2])\n","            bbox_h = int(xywh[3])\n","\n","            csv_rows.append([\n","                annotation_id, image_id, category_id, bbox_x, bbox_y, bbox_w, bbox_h, round(score, 2)\n","            ])\n","            json_rows.append({\n","                \"annotation_id\": annotation_id,\n","                \"image_id\": image_id,\n","                \"img_path\" : img_path,\n","                \"category_id\": category_id,\n","                \"bbox\": [bbox_x, bbox_y, bbox_w, bbox_h],\n","                \"score\": round(score, 3)\n","            })\n","            annotation_id += 1\n","    print(f\"ì´ {len(csv_rows)}ê°œì˜ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±ë¨.\")\n","    return results, csv_rows, json_rows\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311191,"status":"aborted","timestamp":1758005907511,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Q7HTqOOxzK-B"},"outputs":[],"source":["def log_predictions_to_wandb(results, class_names, test_files, num_samples=20):\n","    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ë¥¼ WandBì— ë¡œê·¸\"\"\"\n","    try:\n","        wandb_images = []\n","        sample_results = random.sample(list(zip(results, test_files)), min(num_samples, len(results)))\n","\n","        for result, img_path in sample_results:\n","            # ì›ë³¸ ì´ë¯¸ì§€\n","            img = Image.open(img_path)\n","\n","            # ì˜ˆì¸¡ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš° ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ìƒì„±\n","            boxes = []\n","            if len(result[0].boxes) > 0:\n","                for box in result[0].boxes:\n","                    xyxy = box.xyxy[0].cpu().numpy()\n","                    cls = int(box.cls.item())\n","                    conf = box.conf.item()\n","                    class_name = class_names[cls] if cls < len(class_names) else 'unknown'\n","\n","                    boxes.append({\n","                        \"position\": {\n","                            \"minX\": int(xyxy[0]),\n","                            \"minY\": int(xyxy[1]),\n","                            \"maxX\": int(xyxy[2]),\n","                            \"maxY\": int(xyxy[3])\n","                        },\n","                        \"class_id\": cls,\n","                        \"box_caption\": f\"{class_name} ({conf:.2f})\",\n","                        \"domain\": \"pixel\"\n","                    })\n","\n","            wandb_images.append(\n","                wandb.Image(\n","                    img,\n","                    caption=f\"Predictions: {os.path.basename(img_path)}\",\n","                    boxes={\"predictions\": {\"box_data\": boxes, \"class_labels\": dict(enumerate(class_names))}}\n","                )\n","            )\n","\n","        wandb.log({\"predictions\": wandb_images})\n","\n","    except Exception as e:\n","        print(f\"ì˜ˆì¸¡ ê²°ê³¼ ë¡œê¹… ì¤‘ ì˜¤ë¥˜: {e}\")\n","\n","def create_wandb_summary_table(csv_rows, class_names):\n","    \"\"\"ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ í…Œì´ë¸” ìƒì„±\"\"\"\n","    try:\n","        # í´ë˜ìŠ¤ë³„ ì˜ˆì¸¡ ê°œìˆ˜ ê³„ì‚°\n","        class_counts = {}\n","        confidence_scores = []\n","\n","        for row in csv_rows:\n","            category_id = row[2]\n","            score = row[7]\n","\n","            # ì¹´í…Œê³ ë¦¬ IDë¥¼ í´ë˜ìŠ¤ëª…ìœ¼ë¡œ ë³€í™˜\n","            class_name = f\"K-{category_id + 1}\"\n","            class_counts[class_name] = class_counts.get(class_name, 0) + 1\n","            confidence_scores.append(score)\n","\n","        # WandB í…Œì´ë¸” ìƒì„±\n","        table = wandb.Table(columns=[\"Class\", \"Count\", \"Percentage\"])\n","        total_predictions = len(csv_rows)\n","\n","        for class_name, count in class_counts.items():\n","            percentage = (count / total_predictions) * 100 if total_predictions > 0 else 0\n","            table.add_data(class_name, count, f\"{percentage:.1f}%\")\n","\n","        # ìš”ì•½ ë©”íŠ¸ë¦­\n","        avg_confidence = np.mean(confidence_scores) if confidence_scores else 0\n","\n","        wandb.log({\n","            \"summary/predictions_table\": table,\n","            \"summary/total_predictions\": total_predictions,\n","            \"summary/avg_confidence\": avg_confidence,\n","            \"summary/unique_classes\": len(class_counts)\n","        })\n","\n","    except Exception as e:\n","        print(f\"ìš”ì•½ í…Œì´ë¸” ìƒì„± ì¤‘ ì˜¤ë¥˜: {e}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311195,"status":"aborted","timestamp":1758005907515,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"78ynbAPkzK-B"},"outputs":[],"source":["def convert_yolo_bbox_with_orig_img(xywh, orig_img, default_orig_size=(976, 1280)):\n","    \"\"\"\n","    YOLO ì¢Œí‘œë¥¼ ì›ë³¸ ì¢Œí‘œë¡œ ë³€í™˜\n","\n","    Args:\n","        xywh: YOLO ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [center_x, center_y, width, height]\n","        orig_img: YOLOì—ì„œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€ (ë¦¬ì‚¬ì´ì¦ˆëœ ìƒíƒœ, ë³´í†µ 640x640)\n","        default_orig_size: ì‹¤ì œ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸° (width, height)\n","\n","    Returns:\n","        tuple: (bbox_x, bbox_y, bbox_w, bbox_h) - ì‹¤ì œ ì›ë³¸ í¬ê¸° ê¸°ì¤€ COCO í˜•ì‹ ì¢Œí‘œ\n","    \"\"\"\n","\n","    orig_width, orig_height = default_orig_size\n","    yolo_height, yolo_width = orig_img.shape[:2]\n","    if yolo_height == orig_height and yolo_width == orig_width:\n","        # ë¦¬ì‚¬ì´ì¦ˆë‚˜ íŒ¨ë”©ì´ ì—†ëŠ” ê²½ìš°\n","        center_x, center_y, bbox_w, bbox_h = xywh\n","    else:\n","        # ë¦¬ì‚¬ì´ì¦ˆ ë° íŒ¨ë”©ì´ ìˆëŠ” ê²½ìš° default_orig_size ê¸°ì¤€ ë¹„ìœ¨ ìœ ì§€ ë˜ì—ˆìŒìœ¼ë¡œ í˜ë”©ì„ ì œê±°í•˜ê³  ìŠ¤ì¼€ì¼ ë³µì›\n","        # default_orig_size -> orig_img ë  ê²½ìš° íŒ¨ë”© ê³„ì‚° (ë¹„ìœ¨ ìœ ì§€)\n","        # í˜ë”© ì œê±° ë° ìŠ¤ì¼€ì¼ ë³µì›\n","        scale = min(yolo_width / orig_width, yolo_height / orig_height)\n","        resized_width = int(orig_width * scale)\n","        resized_height = int(orig_height * scale)\n","        pad_x = (yolo_width - resized_width) / 2\n","        pad_y = (yolo_height - resized_height) / 2\n","\n","        center_x = (xywh[0] - pad_x) / scale\n","        center_y = (xywh[1] - pad_y) / scale\n","        bbox_w = xywh[2] / scale\n","        bbox_h = xywh[3] / scale\n","\n","    # ì¤‘ì‹¬ì ì„ ì¢Œìƒë‹¨ìœ¼ë¡œ ë³€í™˜\n","    bbox_x = center_x - bbox_w / 2\n","    bbox_y = center_y - bbox_h / 2\n","\n","    # ê²½ê³„ ê²€ì‚¬\n","    bbox_x = max(0, bbox_x)\n","    bbox_y = max(0, bbox_y)\n","    bbox_w = min(bbox_w, orig_width - bbox_x)\n","    bbox_h = min(bbox_h, orig_height - bbox_y)\n","\n","    bbox_w = int(min(bbox_w, orig_width - bbox_x))\n","    bbox_h = int(min(bbox_h, orig_height - bbox_y))\n","\n","    # ì¶”ê°€ ê²€ì¦\n","    if bbox_w <= 0 or bbox_h <= 0:\n","        print(f\"Warning: Invalid bbox size - w:{bbox_w}, h:{bbox_h}\")\n","        bbox_w = max(1, bbox_w)\n","        bbox_h = max(1, bbox_h)\n","\n","    return int(bbox_x), int(bbox_y), int(bbox_w), int(bbox_h)\n","\n","# ê¸°ì¡´ í•¨ìˆ˜ë„ ìœ ì§€ (í˜¸í™˜ì„±)\n","def convert_yolo_bbox_simple(xywh, orig_size=(976, 1280)):\n","    \"\"\"ê¸°ì¡´ í•¨ìˆ˜ - í˜¸í™˜ì„± ìœ ì§€\"\"\"\n","    return convert_yolo_bbox_with_orig_img(xywh, None, orig_size)\n","\n","\n","#def test_on_samples_with_wandb(model, class_names, categories, test_files: list, log_to_wandb=True):\n","def test_on_samples_with_wandb(model, class_names, test_files: list, log_to_wandb=True):\n","    \"\"\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì—ì„œ ìƒ˜í”Œ ì˜ˆì¸¡ ë° WandB ë¡œê¹…\"\"\"\n","    if not test_files:\n","        print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        return\n","\n","    print(f\"{len(test_files)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ===\")\n","\n","    pbar = tqdm(test_files, **get_tqdm_kwargs())\n","    results = []\n","    csv_rows = []\n","    json_rows = []\n","    annotation_id = 1\n","\n","    for img_path in pbar:\n","        pbar.set_description(f\"Processing {os.path.basename(img_path)}\")\n","        res = model(img_path, verbose=False)\n","        res.append(img_path)  # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ë°°ì—´ ë§ˆì§€ë§‰ì— ì¶”ê°€\n","        results.append(res)\n","        image_id = int(''.join(filter(str.isdigit, os.path.basename(img_path))))\n","        for box in res[0].boxes:\n","            cls = int(box.cls.item())\n","            class_name = class_names[cls] if cls < len(class_names) else 'unknown'\n","            category_id = class_name\n","            # if class_name.startswith('K-'):\n","            #     category_id = categories[class_name]\n","            # else:\n","            #     raise ValueError(f\"Unexpected class name format: {class_name}\")\n","            score = box.conf.item()\n","            xywh = box.xywh[0].cpu().numpy()\n","\n","            bbox_x, bbox_y, bbox_w, bbox_h = convert_yolo_bbox_with_orig_img(\n","                xywh,\n","                res[0].orig_img,  # ì‹¤ì œ ì›ë³¸ ì´ë¯¸ì§€ ì „ë‹¬\n","                default_orig_size=(976, 1280)  # ê¸°ë³¸ê°’\n","            )\n","\n","            csv_rows.append([\n","                annotation_id, image_id, category_id, bbox_x, bbox_y, bbox_w, bbox_h, score\n","            ])\n","            json_rows.append({\n","                \"annotation_id\": annotation_id,\n","                \"image_id\": image_id,\n","                \"img_path\": img_path,\n","                \"category_id\": category_id,\n","                \"bbox\": [bbox_x, bbox_y, bbox_w, bbox_h],\n","                \"score\": score\n","            })\n","            annotation_id += 1\n","\n","    print(f\"ì´ {len(csv_rows)}ê°œì˜ ì˜ˆì¸¡ ê²°ê³¼ ìƒì„±ë¨.\")\n","\n","    # WandB ë¡œê¹…\n","    if log_to_wandb and wandb.run is not None:\n","        log_predictions_to_wandb(results, class_names, test_files)\n","        create_wandb_summary_table(csv_rows, class_names)\n","\n","    return results, csv_rows, json_rows"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311197,"status":"aborted","timestamp":1758005907519,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"HZIG_MXKzK-C"},"outputs":[],"source":["\n","\n","for m in model_paths:\n","    print_json_tree(m)\n","\n","    model_path = os.path.join(m['model_path'], \"weights\", \"best.pt\")\n","    yaml_path = os.path.join(m['yolo_dataset_path'], \"dataset.yaml\")\n","    now_str = datetime.now(__kst).strftime(\"%Y%m%d_%H%M%S\")\n","    submission_path = os.path.join(m['model_path'], f\"submission_{now_str}\")\n","\n","    print(\"model_path:\", model_path)\n","    print(\"yaml_path:\", yaml_path)\n","\n","    # path ê°’ì„ ì ˆëŒ€ê²½ë¡œë¡œ ë³€ê²½í•œë‹¤.\n","    update_yaml_paths_to_absolute(yaml_path)\n","\n","    with open(yaml_path, 'r') as f:\n","        dataset_config = yaml.safe_load(f)\n","\n","    train_images, val_images, test_images, train_labels, val_labels, test_labels = print_dataset_info(yaml_path=yaml_path)\n","    class_names = dataset_config['names']\n","\n","    print(\"ë°ì´í„°ì…‹ ì„¤ì •:\")\n","    print(f\"í´ë˜ìŠ¤ ìˆ˜: {dataset_config['nc']}\")\n","    print(f\"í´ë˜ìŠ¤ ì´ë¦„: {dataset_config['names']}\")\n","    print(f\"í›ˆë ¨ ê²½ë¡œ: {dataset_config['train']}\")\n","    print(f\"ê²€ì¦ ê²½ë¡œ: {dataset_config['val']}\")\n","    print(f\"í…ŒìŠ¤íŠ¸ ê²½ë¡œ: {dataset_config['test']}\")\n","\n","    print(f\"í›ˆë ¨ ì´ë¯¸ì§€: {len(train_images)}ê°œ (ë¼ë²¨: {len(train_labels)}ê°œ)\")\n","    print(f\"ê²€ì¦ ì´ë¯¸ì§€: {len(val_images)}ê°œ (ë¼ë²¨: {len(val_labels)}ê°œ)\")\n","    print(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {len(test_images)}ê°œ (ë¼ë²¨: {len(test_labels)}ê°œ)\")\n","\n","    print(\"\\nëª¨ë¸í•™ìŠµ\")\n","    model = YOLO(model_path)\n","    # results, csv_rows, json_rows = test_on_samples(model=model,\n","    #                 class_names=class_names,\n","    #                 categories=categories,\n","    #                 test_files=test_images)\n","    results, csv_rows, json_rows = test_on_samples_with_wandb(model=model,\n","                    class_names=class_names,\n","                    # categories=categories,\n","                    test_files=test_images)\n","\n","    print('result_save_csv', result_save_csv)\n","    print('csv_rows', csv_rows)\n","    print('json_rows', json_rows)\n","    os.makedirs(submission_path, exist_ok=True)\n","    print(f\"ê²°ê³¼ ì €ì¥ í´ë”: {submission_path}\")\n","\n","    csv_save_path = os.path.join(submission_path, f\"submission.csv\")\n","    result_save_csv(csv_rows, csv_save_path)\n","    plot_result_save(results, class_names, save_dir=submission_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311200,"status":"aborted","timestamp":1758005907522,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"NVAbOwSGzK-C"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":311202,"status":"aborted","timestamp":1758005907525,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"zQ9jm1yjzK-C"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"env_colab_250827","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"}},"nbformat":4,"nbformat_minor":0}