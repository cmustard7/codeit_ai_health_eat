{"cells":[{"cell_type":"markdown","metadata":{"id":"G3tb146HKUGS"},"source":["# [ì´ˆê¸‰ í”„ë¡œì íŠ¸] 4íŒ€_ê¹€ëª…í™˜"]},{"cell_type":"markdown","metadata":{"id":"hmaVeBaGKUGW"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"KzN8SzLMKgH1"},"source":["# í”„ë¡œê·¸ë˜ë°"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"47-Qf8TYKUGW"},"outputs":[],"source":["# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n","import cv2\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Subset\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from torch.utils.data import Dataset\n","from collections import OrderedDict\n","from pycocotools.coco import COCO\n","from pycocotools import mask as coco_mask\n","\n","# --- ê¸°íƒ€ ---\n","import re\n","import os\n","import sys\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU ì„¤ì •\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:{__device}\")"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"gDTmqQCCrBWm","outputId":"07c8b240-b50d-4bad-9d97-6725fcca10e4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757601321115,"user_tz":-540,"elapsed":42612,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","install fonts-nanum...\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":3}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17307,"status":"ok","timestamp":1757601340236,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"WE6336hF11C5","outputId":"b7e4e06b-7344-4798-f0b5-7724bfc124b7"},"outputs":[{"output_type":"stream","name":"stdout","text":["utils_dir: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\n","sys.path: ['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmptfl_1mrc', '/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils']\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","helper.__file__: /content/helper_c0z0c_dev.py\n","health_ea_utils.__file__: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils/health_ea_utils.py\n"]}],"source":["import os, sys\n","from pathlib import Path\n","\n","utils_dir = None\n","if helper.is_colab:\n","    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n","else:\n","    utils_dir = os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n","\n","print(\"utils_dir:\", utils_dir)\n","\n","sys.path.append(str(utils_dir))\n","print(\"sys.path:\", sys.path)\n","import importlib\n","import health_ea_utils as heu\n","importlib.reload(heu)\n","from health_ea_utils import *\n","\n","print(\"helper.__file__:\", helper.__file__)\n","print(\"health_ea_utils.__file__:\", heu.__file__)\n"]},{"cell_type":"markdown","metadata":{"id":"20rBdRxvKUGZ"},"source":["# 1. í•™ìŠµìš© ë°ì´íƒ€ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í’€ê¸°"]},{"cell_type":"code","source":["!pip install -q kaggle\n","print(\"ë¡œë”©ì™„ë£Œ\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ch19qLmxNYIn","executionInfo":{"status":"ok","timestamp":1757601460269,"user_tz":-540,"elapsed":6278,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"0e02596a-cec0-4855-87bc-3751a426d244"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["ë¡œë”©ì™„ë£Œ\n"]}]},{"cell_type":"code","execution_count":9,"metadata":{"id":"DSwfz_YpqZ_W","outputId":"84bf9d9a-976e-4ea2-8644-bf3b10802a25","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602136489,"user_tz":-540,"elapsed":216297,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle_config_dir: /content/drive/MyDrive/\n","kaggle_code_it_data: ~/.cache/dataset/kaggle_code_it_data\n","kaggle.json ë³µì‚¬ ë° ê¶Œí•œ ì„¤ì • ì™„ë£Œ (ë‘ ê²½ë¡œ ëª¨ë‘)\n","Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\n"]},{"output_type":"stream","name":"stderr","text":["ì••ì¶• í•´ì œ ì¤‘: ai04-level1-project.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6858/6858 [00:11<00:00, 595.12file/s]\n"]},{"output_type":"stream","name":"stdout","text":["ì••ì¶• í•´ì œ ì™„ë£Œ: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n","ë‹¤ìš´ë¡œë“œ ì™„ë£Œ ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n"]}],"source":["# google drive rootì— keggle.json íŒŒì¼ í•„ìš”í•©ë‹ˆë‹¤.\n","\n","#kaggle_code_it_data = \"~/.cache/kaggle_code_it_data\" if helper.is_colab else os.path.join(Path.cwd(),'dataset', 'kaggle_code_it_data')\n","kaggle_config_dir = \"/content/drive/MyDrive/\" if helper.is_colab else os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive')\n","print(\"kaggle_config_dir:\", kaggle_config_dir)\n","kaggle_code_it_data = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\','dataset', 'kaggle_code_it_data')\n","print(\"kaggle_code_it_data:\", kaggle_code_it_data)\n","\n","import sys\n","from kaggle.api.kaggle_api_extended import KaggleApi\n","from tqdm import tqdm\n","\n","if helper.is_colab:\n","    os.makedirs('/root/.kaggle', exist_ok=True)\n","    os.makedirs('/root/.config/kaggle', exist_ok=True)\n","    !cp /content/drive/MyDrive/kaggle.json /root/.kaggle/kaggle.json\n","    !cp /content/drive/MyDrive/kaggle.json /root/.config/kaggle/kaggle.json\n","    !chmod 600 /root/.kaggle/kaggle.json\n","    !chmod 600 /root/.config/kaggle/kaggle.json\n","    print(\"kaggle.json ë³µì‚¬ ë° ê¶Œí•œ ì„¤ì • ì™„ë£Œ (ë‘ ê²½ë¡œ ëª¨ë‘)\")\n","\n","def download_ai01_level1_project():\n","    os.environ['KAGGLE_CONFIG_DIR'] = kaggle_config_dir\n","    kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","    if not os.path.exists(kaggle_path):\n","        os.makedirs(kaggle_code_it_data, exist_ok=True)\n","        print(\"Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì¤‘...\")\n","        api = KaggleApi()\n","        api.authenticate()\n","        # ì „ì²´ ì••ì¶•íŒŒì¼ ë‹¤ìš´ë¡œë“œ (í”„ë¡œê·¸ë˜ìŠ¤ ë°”ëŠ” kaggle APIì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ)\n","        api.competition_download_files('ai04-level1-project', path=kaggle_code_it_data)\n","        return os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","        print(\"Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n","    else:\n","        return kaggle_path\n","        print(\"Kaggle ë°ì´í„° ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n","\n","kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","kaggle_unzip_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip.unzip')\n","if os.path.exists(kaggle_unzip_path) is False:\n","    kaggle_path = download_ai01_level1_project()\n","    heu.unzip([kaggle_path,])\n","    kaggle_unzip_path = f\"{kaggle_path}.unzip\"\n","    print(f\"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\", kaggle_unzip_path)\n","else:\n","    kaggle_unzip_path = f\"{kaggle_path}.unzip\"\n","    print(f\"ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ë°›ì•˜ìŠµë‹ˆë‹¤.\", kaggle_unzip_path)\n","\n","root_dir = os.path.join(kaggle_unzip_path)\n","kaggle_unzip_path_test_images = os.path.join(kaggle_unzip_path, 'test_images')\n","kaggle_unzip_path_train_images = os.path.join(kaggle_unzip_path, 'train_images')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k-t1kwMyqZ_W"},"outputs":[],"source":["# heu.print_dir_tree(root=kaggle_unzip_path)"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"Qh4JvLIDKUGa","executionInfo":{"status":"ok","timestamp":1757602174568,"user_tz":-540,"elapsed":107,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def df_filename_list(root):\n","    \"\"\"\n","    root í•˜ìœ„ì˜ ëª¨ë“  .json íŒŒì¼ì— ëŒ€í•´\n","    - íŒŒì¼ëª…(í™•ì¥ì ì—†ëŠ”)\n","    - json íŒŒì¼ ê²½ë¡œ\n","    - png íŒŒì¼ ê²½ë¡œ (ë™ì¼ ê²½ë¡œ, ë™ì¼ íŒŒì¼ëª…, í™•ì¥ìë§Œ .png)\n","    ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜\n","    \"\"\"\n","    import os\n","    import pandas as pd\n","\n","    records = []\n","    for dirpath, _, filenames in os.walk(root):\n","        for fname in filenames:\n","            drug_info={\n","                'filename': None,\n","                'ext': None,\n","                'file_name': None,\n","                'path': None,\n","                'label': None,\n","                'drug0': None,\n","                'drug1': None,\n","                'drug2': None,\n","                'drug3': None,\n","            }\n","\n","            filename, ext = os.path.splitext(fname)\n","            ext = ext.lower().replace('.', '')  # í™•ì¥ìì—ì„œ . ì œê±°\n","            drug_info.update({\n","                'filename': filename,\n","                'file_name': fname,\n","                'ext': ext,\n","                'path': os.path.join(dirpath, fname),\n","            })\n","            if filename.startswith('K-'):\n","                # ì˜ˆì‹œ: K-001900-010224-016551-031705_0_2_0_2_70_000_200\n","                parts = filename.split('_')[0].split('-')\n","                if len(parts) >= 5:\n","                    drug_info.update({\n","                        'label': f'{filename.split(\"_\")[0]}',\n","                        'drug0': f'K-{parts[1]}',\n","                        'drug1': f'K-{parts[2]}',\n","                        'drug2': f'K-{parts[3]}',\n","                        'drug3': f'K-{parts[4]}',\n","                    })\n","            records.append(drug_info)\n","    return pd.DataFrame(records)\n","df_files = df_filename_list(kaggle_unzip_path)\n","df_files.sort_values(by='filename',inplace=True)\n","df_files_sort = df_files"]},{"cell_type":"markdown","metadata":{"id":"9ssg2kYkKUGb"},"source":["# 2. Yolo DataFrame"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"XqY1XACxKUGc","outputId":"917d1ede-0376-4ce1-cf20-465afd7388d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602198448,"user_tz":-540,"elapsed":18262,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["JSON ì •ë³´ ìˆ˜ì§‘ ì¤‘...\n"]},{"output_type":"stream","name":"stderr","text":["Processing Test files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 843/843 [00:00<00:00, 15300.46it/s]\n","Processing JSON files: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4526/4526 [00:14<00:00, 322.60it/s, K-003544-012247-016548-021026_0_2_0_2_75_000_200]"]},{"output_type":"stream","name":"stdout","text":["\n","=== ì²˜ë¦¬ ê²°ê³¼ ===\n","ì „ì²´ íŒŒì¼: 6858\n","ì„±ê³µ ì²˜ë¦¬: 5369\n","ì˜¤ë¥˜ íŒŒì¼: 0\n","df_new shape: (5369, 24)\n","df_drug shape: (73, 19)\n","âœ… ì»¤ë°‹ ì™„ë£Œ: 021da901baae | 2025-09-11 14:50:04 | df_codeit04_new\n","âœ… ì»¤ë°‹ ì™„ë£Œ: 81ede6b27b2e | 2025-09-11 14:50:04 | df_codeit04_drug\n","df_codeit04_new, df_codeit04_drug ì €ì¥\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# json íŒŒì¼ì„ DataFrameë¡œ ë¡œë“œ\n","df = df_files.copy()\n","def json_to_df(json_path):\n","    \"\"\"\n","    json_pathì˜ json íŒŒì¼ì„ pandas DataFrameìœ¼ë¡œ ë³€í™˜\n","    - images, annotations, categoriesë¥¼ ê°ê° DataFrameìœ¼ë¡œ ë°˜í™˜\n","    \"\"\"\n","    with open(json_path, encoding='utf-8') as f:\n","        data = json.load(f)\n","\n","    df_images = pd.DataFrame(data.get('images', []))\n","    df_annotations = pd.DataFrame(data.get('annotations', []))\n","    df_categories = pd.DataFrame(data.get('categories', []))\n","\n","    return df_images, df_annotations, df_categories\n","\n","def bbox_to_yolo(bbox, img_width, img_height):\n","    # bbox: [x, y, w, h] (COCO)\n","    if not bbox or len(bbox) < 4:\n","        return None  # ì˜¤ë¥˜ì‹œ None ë°˜í™˜\n","\n","    x, y, w, h = bbox[:4]\n","    x_center = (x + w / 2) / img_width\n","    y_center = (y + h / 2) / img_height\n","    w_norm = w / img_width\n","    h_norm = h / img_height\n","    return x_center, y_center, w_norm, h_norm\n","\n","def collect_json_info(df):\n","    \"\"\"\n","                                              filename  ext                                             file_name                                                                                                                                                                             path                         label  drug0  drug1  drug2  drug3\n","  962 K-001900-016548-019607-031705_0_2_0_2_75_000_200 json K-001900-016548-019607-031705_0_2_0_2_75_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-019607-031705_json\\K-016548\\K-001900-016548-019607-031705_0_2_0_2_75_000_200.json K-001900-016548-019607-031705 001900 016548 019607 031705\n"," 5406 K-001900-016548-019607-031705_0_2_0_2_75_000_200  png  K-001900-016548-019607-031705_0_2_0_2_75_000_200.png                                                   d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_images\\K-001900-016548-019607-031705_0_2_0_2_75_000_200.png K-001900-016548-019607-031705 001900 016548 019607 031705\n","\n","    df['ext'] jsonì„ ìˆœíšŒí•˜ë©° json_to_dfë¡œ ì •ë³´ë¥¼ ì½ê³ ,\n","    dfì— image, drug_N, width, height, bbox_x/y/w/h, yolo_x/y/w/h ì»¬ëŸ¼ì„ ì¶”ê°€.\n","    ì•½ ì •ë³´ëŠ” drug_N ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì—†ì´ df_drugì— ì €ì¥.\n","    bbox ì˜¤ë¥˜ê°€ ìˆëŠ” íŒŒì¼ì€ ì¶œë ¥í•˜ê³  ì œê±°.\n","    \"\"\"\n","    import pandas as pd\n","\n","    records = []\n","    drug_info = {}\n","    error_files = []  # ì˜¤ë¥˜ íŒŒì¼ ëª©ë¡\n","\n","    # Test ë¶„ë¥˜\n","    df_test = df[(df['ext'] == 'png') & (df['path'].str.contains('test', case=False))].copy()\n","    pbar = tqdm(df_test.iterrows(), total=len(df_test), mininterval=3, desc=\"Processing Test files\")\n","    for idx, row in pbar:\n","        field = {\n","                **row,\n","                'imgfile': row['path'],\n","                'Train' : False,\n","                'Test' : True,\n","                'drug_N': None,\n","                'width': 0,\n","                'height': 0,\n","                'bbox_x': 0,\n","                'bbox_y': 0,\n","                'bbox_w': 0,\n","                'bbox_h': 0,\n","                'yolo_x': 0.0,\n","                'yolo_y': 0.0,\n","                'yolo_w': 0.0,\n","                'yolo_h': 0.0\n","            }\n","        filename_without_ext = os.path.splitext(os.path.basename(row['path']))[0]\n","        field['filename'] = filename_without_ext\n","        records.append(field)\n","\n","    # Train ë¶„ë¥˜\n","    df_json = df[df['ext'] == 'json'].copy()\n","    df_png = df[df['ext'] == 'png'].copy()\n","    pbar = tqdm(df_json.iterrows(), total=len(df_json), mininterval=3, desc=\"Processing JSON files\")\n","    for idx, row in pbar:\n","        field = {\n","                **row,\n","                'imgfile': None,\n","                'Train' : True,\n","                'Test' : False,\n","                'drug_N': None,\n","                'width': 0,\n","                'height': 0,\n","                'bbox_x': 0,\n","                'bbox_y': 0,\n","                'bbox_w': 0,\n","                'bbox_h': 0,\n","                'yolo_x': 0.0,\n","                'yolo_y': 0.0,\n","                'yolo_w': 0.0,\n","                'yolo_h': 0.0\n","            }\n","        filename = row['filename']\n","        json_path = row['path']\n","\n","        try:\n","            df_images, df_annotations, df_categories = json_to_df(json_path)\n","        except Exception as e:\n","            print(f\"JSON íŒŒì‹± ì˜¤ë¥˜ - íŒŒì¼: {filename}, ì˜¤ë¥˜: {e}\")\n","            error_files.append(filename)\n","            continue\n","\n","        if df_images.empty or df_annotations.empty:\n","            print(f\"ë°ì´í„° ë¶€ì¡± - íŒŒì¼: {filename} (images: {len(df_images)}, annotations: {len(df_annotations)})\")\n","            error_files.append(filename)\n","            continue\n","\n","        img_row = df_images.iloc[0]\n","        ann_row = df_annotations.iloc[0]\n","        cat_row = df_categories.iloc[0] if not df_categories.empty else {}\n","\n","        png_match = df_png[df_png['file_name'] == img_row.get('file_name', None)]\n","        if png_match.empty:\n","            pbar.set_postfix_str(f\"ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ - íŒŒì¼: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        field['imgfile'] = png_match['path'].values[0]  # pathê°€ ì—¬ëŸ¬ ê°œë©´ ì²« ë²ˆì§¸ ê°’ ì‚¬ìš©\n","        filename_without_ext = os.path.splitext(os.path.basename(png_match['path'].iloc[0]))[0]\n","        field['filename'] = filename_without_ext\n","\n","        if pd.isna(field['imgfile']) | (field['imgfile'] is None):\n","            pbar.set_postfix_str(f\"ì´ë¯¸ì§€ íŒŒì¼ëª… ëˆ„ë½ - íŒŒì¼: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        # bbox ê²€ì¦\n","        bbox = ann_row.get('bbox', [])\n","        if not bbox or len(bbox) < 4:\n","            print(f\"bbox ì˜¤ë¥˜ - íŒŒì¼: {filename}, bbox: {bbox}\")\n","            error_files.append(filename)\n","            continue\n","\n","        # YOLO bbox ê³„ì‚°\n","        yolo_result = bbox_to_yolo(bbox, img_row['width'], img_row['height'])\n","        if yolo_result is None:\n","            print(f\"YOLO ë³€í™˜ ì˜¤ë¥˜ - íŒŒì¼: {filename}\")\n","            error_files.append(filename)\n","            continue\n","\n","        x_center, y_center, w_norm, h_norm = yolo_result\n","\n","        # ê¸°ì¡´ df rowì— ì •ë³´ ì¶”ê°€\n","        field.update({\n","            'drug_N': img_row.get('drug_N'),\n","            'width': img_row.get('width'),\n","            'height': img_row.get('height'),\n","            'bbox_x': bbox[0],\n","            'bbox_y': bbox[1],\n","            'bbox_w': bbox[2],\n","            'bbox_h': bbox[3],\n","            'yolo_x': x_center,\n","            'yolo_y': y_center,\n","            'yolo_w': w_norm,\n","            'yolo_h': h_norm\n","        })\n","        records.append(field)\n","\n","        # ì•½ ì •ë³´ dict (ì¤‘ë³µ ì œê±°)\n","        drug_N = img_row.get('drug_N')\n","        if drug_N and drug_N not in drug_info:\n","            drug_info[drug_N] = {\n","                'drug_N': drug_N,\n","                'drug_S': img_row.get('drug_S'),\n","                'dl_name': img_row.get('dl_name'),\n","                'dl_name_en': img_row.get('dl_name_en'),\n","                'img_key': img_row.get('img_key'),\n","                'dl_material': img_row.get('dl_material'),\n","                'dl_material_en': img_row.get('dl_material_en'),\n","                'dl_custom_shape': img_row.get('dl_custom_shape'),\n","                'dl_company': img_row.get('dl_company'),\n","                'dl_company_en': img_row.get('dl_company_en'),\n","                'di_class_no': img_row.get('di_class_no'),\n","                'di_etc_otc_code': img_row.get('di_etc_otc_code'),\n","                'di_edi_code': img_row.get('di_edi_code'),\n","                'chart': img_row.get('chart'),\n","                'drug_shape': img_row.get('drug_shape'),\n","                'form_code_name': img_row.get('form_code_name'),\n","                'supercategory': cat_row.get('supercategory', ''),\n","                'name': cat_row.get('name', '')\n","            }\n","        if idx % 100 == 0:\n","            pbar.set_postfix_str(filename)\n","\n","    print(f\"\\n=== ì²˜ë¦¬ ê²°ê³¼ ===\")\n","    print(f\"ì „ì²´ íŒŒì¼: {len(df)}\")\n","    print(f\"ì„±ê³µ ì²˜ë¦¬: {len(records)}\")\n","    print(f\"ì˜¤ë¥˜ íŒŒì¼: {len(error_files)}\")\n","    if error_files:\n","        print(f\"ì˜¤ë¥˜ íŒŒì¼ ëª©ë¡ (ì²˜ìŒ 10ê°œ): {error_files[:10]}\")\n","\n","    df_new = pd.DataFrame(records)\n","    df_drug = pd.DataFrame(list(drug_info.values()))\n","\n","    train_df = df_new[df_new['Train'] == True]\n","    drug_classes = {drug_N: idx+1 for idx, drug_N in enumerate(sorted(train_df['drug_N'].unique()))}\n","\n","    df_new['class_id'] = train_df['drug_N'].map(drug_classes).fillna(0).astype(int)\n","    df_drug['class_id'] = df_drug['drug_N'].map(drug_classes).fillna(0).astype(int)\n","\n","    # df_drug = pd.DataFrame(list(drug_info.values()))\n","    # drug_classes = {drug_N: idx+1 for idx, drug_N in enumerate(sorted(df_new['drug_N'].unique()))}\n","    # df_new['class_id'] = df_new['drug_N'].map(drug_classes).fillna(0).astype(int)\n","    # df_drug['class_id'] = df_drug['drug_N'].map(drug_classes).fillna(0).astype(int)\n","\n","    return df_new, df_drug, drug_classes\n","\n","# os.path.join(kaggle_unzip_path, 'train_images')\n","def create_yolo_dataset(df_files, ignore=True):\n","    df = helper.pd_checkout(\"df_codeit04_new\", commit_dir=drive_root())\n","    df_drug = helper.pd_checkout(\"df_codeit04_drug\", commit_dir=drive_root())\n","    if df.empty or df_drug.empty or ignore:\n","        from datetime import datetime\n","        print(\"JSON ì •ë³´ ìˆ˜ì§‘ ì¤‘...\")\n","        # ì‹¤í–‰\n","        df, df_drug, _ = collect_json_info(df_files)\n","        print('df_new shape:', df.shape)\n","        print('df_drug shape:', df_drug.shape)\n","\n","        helper.pd_commit(df, \"df_codeit04_new\", commit_dir=drive_root())\n","        helper.pd_commit(df_drug, \"df_codeit04_drug\", commit_dir=drive_root())\n","\n","        print(\"df_codeit04_new, df_codeit04_drug ì €ì¥\")\n","    else:\n","        print(\"ì´ë¯¸ df_codeit04_new, df_codeit04_drugê°€ ì¡´ì¬í•¨\")\n","\n","    df.sort_values(by='filename',inplace=True)\n","    df_drug.sort_values(by='drug_N',inplace=True)\n","    return df, df_drug\n","\n","df_train_test, df_drug = create_yolo_dataset(df_files = df_files, ignore=True)\n","drug_classes = dict(zip(df_drug['drug_N'], df_drug['class_id']))\n","drug_classes_idx = dict(zip(df_drug['class_id'], df_drug['drug_N']))\n"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"jVOOXbUfKUGe","executionInfo":{"status":"ok","timestamp":1757602227246,"user_tz":-540,"elapsed":94,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["# dfë¥¼ class_idì˜ ê°œìˆ˜ ë³„ë¡œ ì •ë ¬í•˜ê³ \n","# Train = Falseì´ê³  Test = False ì´ë©´ Validation ë¡œ í•˜ì\n","# Test = True ì´ë©´ Test ë¡œ í•˜ì\n","# Validationì„ Trainì—ì„œ ë¨ë¤í•˜ê²Œ 0.3 ì •ë„ Train=False ë¡œ í•˜ì\n","df = df_train_test.copy()\n","\n","# 1. class_idë³„ë¡œ ì •ë ¬\n","df.sort_values('class_id', inplace=True)\n","\n","# 2. Validation ì…‹ ì§€ì • (Train=True & Test=False ì¤‘ì—ì„œ classë³„ë¡œ 30% ëœë¤ ì„ íƒ)\n","for class_id in df['class_id'].unique():\n","    idxs = df[(df['class_id'] == class_id) & (df['Train'] == True) & (df['Test'] == False)].index\n","    n_val = max(1, int(len(idxs) * 0.3)) if len(idxs) > 0 else 0\n","    if n_val > 0:\n","        val_idxs = np.random.choice(idxs, n_val, replace=False)\n","        df.loc[val_idxs, 'Train'] = False  # Validationìœ¼ë¡œ ë³€ê²½\n","\n","# 3. set_type ì»¬ëŸ¼ ì§€ì •\n","df['set_type'] = np.where(df['Test'] == True, 'Test',\n","                  np.where(df['Train'] == True, 'Train', 'Validation'))\n","\n","df_train_val_test = df.copy()\n"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"li81c7DVKUGg","outputId":"ed85d1fc-ee39-4d12-f442-ea9ee7acef17","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602233081,"user_tz":-540,"elapsed":2620,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Creating YOLO dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5369/5369 [00:01<00:00, 3022.53it/s, K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]\n"]},{"output_type":"stream","name":"stdout","text":["âœ… ì»¤ë°‹ ì™„ë£Œ: 09b5fc2fcb89 | 2025-09-11 14:50:39 | df_codeit04_yolo\n"]}],"source":["def create_yolo_dataset(df, yolo_dataset_path):\n","    \"\"\"\n","                                              filename  ext                                             file_name                                                                                                                                                                             path                         label    drug0    drug1    drug2    drug3 Train  Test   drug_N width height bbox_x bbox_y bbox_w bbox_h yolo_x yolo_y yolo_w yolo_h class_id   set_type\n","  872 K-001900-016548-018110-027926_0_2_0_2_75_000_200 json K-001900-016548-018110-027926_0_2_0_2_75_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-018110-027926_json\\K-001900\\K-001900-016548-018110-027926_0_2_0_2_75_000_200.json K-001900-016548-018110-027926 K-001900 K-016548 K-018110 K-027926 False False K-001900   976   1280    142    241    200    127  0.248 0.2379 0.2049 0.0992        1 Validation\n","  870 K-001900-016548-018110-027926_0_2_0_2_70_000_200 json K-001900-016548-018110-027926_0_2_0_2_70_000_200.json d:\\dataset\\kaggle_code_it_data\\ai04-level1-project.zip.unzip\\train_annotations\\K-001900-016548-018110-027926_json\\K-001900\\K-001900-016548-018110-027926_0_2_0_2_70_000_200.json K-001900-016548-018110-027926 K-001900 K-016548 K-018110 K-027926 False False K-001900   976   1280    630    894    211    133 0.7536 0.7504 0.2162 0.1039        1 Validation\n","\n","dataset/\n","â”œâ”€â”€ images/\n","â”‚   â”œâ”€â”€ train/\n","â”‚   â”‚   â”œâ”€â”€ image1.jpg\n","â”‚   â”‚   â”œâ”€â”€ image2.jpg\n","â”‚   â”‚   â””â”€â”€ ...\n","â”‚   â”œâ”€â”€ val/\n","â”‚   â”‚   â”œâ”€â”€ val_image1.jpg\n","â”‚   â”‚   â””â”€â”€ ...\n","â”‚   â””â”€â”€ test/ (ì„ íƒì )\n","â””â”€â”€ labels/\n","    â”œâ”€â”€ train/\n","    â”‚   â”œâ”€â”€ image1.txt\n","    â”‚   â”œâ”€â”€ image2.txt\n","    â”‚   â””â”€â”€ ...\n","    â”œâ”€â”€ val/\n","    â”‚   â”œâ”€â”€ val_image1.txt\n","    â”‚   â””â”€â”€ ...\n","    â””â”€â”€ test/ (ì„ íƒì )\n","\n","    DataFrame df_convert_yoloë¥¼ ë§Œë“¤ê³  dfë¥¼ ë³µì‚¬í•˜ê³  to yolo_image_train, yolo_image_val, yolo_label_train, yolo_label_valë¥¼ ë§Œë“ ë‹¤.\n","    dfì˜ Train ì»¬ëŸ¼ì„ ì°¸ê³  í•˜ë©´ ëœë‹¤.\n","    df_convert_yoloë¥¼ yolo_dataset_pathì— ì €ì¥í•œë‹¤. (ì›ë³µë“±ì— ì°¸ê³  í•  ìˆ˜ ìˆì„ ê²ƒì´ë‹¤.)\n","\n","    ë§Œë“¤ì–´ì§„ df_convert_yolo ë¥¼ ì´ìš©í•˜ì—¬ imagesë¥¼ yolo_image_train, yolo_image_valì— ì´ë™ì‹œí‚¨ë‹¤.\n","    ì „ì²´ì ì¸ ë°ì´íƒ€ ìš©ëŸ‰ì´ í¼ìœ¼ë¡œ íŒŒì¼ì„ ì´ë™ì‹œí‚¤ëŠ” ë°©ì‹ìœ¼ë¡œ í•œë‹¤.\n","\n","    \"\"\"\n","\n","    images_train_dir = os.path.join(yolo_dataset_path, 'images', 'train')\n","    images_val_dir = os.path.join(yolo_dataset_path, 'images', 'val')\n","    images_test_dir = os.path.join(yolo_dataset_path, 'images', 'test')\n","    labels_train_dir = os.path.join(yolo_dataset_path, 'labels', 'train')\n","    labels_val_dir = os.path.join(yolo_dataset_path, 'labels', 'val')\n","    labels_test_dir = os.path.join(yolo_dataset_path, 'labels', 'test')\n","\n","    df.sort_values('filename', inplace=True)\n","    df = df.reset_index(drop=True)\n","\n","    pbar = tqdm(df.iterrows(), total=len(df), mininterval=3, desc=\"Creating YOLO dataset\")\n","    for idx, row in pbar:\n","        set_type = row.get('set_type', 'Unknown')\n","        img_dst, label_dst = None, None\n","\n","        filename = row['filename']\n","        label_name = row['label']\n","        # íŒŒì¼ëª…ì— _ìˆœì„œ ë¶™ì´ê¸°\n","        base_img_name = f\"{filename}.png\"\n","        base_label_name = f\"{filename}.txt\"\n","\n","        if set_type == 'Train':\n","            img_dst = os.path.join(images_train_dir, base_img_name)\n","            label_dst = os.path.join(labels_train_dir, base_label_name)\n","        elif set_type == 'Validation':\n","            img_dst = os.path.join(images_val_dir, base_img_name)\n","            label_dst = os.path.join(labels_val_dir, base_label_name)\n","        elif set_type == 'Test':\n","            img_dst = os.path.join(images_test_dir, base_img_name)\n","            label_dst = os.path.join(labels_test_dir, base_label_name)\n","        else:\n","            continue\n","\n","        df.loc[idx, 'yolo_image'] = img_dst\n","        df.loc[idx, 'yolo_label'] = label_dst\n","\n","        if idx % 100 == 0:\n","            pbar.set_postfix_str(base_img_name)\n","\n","    return df\n","\n","def create_yolo_df(yolo_path, ignore=True):\n","    df = df_train_val_test.copy()\n","    df_yolo = helper.pd_checkout(\"df_codeit04_yolo\", commit_dir=drive_root())\n","    if df_yolo.empty | ignore:\n","        df_yolo = create_yolo_dataset(df, yolo_path)\n","        helper.pd_commit(df_yolo, \"df_codeit04_yolo\", commit_dir=drive_root())\n","    else:\n","        print(\"df_yolo ë¡œë“œë¨\")\n","    return df_yolo, yolo_path\n","\n","yolo_path  = os.path.join(root_dir, \"yolo\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)"]},{"cell_type":"markdown","metadata":{"id":"J1JkMr2VKUGg"},"source":["# 3. Image to Yolo File\n","- resize Iamge 640 x 480"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"yaLn4RYXKUGg","executionInfo":{"status":"ok","timestamp":1757602237157,"user_tz":-540,"elapsed":121,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["import cv2\n","import numpy as np\n","from sklearn.cluster import KMeans\n","\n","def create_rounded_mask(width, height, radius):\n","    \"\"\"OpenCVë¥¼ ì‚¬ìš©í•œ ë‘¥ê·¼ ë„¤ëª¨ ë§ˆìŠ¤í¬ ìƒì„±\"\"\"\n","    mask = np.zeros((height, width), dtype=np.uint8)\n","\n","    if radius <= 0:\n","        mask[:, :] = 255\n","        return mask\n","\n","    # ë°˜ì§€ë¦„ì´ ë„ˆë¬´ í¬ë©´ ì¡°ì •\n","    radius = min(radius, min(width, height) // 2)\n","\n","    # ë‘¥ê·¼ ì‚¬ê°í˜• ê·¸ë¦¬ê¸°\n","    # ì¤‘ì•™ ì‚¬ê°í˜•ë“¤\n","    cv2.rectangle(mask, (radius, 0), (width - radius, height), 255, -1)\n","    cv2.rectangle(mask, (0, radius), (width, height - radius), 255, -1)\n","\n","    # ë„¤ ëª¨ì„œë¦¬ì— ì› ê·¸ë¦¬ê¸°\n","    cv2.circle(mask, (radius, radius), radius, 255, -1)  # ì¢Œìƒë‹¨\n","    cv2.circle(mask, (width - radius, radius), radius, 255, -1)  # ìš°ìƒë‹¨\n","    cv2.circle(mask, (radius, height - radius), radius, 255, -1)  # ì¢Œí•˜ë‹¨\n","    cv2.circle(mask, (width - radius, height - radius), radius, 255, -1)  # ìš°í•˜ë‹¨\n","\n","    return mask\n","\n","def get_combined_rect_with_margin(bboxes, img_shape, margin=20):\n","    \"\"\"\n","    ì—¬ëŸ¬ ê°ì²´ì˜ bboxë¥¼ í•©ì¹œ ì „ì²´ rectë¥¼ ê³„ì‚°í•˜ê³  ë§ˆì§„ì„ ì¶”ê°€\n","\n","    Args:\n","        bboxes: ê°ì²´ë“¤ì˜ bbox ë¦¬ìŠ¤íŠ¸ [(x, y, w, h), ...]\n","        img_shape: ì´ë¯¸ì§€ í¬ê¸° (height, width)\n","        margin: ì¶”ê°€í•  ë§ˆì§„ í¬ê¸°\n","\n","    Returns:\n","        combined_rect: (x, y, w, h) í˜•íƒœì˜ í•©ì³ì§„ rect\n","    \"\"\"\n","    if not bboxes:\n","        return None\n","\n","    h, w = img_shape[:2]\n","\n","    # ëª¨ë“  bboxì˜ ìµœì†Œ/ìµœëŒ€ ì¢Œí‘œ ê³„ì‚°\n","    min_x = min(bbox[0] for bbox in bboxes)\n","    min_y = min(bbox[1] for bbox in bboxes)\n","    max_x = max(bbox[0] + bbox[2] for bbox in bboxes)\n","    max_y = max(bbox[1] + bbox[3] for bbox in bboxes)\n","\n","    # ë§ˆì§„ ì¶”ê°€\n","    min_x = max(0, min_x - margin)\n","    min_y = max(0, min_y - margin)\n","    max_x = min(w, max_x + margin)\n","    max_y = min(h, max_y + margin)\n","\n","    return (min_x, min_y, max_x - min_x, max_y - min_y)\n","\n","def extract_background_color_advanced(img, combined_rect, corner_radius=20, sample_size=1000):\n","    \"\"\"\n","    ë‘¥ê·¼ ëª¨ì„œë¦¬ë¡œ ì˜ë¼ë‚¸ ê°ì²´ ì˜ì—­ì„ ì œì™¸í•œ ë°°ê²½ì—ì„œ í‰ê·  ìƒ‰ìƒ ì¶”ì¶œ\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        combined_rect: ê°ì²´ë“¤ì˜ í•©ì³ì§„ rect (x, y, w, h)\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","        sample_size: ë°°ê²½ìƒ‰ ì¶”ì¶œì„ ìœ„í•œ ìƒ˜í”Œ í”½ì…€ ìˆ˜\n","\n","    Returns:\n","        bg_color: ë°°ê²½ìƒ‰ (B, G, R)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    # ì „ì²´ ë§ˆìŠ¤í¬ (ë°°ê²½ = 255, ê°ì²´ = 0)\n","    mask = np.ones((h, w), dtype=np.uint8) * 255\n","\n","    if combined_rect is not None:\n","        x, y, rect_w, rect_h = map(int, combined_rect)\n","\n","        # ë‘¥ê·¼ ëª¨ì„œë¦¬ ë§ˆìŠ¤í¬ ìƒì„±\n","        rounded_mask = create_rounded_mask(rect_w, rect_h, corner_radius)\n","\n","        # ê°ì²´ ì˜ì—­ì— ë‘¥ê·¼ ë§ˆìŠ¤í¬ ì ìš© (í•´ë‹¹ ì˜ì—­ì„ 0ìœ¼ë¡œ ì„¤ì •)\n","        if (x + rect_w <= w and y + rect_h <= h and\n","            x >= 0 and y >= 0 and rect_w > 0 and rect_h > 0):\n","            # ë‘¥ê·¼ ë§ˆìŠ¤í¬ë¥¼ ì´ìš©í•´ ê°ì²´ ì˜ì—­ ì œê±°\n","            mask[y:y+rect_h, x:x+rect_w] = rounded_mask\n","\n","    # ë°°ê²½ ì˜ì—­ í”½ì…€ ì¶”ì¶œ\n","    background_pixels = img[mask == 255]\n","\n","    if len(background_pixels) == 0:\n","        # ë°°ê²½ì´ ì—†ìœ¼ë©´ ImageNet í‰ê· ê°’ ì‚¬ìš©\n","        return np.array([123, 117, 104], dtype=np.uint8)\n","\n","    # ë„ˆë¬´ ë§ì€ í”½ì…€ì´ ìˆìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§\n","    if len(background_pixels) > sample_size:\n","        indices = np.random.choice(len(background_pixels), sample_size, replace=False)\n","        background_pixels = background_pixels[indices]\n","\n","    # K-meansë¥¼ ì‚¬ìš©í•´ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ\n","    try:\n","        kmeans = KMeans(n_clusters=min(3, len(background_pixels)), random_state=42, n_init=10)\n","        kmeans.fit(background_pixels)\n","\n","        # ê°€ì¥ ë§ì€ í”½ì…€ì„ ê°€ì§„ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ìƒ‰ì„ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì„ íƒ\n","        labels = kmeans.labels_\n","        cluster_counts = np.bincount(labels)\n","        dominant_cluster = np.argmax(cluster_counts)\n","        bg_color = kmeans.cluster_centers_[dominant_cluster].astype(np.uint8)\n","\n","    except:\n","        # K-means ì‹¤íŒ¨ì‹œ í‰ê· ê°’ ì‚¬ìš©\n","        bg_color = np.mean(background_pixels, axis=0).astype(np.uint8)\n","\n","    return bg_color\n","\n","def create_cleaned_image_with_rounded_crop(img, combined_rect, bg_color, corner_radius=20):\n","    \"\"\"\n","    ë‘¥ê·¼ ëª¨ì„œë¦¬ë¡œ ì˜ë¼ë‚¸ ê°ì²´ ì˜ì—­ì„ ì œì™¸í•˜ê³  ë°°ê²½ìƒ‰ìœ¼ë¡œ ì±„ìš´ ì´ë¯¸ì§€ ìƒì„±\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        combined_rect: ê°ì²´ë“¤ì˜ í•©ì³ì§„ rect (x, y, w, h)\n","        bg_color: ë°°ê²½ìƒ‰\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","\n","    Returns:\n","        cleaned_img: ì •ë¦¬ëœ ì´ë¯¸ì§€\n","    \"\"\"\n","    h, w = img.shape[:2]\n","    cleaned_img = np.full_like(img, bg_color)\n","\n","    if combined_rect is not None:\n","        x, y, rect_w, rect_h = map(int, combined_rect)\n","\n","        # ì•ˆì „ ì²´í¬\n","        if (x + rect_w <= w and y + rect_h <= h and\n","            x >= 0 and y >= 0 and rect_w > 0 and rect_h > 0):\n","\n","            # ë‘¥ê·¼ ëª¨ì„œë¦¬ ë§ˆìŠ¤í¬ ìƒì„±\n","            rounded_mask = create_rounded_mask(rect_w, rect_h, corner_radius)\n","\n","            # ê°ì²´ ì˜ì—­ë§Œ ë³µì‚¬ (ë‘¥ê·¼ ëª¨ì„œë¦¬ ì ìš©)\n","            roi = img[y:y+rect_h, x:x+rect_w]\n","\n","            # ë§ˆìŠ¤í¬ê°€ 255ì¸ ë¶€ë¶„ë§Œ ë³µì‚¬\n","            mask_3ch = cv2.cvtColor(rounded_mask, cv2.COLOR_GRAY2BGR) / 255.0\n","\n","            cleaned_roi = (roi * mask_3ch +\n","                          bg_color.reshape(1, 1, 3) * (1 - mask_3ch)).astype(np.uint8)\n","\n","            cleaned_img[y:y+rect_h, x:x+rect_w] = cleaned_roi\n","\n","    return cleaned_img\n","\n","def resize_with_aspect_ratio_and_bg_advanced(img, target_size=(640, 480), bg_color=None):\n","    \"\"\"\n","    ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆí•˜ê³ , ë°°ê²½ìƒ‰ìœ¼ë¡œ íŒ¨ë”© ì¶”ê°€\n","    \"\"\"\n","    if bg_color is None:\n","        bg_color = [0, 0, 0]\n","\n","    h, w = img.shape[:2]\n","    target_w, target_h = target_size\n","\n","    # ìŠ¤ì¼€ì¼ ê³„ì‚° (ë¹„ìœ¨ ìœ ì§€)\n","    scale = min(target_w / w, target_h / h)\n","    new_w, new_h = int(w * scale), int(h * scale)\n","\n","    # ë¦¬ì‚¬ì´ì¦ˆ\n","    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n","\n","    # ë°°ê²½ìƒ‰ìœ¼ë¡œ íŒ¨ë”©ëœ ìº”ë²„ìŠ¤ ìƒì„±\n","    result = np.full((target_h, target_w, 3), bg_color, dtype=np.uint8)\n","\n","    # ì¤‘ì•™ì— ë°°ì¹˜\n","    x_offset = (target_w - new_w) // 2\n","    y_offset = (target_h - new_h) // 2\n","    result[y_offset:y_offset+new_h, x_offset:x_offset+new_w] = resized\n","\n","    return result\n"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"U380f5XQKUGk","executionInfo":{"status":"ok","timestamp":1757602243246,"user_tz":-540,"elapsed":11,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_individual_object_masks(img, bboxes, corner_radius=20):\n","    \"\"\"\n","    ê° ê°ì²´ë³„ë¡œ ê°œë³„ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        bboxes: ê°ì²´ë“¤ì˜ bbox ë¦¬ìŠ¤íŠ¸ [(x, y, w, h), ...]\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","\n","    Returns:\n","        object_masks: ê° ê°ì²´ì˜ ë§ˆìŠ¤í¬ ë¦¬ìŠ¤íŠ¸\n","        combined_mask: ëª¨ë“  ê°ì²´ë¥¼ í•©ì¹œ ë§ˆìŠ¤í¬\n","    \"\"\"\n","    h, w = img.shape[:2]\n","    object_masks = []\n","    combined_mask = np.zeros((h, w), dtype=np.uint8)\n","\n","    for bbox in bboxes:\n","        x, y, bbox_w, bbox_h = map(int, bbox)\n","\n","        # ì•ˆì „ ì²´í¬\n","        if (x + bbox_w <= w and y + bbox_h <= h and\n","            x >= 0 and y >= 0 and bbox_w > 0 and bbox_h > 0):\n","\n","            # ê°œë³„ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±\n","            object_mask = np.zeros((h, w), dtype=np.uint8)\n","\n","            # ë‘¥ê·¼ ëª¨ì„œë¦¬ ë§ˆìŠ¤í¬ ìƒì„±\n","            rounded_mask = create_rounded_mask(bbox_w, bbox_h, corner_radius)\n","\n","            # í•´ë‹¹ ìœ„ì¹˜ì— ë§ˆìŠ¤í¬ ì ìš©\n","            object_mask[y:y+bbox_h, x:x+bbox_w] = rounded_mask\n","\n","            object_masks.append(object_mask)\n","\n","            # ì „ì²´ ë§ˆìŠ¤í¬ì— ì¶”ê°€ (OR ì—°ì‚°)\n","            combined_mask = cv2.bitwise_or(combined_mask, object_mask)\n","\n","    return object_masks, combined_mask"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"wSwWCB9GKUGk","executionInfo":{"status":"ok","timestamp":1757602245179,"user_tz":-540,"elapsed":11,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["\n","def create_cleaned_image_with_individual_objects(img, bboxes, bg_color, corner_radius=20):\n","    \"\"\"\n","    ê°œë³„ ê°ì²´ë“¤ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë°°ê²½ìƒ‰ìœ¼ë¡œ ì±„ìš´ ì´ë¯¸ì§€ ìƒì„±\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        bboxes: ë¼ë²¨ë§ëœ ê°ì²´ë“¤ì˜ bbox ë¦¬ìŠ¤íŠ¸ [(x, y, w, h), ...]\n","        bg_color: ë°°ê²½ìƒ‰\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","\n","    Returns:\n","        cleaned_img: ì •ë¦¬ëœ ì´ë¯¸ì§€ (ë¼ë²¨ë§ëœ ê°ì²´ë§Œ ìœ ì§€)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    # ë°°ê²½ìƒ‰ìœ¼ë¡œ ì±„ìš´ ìº”ë²„ìŠ¤ ìƒì„±\n","    cleaned_img = np.full_like(img, bg_color)\n","\n","    if not bboxes:\n","        return cleaned_img\n","\n","    # ê° ê°ì²´ë³„ ë§ˆìŠ¤í¬ ìƒì„±\n","    object_masks, combined_mask = create_individual_object_masks(img, bboxes, corner_radius)\n","\n","    # ê° ê°ì²´ë¥¼ ê°œë³„ì ìœ¼ë¡œ ë³µì‚¬\n","    for bbox, object_mask in zip(bboxes, object_masks):\n","        x, y, bbox_w, bbox_h = map(int, bbox)\n","\n","        # ì•ˆì „ ì²´í¬\n","        if (x + bbox_w <= w and y + bbox_h <= h and\n","            x >= 0 and y >= 0 and bbox_w > 0 and bbox_h > 0):\n","\n","            # í•´ë‹¹ ì˜ì—­ì˜ ë§ˆìŠ¤í¬ì™€ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•´ ê°ì²´ë§Œ ì¶”ì¶œ\n","            roi_mask = object_mask[y:y+bbox_h, x:x+bbox_w]\n","            roi_img = img[y:y+bbox_h, x:x+bbox_w]\n","            roi_bg = np.full_like(roi_img, bg_color)\n","\n","            # ë§ˆìŠ¤í¬ ì ìš© (ê°ì²´ ë¶€ë¶„ë§Œ ì›ë³¸, ë‚˜ë¨¸ì§€ëŠ” ë°°ê²½ìƒ‰)\n","            mask_3ch = cv2.cvtColor(roi_mask, cv2.COLOR_GRAY2BGR) / 255.0\n","            blended_roi = (roi_img * mask_3ch + roi_bg * (1 - mask_3ch)).astype(np.uint8)\n","\n","            # ì •ë¦¬ëœ ì´ë¯¸ì§€ì— ë³µì‚¬\n","            cleaned_img[y:y+bbox_h, x:x+bbox_w] = blended_roi\n","\n","    return cleaned_img\n"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"lI53cXAEKUGl","executionInfo":{"status":"ok","timestamp":1757602246625,"user_tz":-540,"elapsed":21,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["\n","def extract_background_color_from_unlabeled_areas(img, bboxes, corner_radius=20, sample_size=1000):\n","    \"\"\"\n","    ë¼ë²¨ë§ëœ ê°ì²´ë“¤ì„ ì œì™¸í•œ ì˜ì—­ì—ì„œ ë°°ê²½ìƒ‰ ì¶”ì¶œ\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        bboxes: ë¼ë²¨ë§ëœ ê°ì²´ë“¤ì˜ bbox ë¦¬ìŠ¤íŠ¸\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","        sample_size: ë°°ê²½ìƒ‰ ì¶”ì¶œì„ ìœ„í•œ ìƒ˜í”Œ í”½ì…€ ìˆ˜\n","\n","    Returns:\n","        bg_color: ë°°ê²½ìƒ‰ (B, G, R)\n","    \"\"\"\n","    h, w = img.shape[:2]\n","\n","    if not bboxes:\n","        # bboxê°€ ì—†ìœ¼ë©´ ì „ì²´ ì´ë¯¸ì§€ì—ì„œ í‰ê·  ì¶”ì¶œ\n","        return np.mean(img.reshape(-1, 3), axis=0).astype(np.uint8)\n","\n","    # ë¼ë²¨ë§ëœ ê°ì²´ë“¤ì˜ ë§ˆìŠ¤í¬ ìƒì„±\n","    _, combined_mask = create_individual_object_masks(img, bboxes, corner_radius)\n","\n","    # ë°°ê²½ ë§ˆìŠ¤í¬ (ë¼ë²¨ë§ëœ ê°ì²´ê°€ ì•„ë‹Œ ì˜ì—­)\n","    background_mask = cv2.bitwise_not(combined_mask)\n","\n","    # ë°°ê²½ ì˜ì—­ í”½ì…€ ì¶”ì¶œ\n","    background_pixels = img[background_mask == 255]\n","\n","    if len(background_pixels) == 0:\n","        # ë°°ê²½ì´ ì—†ìœ¼ë©´ ImageNet í‰ê· ê°’ ì‚¬ìš©\n","        return np.array([123, 117, 104], dtype=np.uint8)\n","\n","    # ë„ˆë¬´ ë§ì€ í”½ì…€ì´ ìˆìœ¼ë©´ ëœë¤ ìƒ˜í”Œë§\n","    if len(background_pixels) > sample_size:\n","        indices = np.random.choice(len(background_pixels), sample_size, replace=False)\n","        background_pixels = background_pixels[indices]\n","\n","    # K-meansë¥¼ ì‚¬ìš©í•´ ì£¼ìš” ìƒ‰ìƒ ì¶”ì¶œ\n","    try:\n","        kmeans = KMeans(n_clusters=min(3, len(background_pixels)), random_state=42, n_init=10)\n","        kmeans.fit(background_pixels)\n","\n","        # ê°€ì¥ ë§ì€ í”½ì…€ì„ ê°€ì§„ í´ëŸ¬ìŠ¤í„°ì˜ ì¤‘ì‹¬ìƒ‰ì„ ë°°ê²½ìƒ‰ìœ¼ë¡œ ì„ íƒ\n","        labels = kmeans.labels_\n","        cluster_counts = np.bincount(labels)\n","        dominant_cluster = np.argmax(cluster_counts)\n","        bg_color = kmeans.cluster_centers_[dominant_cluster].astype(np.uint8)\n","\n","    except:\n","        # K-means ì‹¤íŒ¨ì‹œ í‰ê· ê°’ ì‚¬ìš©\n","        bg_color = np.mean(background_pixels, axis=0).astype(np.uint8)\n","\n","    return bg_color"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"KHPKMB_GKUGl","executionInfo":{"status":"ok","timestamp":1757602247789,"user_tz":-540,"elapsed":5,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def resize_with_aspect_ratio_simple(img, target_size):\n","    \"\"\"\n","    ë¹„ìœ¨ì„ ìœ ì§€í•˜ë©° ì´ë¯¸ì§€ë¥¼ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³  ImageNet í‰ê· ê°’ìœ¼ë¡œ íŒ¨ë”©\n","\n","    Args:\n","        img: ì›ë³¸ ì´ë¯¸ì§€\n","        target_size: ëª©í‘œ í¬ê¸° (width, height)\n","\n","    Returns:\n","        resized_img: ë¦¬ì‚¬ì´ì¦ˆëœ ì´ë¯¸ì§€\n","    \"\"\"\n","    target_w, target_h = target_size\n","    h, w = img.shape[:2]\n","\n","    # ë¹„ìœ¨ ê³„ì‚°\n","    scale = min(target_w / w, target_h / h)\n","\n","    # ìƒˆë¡œìš´ í¬ê¸° ê³„ì‚°\n","    new_w = int(w * scale)\n","    new_h = int(h * scale)\n","\n","    # ë¦¬ì‚¬ì´ì¦ˆ\n","    resized = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n","\n","    # ImageNet í‰ê· ê°’ìœ¼ë¡œ ë°°ê²½ ìƒì„± (BGR ìˆœì„œ)\n","    imagenet_mean = [103.939, 116.779, 123.68]  # BGR ìˆœì„œ\n","    result = np.full((target_h, target_w, 3), imagenet_mean, dtype=np.uint8)\n","\n","    # ì¤‘ì•™ ìœ„ì¹˜ ê³„ì‚°\n","    start_x = (target_w - new_w) // 2\n","    start_y = (target_h - new_h) // 2\n","\n","    # ì´ë¯¸ì§€ ë°°ì¹˜\n","    result[start_y:start_y + new_h, start_x:start_x + new_w] = resized\n","\n","    return result"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"-0ApQERPKUGl","executionInfo":{"status":"ok","timestamp":1757602249434,"user_tz":-540,"elapsed":24,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[],"source":["def create_yolo_file(\n","    df_yolo,\n","    yolo_dataset_path,\n","    image_size=(640, 640),\n","    object_margin=30,\n","    corner_radius=20,\n","    ignore=True,\n","    no_label_erase=True,\n","):\n","    \"\"\"\n","    ê°œì„ ëœ YOLO ë°ì´í„°ì…‹ ìƒì„± í•¨ìˆ˜\n","\n","    Args:\n","        df_yolo: YOLO ë°ì´í„°í”„ë ˆì„\n","        yolo_dataset_path: ì €ì¥ ê²½ë¡œ\n","        image_size: ëª©í‘œ ì´ë¯¸ì§€ í¬ê¸°\n","        object_margin: ê°ì²´ ì£¼ë³€ ë§ˆì§„\n","        corner_radius: ë‘¥ê·¼ ëª¨ì„œë¦¬ ë°˜ì§€ë¦„\n","        ignore: ê¸°ì¡´ íŒŒì¼ ë¬´ì‹œ ì—¬ë¶€\n","        no_label_erase: Trueì´ë©´ ë¼ë²¨ë§ë˜ì§€ ì•Šì€ ê°ì²´ ì œê±°, Falseì´ë©´ ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆë§Œ\n","    \"\"\"\n","    df_yolo = df_yolo.sort_values(\"imgfile\").reset_index(drop=True)\n","\n","    # ì²˜ë¦¬ ëª¨ë“œ ì„¤ì •\n","    mode_desc = \"label-only\" if no_label_erase else \"simple resize\"\n","\n","    # ìœ ë‹ˆí¬í•œ filename ë¦¬ìŠ¤íŠ¸ ìƒì„±\n","    unique_filenames = df_yolo[\"filename\"].unique()\n","    pbar = tqdm(\n","        unique_filenames,\n","        total=len(unique_filenames),\n","        mininterval=3,\n","        desc=f\"Creating {mode_desc} YOLO dataset\",\n","    )\n","\n","    count = 0\n","    for filename in pbar:\n","        # í•´ë‹¹ filenameì˜ ëª¨ë“  í–‰ë“¤ ê°€ì ¸ì˜¤ê¸°\n","        filename_rows = df_yolo[df_yolo[\"filename\"] == filename]\n","        row = filename_rows.iloc[0]  # ì²« ë²ˆì§¸ í–‰ ì‚¬ìš© (ê°™ì€ ì´ë¯¸ì§€ì´ë¯€ë¡œ)\n","        src_img_path = row[\"imgfile\"]\n","        dest_img_path = row[\"yolo_image\"]\n","        set_type = row[\"set_type\"]\n","\n","        str_end = os.path.basename(dest_img_path)\n","\n","        org_image_size = (row[\"width\"], row[\"height\"])\n","        final_image_size = image_size\n","\n","        # ì´ë¯¸ì§€ ì²˜ë¦¬\n","        if not ignore and os.path.exists(dest_img_path):\n","            str_end += \" (ì´ë¯¸ ì¡´ì¬)\"\n","        else:\n","            try:\n","                dest_img_dir = os.path.dirname(dest_img_path)\n","                os.makedirs(dest_img_dir, exist_ok=True)\n","\n","                if os.path.exists(src_img_path):\n","                    # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ\n","                    img = cv2.imread(src_img_path)\n","                    if img is None:\n","                        print(f\"ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {src_img_path}\")\n","                        continue\n","\n","                    org_image_size = (img.shape[1], img.shape[0])  # (width, height)\n","\n","                    if set_type == \"Test\":\n","                        # Test ë°ì´í„°: ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆë§Œ ìˆ˜í–‰\n","                        final_img = resize_with_aspect_ratio_simple(img, image_size)\n","                    else:\n","                        # Train/Validation ë°ì´í„°: ì „ì²´ ì „ì²˜ë¦¬ ìˆ˜í–‰\n","                        # filename_rows ê°™ì€ ì´ë¯¸ì§€ì˜ ëª¨ë“  bbox ìˆ˜ì§‘\n","                        bboxes = []\n","                        for _, same_row in filename_rows.iterrows():\n","                            if (\n","                                same_row[\"bbox_w\"] > 0\n","                                and same_row[\"bbox_h\"] > 0\n","                                and not pd.isna(same_row[\"bbox_x\"])\n","                            ):\n","                                bboxes.append(\n","                                    [\n","                                        same_row[\"bbox_x\"],\n","                                        same_row[\"bbox_y\"],\n","                                        same_row[\"bbox_w\"],\n","                                        same_row[\"bbox_h\"],\n","                                    ]\n","                                )\n","\n","                        if not no_label_erase:\n","                            # ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆë§Œ ìˆ˜í–‰\n","                            final_img = resize_with_aspect_ratio_simple(img, image_size)\n","                        else:\n","                            # ë¼ë²¨ë§ë˜ì§€ ì•Šì€ ì˜ì—­ì—ì„œ ë°°ê²½ìƒ‰ ì¶”ì¶œ\n","                            bg_color = extract_background_color_from_unlabeled_areas(\n","                                img, bboxes, corner_radius\n","                            )\n","                            # ë¼ë²¨ë§ëœ ê°ì²´ë§Œ ìœ ì§€í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë°°ê²½ìƒ‰ìœ¼ë¡œ ì±„ì›€\n","                            cleaned_img = create_cleaned_image_with_individual_objects(\n","                                img, bboxes, bg_color, corner_radius\n","                            )\n","                            # ë¹„ìœ¨ ìœ ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° ë°°ê²½ìƒ‰ íŒ¨ë”©\n","                            final_img = resize_with_aspect_ratio_and_bg_advanced(\n","                                cleaned_img, image_size, bg_color\n","                            )\n","\n","                    # ì´ë¯¸ì§€ ì €ì¥\n","                    cv2.imwrite(dest_img_path, final_img)\n","                    final_image_size = (final_img.shape[1], final_img.shape[0])  # (width, height)\n","                else:\n","                    print(f\"ì›ë³¸ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {src_img_path}\")\n","                    continue\n","\n","            except Exception as e:\n","                print(f\"ì´ë¯¸ì§€ ì €ì¥ ì˜¤ë¥˜: {dest_img_path}, {e}\")\n","\n","        # YOLO ë¼ë²¨ íŒŒì¼ ìƒì„± (Test ë°ì´í„°ëŠ” ì œì™¸)\n","        if set_type != \"Test\":\n","            try:\n","                dest_label_path = row[\"yolo_label\"]\n","                if ignore or not os.path.exists(dest_label_path):\n","                    dest_label_dir = os.path.dirname(dest_label_path)\n","                    os.makedirs(dest_label_dir, exist_ok=True)\n","\n","                    with open(dest_label_path, \"w\", encoding=\"utf-8\") as f:\n","                        for _, label_row in filename_rows.iterrows():\n","                            # ì›ë³¸ ë° ìµœì¢… ì´ë¯¸ì§€ ì‚¬ì´ì¦ˆ\n","                            orig_w, orig_h = org_image_size  # (width, height)\n","                            tgt_w, tgt_h = final_image_size  # (width, height)\n","\n","                            # ê¸°ì¡´ yolo_x, yolo_y, yolo_w, yolo_h (ì›ë³¸ ì´ë¯¸ì§€ ê¸°ì¤€)\n","                            x_center_orig = label_row[\"yolo_x\"] * orig_w\n","                            y_center_orig = label_row[\"yolo_y\"] * orig_h\n","                            w_orig = label_row[\"yolo_w\"] * orig_w\n","                            h_orig = label_row[\"yolo_h\"] * orig_h\n","\n","                            # ë¦¬ì‚¬ì´ì¦ˆ ë¹„ìœ¨ ë° íŒ¨ë”© ê³„ì‚°\n","                            scale = min(tgt_w / orig_w, tgt_h / orig_h)\n","                            pad_x = (tgt_w - int(orig_w * scale)) // 2\n","                            pad_y = (tgt_h - int(orig_h * scale)) // 2\n","\n","                            # ë¦¬ì‚¬ì´ì¦ˆ ë° íŒ¨ë”© ì ìš©\n","                            x_center_new = x_center_orig * scale + pad_x\n","                            y_center_new = y_center_orig * scale + pad_y\n","                            w_new = w_orig * scale\n","                            h_new = h_orig * scale\n","\n","                            # ìµœì¢… yolo ì¢Œí‘œ (ë³€í™˜ëœ ì´ë¯¸ì§€ ê¸°ì¤€)\n","                            x_center = x_center_new / tgt_w\n","                            y_center = y_center_new / tgt_h\n","                            w_norm = w_new / tgt_w\n","                            h_norm = h_new / tgt_h\n","\n","                            class_id = (\n","                                max(0, int(label_row[\"class_id\"]) - 1)\n","                                if label_row[\"class_id\"] > 0\n","                                else 0\n","                            )\n","                            f.write(\n","                                f\"{class_id} {x_center:.6f} {y_center:.6f} {w_norm:.6f} {h_norm:.6f}\\n\"\n","                            )\n","\n","            except Exception as e:\n","                print(f\"ë¼ë²¨ ì €ì¥ ì˜¤ë¥˜: {dest_label_path}, {e}\")\n","\n","        if count % 100 == 0:\n","            pbar.set_postfix_str(str_end)\n","        count += 1\n","\n","    # dataset.yaml íŒŒì¼ ìƒì„±\n","    df_drug_sort = df_drug.sort_values(by=\"class_id\")\n","    classnames = df_drug_sort[\"drug_N\"].tolist()\n","\n","    dataset_config = {\n","        \"path\": yolo_dataset_path,\n","        \"train\": \"images/train\",\n","        \"val\": \"images/val\",\n","        \"test\": \"images/test\",\n","        \"nc\": len(classnames),\n","        \"names\": classnames,\n","    }\n","\n","    yaml_path = os.path.join(yolo_dataset_path, \"dataset.yaml\")\n","\n","    print(yolo_dataset_path)\n","    print(yaml_path)\n","\n","    with open(yaml_path, \"w\") as f:\n","        yaml.dump(dataset_config, f, default_flow_style=False)\n","\n","    print(f\"\\n=== ì²˜ë¦¬ ì™„ë£Œ ===\")\n","    print(f\"ìƒì„±: {len(df_yolo)}\")\n","    print(f\"YAML íŒŒì¼: {yaml_path}\")\n","\n","    return yaml_path\n","\n","\n","# # 1. ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆë§Œ (ê°€ì¥ ë¹ ë¦„)\n","# yolo_path = os.path.join(root_dir, \"yolo_resize\")\n","# df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","# #df_yolo_test = df_yolo.iloc[2000:2100].copy()\n","# yaml_path = create_yolo_file(df_yolo_test, yolo_dataset_path=yolo_path)"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"LNFgc1ahKUGl","outputId":"77a01267-de7e-4f3a-afc7-738afda6fbe5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1757602385925,"user_tz":-540,"elapsed":130284,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["Creating YOLO dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5369/5369 [00:01<00:00, 2976.90it/s, K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]\n"]},{"output_type":"stream","name":"stdout","text":["âœ… ì»¤ë°‹ ì™„ë£Œ: b4dc3e242139 | 2025-09-11 14:51:03 | df_codeit04_yolo\n"]},{"output_type":"stream","name":"stderr","text":["Creating simple resize YOLO dataset: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2332/2332 [02:08<00:00, 18.16it/s, K-003544-010221-016548-029451_0_2_0_2_75_000_200.png]"]},{"output_type":"stream","name":"stdout","text":["~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize/dataset.yaml\n","\n","=== ì²˜ë¦¬ ì™„ë£Œ ===\n","ìƒì„±: 5369\n","YAML íŒŒì¼: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_resize/dataset.yaml\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["# # ì‹¤í–‰\n","# 1. ê°„ë‹¨í•œ ë¦¬ì‚¬ì´ì¦ˆë§Œ (ê°€ì¥ ë¹ ë¦„)\n","yolo_path  = os.path.join(root_dir, \"yolo_resize\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","yaml_path = create_yolo_file(df_yolo, yolo_path, no_label_erase=False, ignore=True)"]},{"cell_type":"code","execution_count":30,"metadata":{"id":"c464SJfYKUGl","outputId":"1813054a-4fa5-4ffc-de79-c321a004c851","colab":{"base_uri":"https://localhost:8080/","height":259,"referenced_widgets":["24816e0122cf4c058127b5a4e2cee908","d5676358062d41e39a3734d658d52a37","e0a75d1cd56e44788b3b4eb575d2ae2c","b098f041193a4882b2f8dad7815deb7d","d2a93d522b3f44c1a5bfaaab6b0e29ef","71d5cc6214c243d9ba22fd2982b157bf","d60d3d229d1f43de9808f6cf19d61d97","761c6eaa6d8b440a9225f6d6ed61117c","8a9be69c35014cbe85c96d4392265fc9","1e7961a59b744823b460a16a4d59193a","fd638b147d944be69005e5897720d3f4","fe8aeea207ed441d9aa2773db23c97d6","c419bc980fec415a944c6e6e2dd8ad98","d5086a914578434fb4a31403b5792a03","a8ebacd7e8e040328ff249ff891a601d","a42111a1c71c4cd28ec4394699586313","f83dd9a5bdd443f5b518d386a69eb075","e7e1efdc57684c219d9caf7b3f13c375","e71aa091bc7647c79b74ce754f3ad404","27add70b337647dca61c36c66fa8a943","1549aadb94ce422ebddabfde483ec2b4","fe60a5cc55d84ea0b86b03cf43e21caa"]},"executionInfo":{"status":"ok","timestamp":1757603842005,"user_tz":-540,"elapsed":287917,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}}},"outputs":[{"output_type":"display_data","data":{"text/plain":["Creating YOLO dataset:   0%|          | 0/5369 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24816e0122cf4c058127b5a4e2cee908"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["âœ… ì»¤ë°‹ ì™„ë£Œ: 735a7cb92423 | 2025-09-11 15:12:42 | df_codeit04_yolo\n"]},{"output_type":"display_data","data":{"text/plain":["Creating label-only YOLO dataset:   0%|          | 0/2332 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe8aeea207ed441d9aa2773db23c97d6"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","\n","=== ì²˜ë¦¬ ì™„ë£Œ ===\n","ìƒì„±: 5369\n","YAML íŒŒì¼: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n"]}],"source":["# 2. ìƒˆë¡œìš´ ë°©ì‹ (ë¼ë²¨ë§ëœ ê°ì²´ë§Œ ìœ ì§€)\n","yolo_path  = os.path.join(root_dir, \"yolo_no_label\")\n","df_yolo, yolo_path = create_yolo_df(yolo_path, ignore=True)\n","yaml_path = create_yolo_file(df_yolo, yolo_path, no_label_erase=True, ignore=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xkmRQLG9MlGp"},"outputs":[],"source":["raise ValueError(\"stop here\")"]},{"cell_type":"markdown","metadata":{"id":"Z4JFBb3HMlGp"},"source":["# í”„ë¡œê·¸ë˜ë° Yolo"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QWNUnPJkMlGp","executionInfo":{"status":"ok","timestamp":1757602426211,"user_tz":-540,"elapsed":26158,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"249c5bd5-9b8f-4ad4-8600-2a9b66552bec"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m83.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hë¡œë”©ì™„ë£Œ\n"]}],"source":["!pip install -q albumentations\n","!pip install -q ultralytics\n","!pip install -q roboflow\n","!pip install -q opencv-python\n","!pip install -q opencv-python-headless\n","print(\"ë¡œë”©ì™„ë£Œ\")"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"orKJ7phmMlGp","executionInfo":{"status":"ok","timestamp":1757602434345,"user_tz":-540,"elapsed":5958,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"44eab525-a66e-496b-bafb-84457ec19d2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":22}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"adgC_6YVMlGp","executionInfo":{"status":"ok","timestamp":1757602438804,"user_tz":-540,"elapsed":10,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"79f51802-5cc8-46c7-b49c-e69011daea24"},"outputs":[{"output_type":"stream","name":"stdout","text":["ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:cuda\n"]}],"source":["# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n","\n","# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error\n","from sklearn.metrics import average_precision_score\n","\n","# --- ê¸°íƒ€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n","from PIL import Image\n","from PIL import ImageFilter\n","from PIL import ImageDraw\n","import albumentations as A\n","import IPython.display\n","#from tqdm import tqdm\n","from tqdm.notebook import tqdm\n","\n","# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.transforms import v2\n","from torchvision.datasets import CocoDetection\n","from torchvision.transforms import functional as TF\n","from torch.nn import CrossEntropyLoss\n","from collections import OrderedDict\n","\n","# --- ê¸°íƒ€ ---\n","import re\n","import os\n","import sys\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import pandas as pd\n","import numpy as np\n","from pathlib import Path\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import pandas as pd\n","from datetime import datetime\n","from datetime import timezone, timedelta\n","import pytz\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# GPU ì„¤ì •\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","  # ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•´\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜:{__device}\")"]},{"cell_type":"markdown","metadata":{"id":"JfapF4EsMlGp"},"source":["### > ì„¤ì • < í”Œë ˆê·¸"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kJ2Z8DJ5MlGq","executionInfo":{"status":"ok","timestamp":1757602445610,"user_tz":-540,"elapsed":8,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"4b8a413d-8878-45bd-9fa5-4b57c77bc4bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì´ë¯¸ì§€ ì›ë³¸í¬ê¸°:(640, 480) ëª¨ë¸ì…ë ¥í¬ê¸°:(640, 480) DEBUG_ON:False\n","í‰ê·  í‘œì¤€í¸ì°¨ {'mean_tensor': [0.485, 0.456, 0.406], 'std_tensor': [0.229, 0.224, 0.225], 'mean_rgb': [123, 116, 103], 'std_rgb': [58, 57, 57]}\n"]}],"source":["# ë””ë²„ê·¸ ëª¨ë“œ (í•„ìš”ì‹œ Trueë¡œ ë³€ê²½)\n","DEBUG_ON = False\n","if not helper.is_colab:\n","    DEBUG_ON = True\n","\n","IMAGE_SIZE_ORG=(640,480)\n","IMAGE_SIZE=(640,480)\n","BATCH_SIZE=16\n","\n","__MEAN_TENSOR = [0.485, 0.456, 0.406]\n","__STD_TENSOR = [0.229, 0.224, 0.225]\n","__MEAN_RGB = [123, 116, 103]\n","__STD_RGB = [58, 57, 57]\n","\n","def mean_std(type=None, mean_tensor=None, std_tensor=None, mean_rgb=None, std_rgb=None):\n","    \"\"\"\n","    Mean (RGB): [0.485, 0.456, 0.406]\n","    Std (RGB):  [0.229, 0.224, 0.225]\n","    Mean (RGB, 0~255): [123, 116, 103]\n","    Std (RGB, 0~255):  [58, 57, 57]\n","    \"\"\"\n","    global __MEAN_TENSOR, __STD_TENSOR, __MEAN_RGB, __STD_RGB\n","    res_old = {\n","        \"mean_tensor\": __MEAN_TENSOR,\n","        \"std_tensor\": __STD_TENSOR,\n","        \"mean_rgb\": __MEAN_RGB,\n","        \"std_rgb\": __STD_RGB\n","    }\n","\n","    if mean_tensor is not None:\n","        __MEAN_TENSOR = mean_tensor\n","    if std_tensor is not None:\n","        __STD_TENSOR = std_tensor\n","    if mean_rgb is not None:\n","        __MEAN_RGB = mean_rgb\n","    if std_rgb is not None:\n","        __STD_RGB = std_rgb\n","\n","    res = {\n","        \"mean_tensor\": __MEAN_TENSOR,\n","        \"std_tensor\": __STD_TENSOR,\n","        \"mean_rgb\": __MEAN_RGB,\n","        \"std_rgb\": __STD_RGB\n","    }\n","\n","    if res_old != res:\n","        print(f\"ë³€ê²½ì‚¬í•­ ë°œê²¬: { json.dumps(res_old, indent=2, ensure_ascii=False)} -> {json.dumps(res, indent=2, ensure_ascii=False)}\")\n","\n","    if type is None:\n","        return res\n","    return res.get(type, res)\n","\n","\n","print(f'ì´ë¯¸ì§€ ì›ë³¸í¬ê¸°:{IMAGE_SIZE_ORG} ëª¨ë¸ì…ë ¥í¬ê¸°:{IMAGE_SIZE} DEBUG_ON:{DEBUG_ON}')\n","print(f'í‰ê·  í‘œì¤€í¸ì°¨ {mean_std()}')"]},{"cell_type":"markdown","metadata":{"id":"S41xfQbvMlGq"},"source":["### 1.2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"]},{"cell_type":"markdown","metadata":{"id":"tpJHEimnMlGq"},"source":["#### 1.2.1 ê¸°ë³¸ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W1gQK-nfMlGq","executionInfo":{"status":"ok","timestamp":1757602450481,"user_tz":-540,"elapsed":41,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"98468928-0a95-493a-8063-da0810663c47"},"outputs":[{"output_type":"stream","name":"stdout","text":["ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"]}],"source":["\n","def get_tqdm_kwargs_old():\n","    \"\"\"í™˜ê²½ì— ë§ëŠ” tqdm ì„¤ì • ë°˜í™˜\"\"\"\n","    if helper.is_colab or 'ipykernel' in sys.modules:\n","        # Jupyter/Colab í™˜ê²½\n","        # return {'disable': False, 'leave': True, 'position': 0, 'ncols': 60}  # í­ 60ìœ¼ë¡œ ì§€ì •\n","        return {'disable': False, 'leave': True, 'position': 0}\n","    else:\n","        # ì¼ë°˜ Python í™˜ê²½\n","        #return {'disable': False, 'mininterval': 1, 'leave': True, 'ncols': 60}\n","        return {'disable': False, 'mininterval': 1, 'leave': True}\n","\n","def get_tqdm_kwargs():\n","    \"\"\"Widget ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ tqdm ì„¤ì •\"\"\"\n","    return {\n","        'disable': False,\n","        'leave': True,\n","        'file': sys.stdout,\n","        'ascii': True,  # ASCII ë¬¸ìë§Œ ì‚¬ìš©\n","        'dynamic_ncols': False,\n","#        'ncols': 80  # ê³ ì • í­\n","    }\n","\n","def drive_root():\n","    root_path = os.path.join(\"D:\\\\\", \"GoogleDrive\")\n","    if helper.is_colab:\n","        root_path = os.path.join(\"/content/drive/MyDrive\")\n","    return root_path\n","\n","def get_path_modeling(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    if DEBUG_ON:\n","        modeling_path = modeling_path +\"_debug\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def get_path_modeling_release(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def print_dir_tree(root, max_depth=2, list_count=3, indent=\"\"):\n","    import os\n","    if max_depth < 0:\n","        return\n","    try:\n","        items = os.listdir(root)\n","    except Exception as e:\n","        print(indent + f\"[Error] {e}\")\n","        return\n","\n","    img_count = len([f for f in os.listdir(root) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","    for item in items:\n","        path = os.path.join(root, item)\n","        if os.path.isdir(path):\n","            print(indent + \"|-- \"+ item)\n","            # ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ë§Œ ì¶œë ¥\n","            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","            if img_count > list_count:\n","                print(indent + \"   \"+ f\"[ë°ì´í„°íŒŒì¼: {img_count}ê°œ]\")\n","            print_dir_tree(root=path, max_depth=max_depth-1, list_count=list_count, indent=indent + \"   \")\n","        else:\n","            if list_count < img_count and item.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt')):\n","                continue\n","            print(indent + \"|-- \"+ item)\n","\n","def save_model_dict(model, path, pth_name, kwargs=None):\n","    \"\"\"ëª¨ë¸ state_dictì™€ ì¶”ê°€ ì •ë³´ë¥¼ ì €ì¥\"\"\"\n","    def safe_makedirs(path):\n","        \"\"\"ì•ˆì „í•œ ë””ë ‰í† ë¦¬ ìƒì„±\"\"\"\n","        if os.path.exists(path) and not os.path.isdir(path):\n","            os.remove(path)  # íŒŒì¼ì´ë©´ ì‚­ì œ\n","        os.makedirs(path, exist_ok=True)\n","\n","    # ë””ë ‰í† ë¦¬ ìƒì„±\n","    safe_makedirs(path)\n","\n","    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n","    model_info = {\n","        'class_name': model.__class__.__name__,\n","        'init_args': {},\n","        'str': str(model),\n","        'repr': repr(model),\n","        'modules': [m.__class__.__name__ for m in model.modules()],\n","    }\n","\n","    # ìƒì„±ì ì¸ì ìë™ ì¶”ì¶œ(ê°€ëŠ¥í•œ ê²½ìš°)\n","    if hasattr(model, '__dict__'):\n","        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n","            if hasattr(model, key):\n","                model_info['init_args'][key] = getattr(model, key)\n","\n","    # kwargs ì²˜ë¦¬\n","    extra_info = {}\n","    if kwargs is not None:\n","        if isinstance(kwargs, str):\n","            extra_info = json.loads(kwargs)\n","        elif isinstance(kwargs, dict):\n","            extra_info = kwargs\n","\n","    model_info.update(extra_info)\n","\n","    # ì €ì¥í•  dict êµ¬ì„±\n","    save_dict = {\n","        'model_state': model.state_dict(),\n","        'class_name': model.__class__.__name__,\n","        'model_info': model_info,\n","    }\n","\n","    save_path = os.path.join(path, f\"{pth_name}.pth\")\n","    torch.save(save_dict, save_path)\n","    return save_path\n","\n","def load_model_dict(path, pth_name=None):\n","    \"\"\"\n","    save_model_dictë¡œ ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n","    ë°˜í™˜ê°’: (model_state, model_info)\n","    \"\"\"\n","    import torch\n","    load_path = path\n","    if pth_name is not None:\n","        load_path = os.path.join(path, f\"{pth_name}.pth\")\n","    checkpoint = torch.load(load_path, map_location='cpu', weights_only=False)  # <-- ì—¬ê¸° ì¶”ê°€\n","    model_state = checkpoint.get('model_state')\n","    model_info = checkpoint.get('model_info')\n","    model_info['file_name'] = os.path.basename(load_path)\n","    return model_state, model_info\n","\n","\n","def search_pth_files(base_path):\n","    \"\"\"\n","    ì…ë ¥ëœ ê²½ë¡œì˜ í•˜ìœ„ í´ë”ë“¤ì—ì„œ pth íŒŒì¼ë“¤ì„ ê²€ìƒ‰\n","    \"\"\"\n","    pth_files = []\n","\n","    if not os.path.exists(base_path):\n","        print(f\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_path}\")\n","        return pth_files\n","\n","    print(f\"pth íŒŒì¼ ê²€ìƒ‰ ì‹œì‘: {base_path}\")\n","\n","    # í•˜ìœ„ í´ë”ë“¤ì„ ìˆœíšŒí•˜ë©° pth íŒŒì¼ ê²€ìƒ‰\n","    for root, dirs, files in os.walk(base_path):\n","        for file in files:\n","            if file.endswith('.pth'):\n","                pth_path = os.path.join(root, file)\n","                pth_files.append(pth_path)\n","\n","    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥\n","    if pth_files:\n","        print(f\"\\në°œê²¬ëœ pth íŒŒì¼ë“¤ ({len(pth_files)}ê°œ):\")\n","        for i, pth_file in enumerate(pth_files, 1):\n","            # ìƒëŒ€ ê²½ë¡œë¡œ í‘œì‹œ (base_path ê¸°ì¤€)\n","            rel_path = os.path.relpath(pth_file, base_path)\n","            print(f\" {i:2d}. {rel_path}\")\n","    else:\n","        print(\"pth íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","\n","    return pth_files\n","\n","def print_json_tree(data, indent=\"\", max_depth=4, _depth=0, list_count=2, print_value=True):\n","    \"\"\"\n","    JSON ê°ì²´ë¥¼ ì§€ì •í•œ ë‹¨ê³„(max_depth)ê¹Œì§€ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\n","    - list íƒ€ì…ì€ 3ê°œ ì´ìƒì¼ ë•Œ ê°œìˆ˜ë§Œ ì¶œë ¥\n","    - í•˜ìœ„ ë…¸ë“œê°€ ê°’ì¼ ê²½ìš° key(type) í˜•íƒœë¡œ ì¶œë ¥\n","    - print_value=Trueì¼ ë•Œ key(type): ê°’ í˜•íƒœë¡œ ì¶œë ¥\n","    \"\"\"\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            if isinstance(value, (dict, list)):\n","                print(f\"{indent}|-- {key}\")\n","                print_json_tree(value, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","            else:\n","                if print_value:\n","                    print(f\"{indent}|-- {key}({type(value).__name__}): {value if len(str(value)) < 100 else f'{str(value)[:30]}...'}\")\n","                else:\n","                    print(f\"{indent}|-- {key}({type(value).__name__})\")\n","    elif isinstance(data, list):\n","        if len(data) > list_count:\n","            print(f\"{indent}|-- [list] ({len(data)} items)\")\n","        else:\n","            for i, item in enumerate(data):\n","                if isinstance(item, (dict, list)):\n","                    print(f\"{indent}|-- [{i}]\")\n","                    print_json_tree(item, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","                else:\n","                    if print_value:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__}): {item if len(str(item)) < 100 else f'{str(item)[:30]}...'}\")\n","                    else:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__})\")\n","    else:\n","        if print_value:\n","            print(f\"{indent}{type(data).__name__}: {data if len(str(data)) < 100 else f'{str(data)[:30]}...'}\")\n","        else:\n","            print(f\"{indent}{type(data).__name__}\")\n","\n","def print_git_tree(data, indent=\"\", max_depth=3, _depth=0):\n","    \"\"\"\n","    PyTorch tensor/ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ë¥¼ git tree ìŠ¤íƒ€ì¼ë¡œ ì¶œë ¥\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            print(f\"{indent}â”œâ”€ {key} [{type(value).__name__}]\")\n","            print_git_tree(value, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif isinstance(data, (list, tuple)):\n","        for i, item in enumerate(data):\n","            print(f\"{indent}â”œâ”€ [{i}] [{type(item).__name__}]\")\n","            print_git_tree(item, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif torch.is_tensor(data):\n","        shape = tuple(data.shape)\n","        dtype = str(data.dtype)\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ Tensor shape={shape} dtype={dtype} preview={preview_str}\")\n","    elif isinstance(data, np.ndarray):\n","        shape = data.shape\n","        dtype = data.dtype\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ ndarray shape={shape} dtype={dtype} preview={preview_str}\")\n","    else:\n","        val_str = str(data)\n","        print(f\"{indent}â””â”€ {type(data).__name__}: {val_str[:80]}{'...' if len(val_str)>80 else ''}\")\n","\n","\n","print(\"ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"]},{"cell_type":"markdown","metadata":{"id":"MSpb1Pp8MlGq"},"source":["## 2. ë°ì´í„° ë¡œë“œ"]},{"cell_type":"markdown","metadata":{"id":"Ephz8BXVMlGq"},"source":["### 2.1. ë°ì´í„° ë‹¤ìš´ë¡œë“œ"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PjxsUVjUMlGq","executionInfo":{"status":"ok","timestamp":1757605349523,"user_tz":-540,"elapsed":443,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"0842dab0-0eda-4659-e1b5-b938ce20d643"},"outputs":[{"output_type":"stream","name":"stdout","text":["kaggle_config_dir: /content/drive/MyDrive/\n","kaggle_code_it_data: ~/.cache/dataset/kaggle_code_it_data\n","root_dir: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip\n","yolo_path ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","yaml_path: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","get_path_data: ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n"]}],"source":["# google drive rootì— keggle.json íŒŒì¼ í•„ìš”í•©ë‹ˆë‹¤.\n","\n","#kaggle_code_it_data = \"~/.cache/kaggle_code_it_data\" if helper.is_colab else os.path.join(Path.cwd(),'dataset', 'kaggle_code_it_data')\n","kaggle_config_dir = \"/content/drive/MyDrive/\" if helper.is_colab else os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive')\n","print(\"kaggle_config_dir:\", kaggle_config_dir)\n","kaggle_code_it_data = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\','dataset', 'kaggle_code_it_data')\n","print(\"kaggle_code_it_data:\", kaggle_code_it_data)\n","\n","kaggle_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip')\n","kaggle_unzip_path = os.path.join(kaggle_code_it_data, 'ai04-level1-project.zip.unzip')\n","kaggle_unzip_path_test_images = os.path.join(kaggle_unzip_path, 'test_images')\n","kaggle_unzip_path_train_images = os.path.join(kaggle_unzip_path, 'train_images')\n","root_dir = os.path.join(kaggle_unzip_path)\n","#yolo_path  = os.path.join(root_dir, \"yolo_resize\")\n","yolo_path  = os.path.join(root_dir, \"yolo_no_label\")\n","yaml_path = os.path.join(yolo_path, \"dataset.yaml\")\n","\n","def get_path_data():\n","    path = yolo_path\n","    return path\n","\n","print(\"root_dir:\", root_dir)\n","print(\"yolo_path\",yolo_path)\n","print(\"yaml_path:\", yaml_path)\n","print(\"get_path_data:\", get_path_data())"]},{"cell_type":"markdown","metadata":{"id":"ZRk0o5CUMlGq"},"source":["## YOLO ëª¨ë¸ë§"]},{"cell_type":"code","execution_count":39,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tTZrT8TLMlGq","executionInfo":{"status":"ok","timestamp":1757605358844,"user_tz":-540,"elapsed":437,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"8958aee4-3c88-49bf-a6af-97056bbd210e"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì‚¬ìš© ë””ë°”ì´ìŠ¤: cuda\n","CUDA ë²„ì „: 12.6\n","~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label\n","|-- images\n","   |-- val\n","      [ë°ì´í„°íŒŒì¼: 435ê°œ]\n","   |-- train\n","      [ë°ì´í„°íŒŒì¼: 1054ê°œ]\n","   |-- test\n","      [ë°ì´í„°íŒŒì¼: 843ê°œ]\n","|-- dataset.yaml\n","|-- labels\n","   |-- train.cache\n","   |-- val\n","      [ë°ì´í„°íŒŒì¼: 435ê°œ]\n","   |-- val.cache\n","   |-- train\n","      [ë°ì´í„°íŒŒì¼: 1054ê°œ]\n","ë°ì´í„°ì…‹ ì„¤ì •:\n","í´ë˜ìŠ¤ ìˆ˜: 73\n","í´ë˜ìŠ¤ ì´ë¦„: ['K-001900', 'K-002483', 'K-003351', 'K-003483', 'K-003544', 'K-003743', 'K-003832', 'K-004378', 'K-004543', 'K-005094', 'K-005886', 'K-006192', 'K-006563', 'K-010221', 'K-012081', 'K-012247', 'K-012420', 'K-012778', 'K-013395', 'K-013900', 'K-016232', 'K-016262', 'K-016548', 'K-016551', 'K-016688', 'K-018110', 'K-018147', 'K-018357', 'K-019232', 'K-019552', 'K-019607', 'K-019861', 'K-020014', 'K-020238', 'K-020877', 'K-021026', 'K-021325', 'K-021771', 'K-022074', 'K-022347', 'K-022362', 'K-022627', 'K-023203', 'K-023223', 'K-024850', 'K-025367', 'K-025438', 'K-025469', 'K-027653', 'K-027733', 'K-027777', 'K-027926', 'K-027993', 'K-028763', 'K-029345', 'K-029451', 'K-029667', 'K-029871', 'K-030308', 'K-031705', 'K-031863', 'K-031885', 'K-032310', 'K-033009', 'K-033208', 'K-033878', 'K-033880', 'K-034597', 'K-035206', 'K-036637', 'K-038162', 'K-041768', 'K-044199']\n","í›ˆë ¨ ê²½ë¡œ: images/train\n","ê²€ì¦ ê²½ë¡œ: images/val\n","í…ŒìŠ¤íŠ¸ ê²½ë¡œ: images/test\n","\n","=== ë°ì´í„°ì…‹ ì •ë³´ ===\n","í›ˆë ¨ ì´ë¯¸ì§€: 0ê°œ (ë¼ë²¨: 1054ê°œ)\n","ê²€ì¦ ì´ë¯¸ì§€: 0ê°œ (ë¼ë²¨: 435ê°œ)\n","í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: 0ê°œ\n"]}],"source":["# YOLO ê°œê³ ì–‘ì´ ë¶„ë¥˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸ (Google Colab)\n","# ë°ì´í„°: 2564 train, 1100 valid, 3659 test (ì´ 37ê°œ í’ˆì¢… â†’ 2ê°œ í´ë˜ìŠ¤)\n","\n","# ============================================================================\n","# 1. í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n","# ============================================================================\n","from pathlib import Path\n","from ultralytics import YOLO\n","\n","\n","# GPU í™•ì¸\n","device = __device\n","print(f\"ì‚¬ìš© ë””ë°”ì´ìŠ¤: {device}\")\n","print(f\"CUDA ë²„ì „: {torch.version.cuda}\")\n","\n","# ============================================================================\n","# 2. ë°ì´í„°ì…‹ ì„¤ì • ë° í™•ì¸\n","# ============================================================================\n","\n","# ë°ì´í„°ì…‹ ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •)\n","#dataset_root = \"/root/.cache/yolo_dataset\"\n","\n","print(yolo_path)\n","print_dir_tree(root=yolo_path, max_depth=3,list_count=3)\n","#print_dir_tree(yaml_path, max_depth=3)\n","\n","# YAML íŒŒì¼ ë‚´ìš© í™•ì¸\n","with open(yaml_path, 'r') as f:\n","    dataset_config = yaml.safe_load(f)\n","\n","print(\"ë°ì´í„°ì…‹ ì„¤ì •:\")\n","print(f\"í´ë˜ìŠ¤ ìˆ˜: {dataset_config['nc']}\")\n","print(f\"í´ë˜ìŠ¤ ì´ë¦„: {dataset_config['names']}\")\n","print(f\"í›ˆë ¨ ê²½ë¡œ: {dataset_config['train']}\")\n","print(f\"ê²€ì¦ ê²½ë¡œ: {dataset_config['val']}\")\n","print(f\"í…ŒìŠ¤íŠ¸ ê²½ë¡œ: {dataset_config.get('test', 'None')}\")\n","\n","# ë°ì´í„° ë¶„í¬ í™•ì¸\n","def print_dataset_info():\n","    train_images = len(list(Path(f\"{yolo_path}/images/train\").glob(\"*.jpg\")))\n","    val_images = len(list(Path(f\"{yolo_path}/images/val\").glob(\"*.jpg\")))\n","    test_images = len(list(Path(f\"{yolo_path}/images/test\").glob(\"*.jpg\")))\n","\n","    train_labels = len(list(Path(f\"{yolo_path}/labels/train\").glob(\"*.txt\")))\n","    val_labels = len(list(Path(f\"{yolo_path}/labels/val\").glob(\"*.txt\")))\n","\n","    print(f\"\\n=== ë°ì´í„°ì…‹ ì •ë³´ ===\")\n","    print(f\"í›ˆë ¨ ì´ë¯¸ì§€: {train_images}ê°œ (ë¼ë²¨: {train_labels}ê°œ)\")\n","    print(f\"ê²€ì¦ ì´ë¯¸ì§€: {val_images}ê°œ (ë¼ë²¨: {val_labels}ê°œ)\")\n","    print(f\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {test_images}ê°œ\")\n","\n","print_dataset_info()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sYiHmKJIMlGq"},"outputs":[],"source":["raise ValueError(\"stop here\")"]},{"cell_type":"markdown","metadata":{"id":"d_ZyKQe7MlGu"},"source":["### 3.3 ëª¨ë¸ë§ ì—”ì§„"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"udSHefYQMlGu","executionInfo":{"status":"ok","timestamp":1757607134333,"user_tz":-540,"elapsed":1742830,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"}},"outputId":"4ba84b8c-840a-4d70-d82a-16e6df518fb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["yaml_path= ~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml\n","\n","=== YOLO ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 130.5MB 114.5MB/s 1.1s\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/dataset.yaml, degrees=0.0, deterministic=True, device=None, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=30, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8x.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo_20250912_0043, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=10, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/drive/MyDrive/modeling_yolo, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043, save_frames=False, save_json=False, save_period=10, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","Overriding model.yaml nc=80 with nc=73\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      2320  ultralytics.nn.modules.conv.Conv             [3, 80, 3, 2]                 \n","  1                  -1  1    115520  ultralytics.nn.modules.conv.Conv             [80, 160, 3, 2]               \n","  2                  -1  3    436800  ultralytics.nn.modules.block.C2f             [160, 160, 3, True]           \n","  3                  -1  1    461440  ultralytics.nn.modules.conv.Conv             [160, 320, 3, 2]              \n","  4                  -1  6   3281920  ultralytics.nn.modules.block.C2f             [320, 320, 6, True]           \n","  5                  -1  1   1844480  ultralytics.nn.modules.conv.Conv             [320, 640, 3, 2]              \n","  6                  -1  6  13117440  ultralytics.nn.modules.block.C2f             [640, 640, 6, True]           \n","  7                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n","  8                  -1  3   6969600  ultralytics.nn.modules.block.C2f             [640, 640, 3, True]           \n","  9                  -1  1   1025920  ultralytics.nn.modules.block.SPPF            [640, 640, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1948800  ultralytics.nn.modules.block.C2f             [960, 320, 3]                 \n"," 16                  -1  1    922240  ultralytics.nn.modules.conv.Conv             [320, 320, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   7174400  ultralytics.nn.modules.block.C2f             [960, 640, 3]                 \n"," 19                  -1  1   3687680  ultralytics.nn.modules.conv.Conv             [640, 640, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   7379200  ultralytics.nn.modules.block.C2f             [1280, 640, 3]                \n"," 22        [15, 18, 21]  1   8788267  ultralytics.nn.modules.head.Detect           [73, [320, 640, 640]]         \n","Model summary: 209 layers, 68,222,907 parameters, 68,222,891 gradients, 258.5 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1904.9Â±530.2 MB/s, size: 114.0 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/labels/train.cache... 1054 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1054/1054 2.2Mit/s 0.0s\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 412.6Â±158.0 MB/s, size: 65.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/labels/val.cache... 435 images, 0 backgrounds, 2 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 435/435 475.1Kit/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/images/val/K-003351-016262-018357_0_2_0_2_75_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     5.3707]\n","\u001b[34m\u001b[1mval: \u001b[0m/content/~/.cache/dataset/kaggle_code_it_data/ai04-level1-project.zip.unzip/yolo_no_label/images/val/K-003544-004543-012247-016551_0_2_0_2_70_000_200.png: ignoring corrupt image/label: non-normalized or out of bounds coordinates [     7.0293]\n","Plotting labels to /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00013, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 8 dataloader workers\n","Logging results to \u001b[1m/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043\u001b[0m\n","Starting training for 30 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       1/30      12.5G      0.237      3.006     0.8432         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 47.3s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.715      0.484      0.553      0.552\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       2/30      12.8G     0.1454      1.152     0.8051         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 47.1s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.869      0.749      0.901      0.899\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       3/30      12.5G     0.1552     0.7957     0.8064         77        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 47.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323        0.8      0.866      0.933       0.93\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       4/30      12.8G     0.1527     0.6678     0.8031         71        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.892      0.904      0.955      0.951\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       5/30      12.7G     0.1435     0.5526     0.8056         73        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.913      0.898      0.965      0.964\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       6/30      12.7G     0.1339     0.4838     0.8022         65        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.906       0.92      0.963       0.96\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       7/30      12.7G     0.1263     0.4358     0.8007         55        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.906       0.96      0.975      0.974\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       8/30      12.7G     0.1241     0.4359     0.7986         59        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.953      0.953      0.983      0.981\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K       9/30      12.8G     0.1201     0.3946     0.8019         58        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.949      0.984       0.99       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      10/30      12.8G     0.1201      0.352     0.7968         69        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.95      0.968       0.99      0.988\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      11/30      12.7G     0.1165     0.3466     0.8011         66        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.964      0.968       0.99       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      12/30      12.8G     0.1121     0.3412     0.8003         67        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.939      0.987      0.987      0.986\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      13/30      12.7G      0.103     0.3054     0.8001         56        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.953      0.966       0.99      0.989\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      14/30      12.8G      0.102     0.2799     0.7966         66        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.968      0.984      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      15/30      12.8G     0.1019     0.2779     0.7947         57        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.971      0.972      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      16/30      12.7G    0.09924     0.2736     0.7938         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.98      0.972      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      17/30      12.7G    0.09572     0.2442     0.7968         54        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.981      0.992      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      18/30      12.4G    0.08994     0.2272     0.7943         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323       0.97      0.994      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      19/30      12.7G    0.08777     0.2253      0.796         86        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.981      0.989      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      20/30      12.8G     0.0863     0.2208     0.7951         61        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.988      0.995      0.991      0.991\n","Closing dataloader mosaic\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      21/30      12.7G     0.0781     0.1459     0.7721         41        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 47.2s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.988      0.993      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      22/30      12.7G    0.07853     0.1391     0.7733         42        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.987      0.995      0.991       0.99\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      23/30      12.7G    0.07631     0.1342     0.7734         38        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.986      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      24/30      12.7G    0.07172     0.1295     0.7676         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323       0.99      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      25/30      12.7G    0.07107     0.1169     0.7653         43        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.986      0.993      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      26/30      12.8G     0.0683     0.1154     0.7704         48        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      27/30      12.7G    0.06375     0.1054     0.7682         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.9s\n","                   all        433       1323       0.99      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      28/30      12.7G    0.05987     0.1033     0.7713         36        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.991      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      29/30      12.7G     0.0584    0.09531     0.7709         45        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.9s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      30/30      12.8G    0.05445    0.09301     0.7652         44        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 66/66 1.4it/s 46.8s\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.8s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","\n","30 epochs completed in 0.477 hours.\n","Optimizer stripped from /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/last.pt, 136.9MB\n","Optimizer stripped from /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/best.pt, 136.9MB\n","\n","Validating /content/drive/MyDrive/modeling_yolo/yolo_20250912_0043/weights/best.pt...\n","Ultralytics 8.3.198 ğŸš€ Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (NVIDIA L4, 22693MiB)\n","Model summary (fused): 112 layers, 68,193,867 parameters, 0 gradients, 257.8 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 14/14 1.8it/s 7.7s\n","                   all        433       1323      0.992      0.995      0.992      0.991\n","              K-001900         61         61      0.999          1      0.995      0.995\n","              K-002483         52         52      0.999          1      0.995      0.995\n","              K-003351         65         65      0.999      0.985       0.99       0.99\n","              K-003483        152        152          1          1      0.995      0.995\n","              K-003544         21         21      0.997          1      0.995      0.995\n","              K-003743         16         16      0.995          1      0.995      0.975\n","              K-003832         10         10      0.992        0.9      0.911      0.911\n","              K-004378         13         13      0.994          1      0.995      0.995\n","              K-004543          8          8      0.991          1      0.995      0.995\n","              K-005094         21         21      0.996          1      0.995      0.995\n","              K-005886         10         10      0.993          1      0.995      0.995\n","              K-006192         14         14      0.997          1      0.995      0.995\n","              K-006563          8          8      0.991          1      0.995      0.995\n","              K-010221          9          9      0.992          1      0.995      0.995\n","              K-012081         12         12      0.993      0.917      0.928      0.928\n","              K-012247          4          4      0.983          1      0.995      0.995\n","              K-012420          3          3      0.978          1      0.995      0.995\n","              K-012778         10         10      0.992          1      0.995      0.995\n","              K-013395         11         11      0.997          1      0.995      0.995\n","              K-013900          6          6      0.988          1      0.995      0.995\n","              K-016232         29         29      0.997          1      0.995      0.995\n","              K-016262         24         24      0.997          1      0.995      0.995\n","              K-016548         43         43      0.998      0.977      0.984      0.984\n","              K-016551         38         38      0.998          1      0.995      0.995\n","              K-016688          3          3       0.98          1      0.995      0.995\n","              K-018110          7          7      0.989          1      0.995      0.995\n","              K-018147          5          5       0.99          1      0.995      0.995\n","              K-018357          5          5      0.987          1      0.995      0.995\n","              K-019232         10         10      0.992          1      0.995      0.995\n","              K-019552         15         15      0.995          1      0.995      0.995\n","              K-019607         14         14      0.995          1      0.995      0.995\n","              K-019861         19         19      0.996          1      0.995      0.995\n","              K-020014          3          3          1          1      0.995      0.995\n","              K-020238         30         30      0.997          1      0.995      0.995\n","              K-020877         22         22      0.997          1      0.995      0.995\n","              K-021026         11         11          1          1      0.995      0.995\n","              K-021325          6          6      0.988          1      0.995      0.995\n","              K-021771          8          8      0.991          1      0.995      0.995\n","              K-022074         12         12      0.994          1      0.995      0.995\n","              K-022347         26         26      0.997          1      0.995      0.995\n","              K-022362         11         11      0.995          1      0.995      0.995\n","              K-022627          9          9      0.993          1      0.995      0.995\n","              K-023203          1          1          1          1      0.995      0.995\n","              K-023223         10         10      0.993          1      0.995      0.995\n","              K-024850         12         12      0.995          1      0.995      0.995\n","              K-025367         26         26      0.997          1      0.995      0.995\n","              K-025438         18         18      0.996          1      0.995      0.995\n","              K-025469         27         27      0.997          1      0.995      0.995\n","              K-027653         16         16      0.995          1      0.995      0.995\n","              K-027733         34         34      0.967      0.941      0.948      0.948\n","              K-027777         31         31      0.998          1      0.995      0.995\n","              K-027926         11         11      0.994          1      0.995      0.995\n","              K-027993          3          3      0.979          1      0.995      0.995\n","              K-028763         22         22      0.997          1      0.995      0.995\n","              K-029345         12         12      0.994          1      0.995      0.995\n","              K-029451          8          8      0.991          1      0.995      0.995\n","              K-029667         30         30      0.998          1      0.995      0.995\n","              K-029871          1          1      0.958          1      0.995      0.995\n","              K-030308         26         26      0.997          1      0.995      0.987\n","              K-031705         10         10      0.992          1      0.995      0.995\n","              K-031863          6          6          1          1      0.995      0.995\n","              K-031885         25         25          1      0.962      0.995      0.995\n","              K-032310          3          3      0.984          1      0.995      0.995\n","              K-033009         11         11      0.993          1      0.995      0.995\n","              K-033208          7          7          1          1      0.995      0.995\n","              K-033878          1          1      0.955          1      0.995      0.995\n","              K-033880          8          8      0.991          1      0.995      0.995\n","              K-034597         29         29      0.965          1      0.995      0.995\n","              K-035206         30         30      0.964      0.967      0.954      0.954\n","              K-036637         30         30      0.998          1      0.995      0.995\n","              K-038162          6          6      0.991          1      0.995      0.995\n","              K-041768          6          6      0.988          1      0.995      0.995\n","              K-044199          7          7       0.99          1      0.995      0.995\n","Speed: 0.2ms preprocess, 13.8ms inference, 0.0ms loss, 1.1ms postprocess per image\n","Results saved to \u001b[1m/content/drive/MyDrive/modeling_yolo/yolo_20250912_0043\u001b[0m\n"]}],"source":["# ============================================================================\n","# 3. YOLO ëª¨ë¸ í•™ìŠµ\n","# ============================================================================\n","\n","print(\"yaml_path=\",yaml_path)\n","\n","def train_yolo_model(yaml_path=yaml_path):\n","    \"\"\"YOLO ëª¨ë¸ í›ˆë ¨\"\"\"\n","    # YOLOv8n ëª¨ë¸ ë¡œë“œ (ê°€ì¥ ë¹ ë¥¸ ë²„ì „)\n","    model = YOLO('yolov8x.pt')\n","    #model = YOLO('yolov8n.pt')  # nano ë²„ì „ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\n","    #model = YOLO('yolov8s.pt')  # nano ë²„ì „ìœ¼ë¡œ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸\n","\n","    model_save_name = f\"yolo_{datetime.now(__kst).strftime('%Y%m%d_%H%M')}\"\n","    # í›ˆë ¨ ì„¤ì •\n","    results = model.train(\n","        data=yaml_path,           # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼\n","        epochs=30,                # ì—í¬í¬ ìˆ˜ (í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 50)\n","        imgsz=640,               # ì´ë¯¸ì§€ í¬ê¸°\n","        batch=16,                # ë°°ì¹˜ í¬ê¸°\n","        device=__device,           # GPU ì‚¬ìš©\n","        project=get_path_modeling(),  # í”„ë¡œì íŠ¸ ì´ë¦„\n","        name=model_save_name,       # ì‹¤í—˜ ì´ë¦„\n","        save_period=10,          # 10 ì—í¬í¬ë§ˆë‹¤ ì €ì¥\n","        patience=10,             # ì¡°ê¸° ì¢…ë£Œ ì„¤ì •\n","        resume=False,            # ì²˜ìŒë¶€í„° ì‹œì‘\n","        verbose=True             # ìì„¸í•œ ë¡œê·¸ ì¶œë ¥\n","    )\n","\n","    return model, results, model_save_name\n","\n","# í›ˆë ¨ ì‹œì‘\n","print(\"\\n=== YOLO ëª¨ë¸ í›ˆë ¨ ì‹œì‘ ===\")\n","model, train_results, model_save_name = train_yolo_model(yaml_path=yaml_path)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ahzyEaU1MlGv"},"outputs":[],"source":["model_save_name = f\"yolo_{datetime.now(__kst).strftime('%Y%m%d_%H%M')}\"\n","print(model_save_name)\n","yolo_best_model_path = os.path.join(get_path_modeling(), model_save_name, \"weights\", \"best.pt\")\n","print(f\"ìµœì  ëª¨ë¸ ê²½ë¡œ: {yolo_best_model_path}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ezrx3HeeMlGv"},"outputs":[],"source":["# ============================================================================\n","# 4. í›ˆë ¨ ê²°ê³¼ ë¶„ì„\n","# ============================================================================\n","\n","def analyze_training_results():\n","    \"\"\"í›ˆë ¨ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”\"\"\"\n","    # ê²°ê³¼ ê²½ë¡œ\n","    results_path = os.path.join(get_path_modeling(), 'yolo_20250906_205051')\n","\n","    # í›ˆë ¨ ê³¡ì„  í‘œì‹œ\n","    if os.path.exists(f\"{results_path}/results.png\"):\n","        img = Image.open(f\"{results_path}/results.png\")\n","        plt.figure(figsize=(12, 8))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"YOLO í›ˆë ¨ ê²°ê³¼\")\n","        plt.show()\n","\n","    # í˜¼ë™ í–‰ë ¬ í‘œì‹œ\n","    if os.path.exists(f\"{results_path}/confusion_matrix.png\"):\n","        img = Image.open(f\"{results_path}/confusion_matrix.png\")\n","        plt.figure(figsize=(8, 6))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"í˜¼ë™ í–‰ë ¬ (Confusion Matrix)\")\n","        plt.show()\n","\n","    # F1 ê³¡ì„  í‘œì‹œ\n","    if os.path.exists(f\"{results_path}/F1_curve.png\"):\n","        img = Image.open(f\"{results_path}/F1_curve.png\")\n","        plt.figure(figsize=(8, 6))\n","        plt.imshow(img)\n","        plt.axis('off')\n","        plt.title(\"F1 ì ìˆ˜ ê³¡ì„ \")\n","        plt.show()\n","\n","analyze_training_results()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_sdVcvaMlGv"},"outputs":[],"source":["# ============================================================================\n","# 5. ëª¨ë¸ ê²€ì¦ ë° mAP ê³„ì‚°\n","# ============================================================================\n","\n","def validate_model():\n","    \"\"\"ê²€ì¦ ë°ì´í„°ë¡œ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€\"\"\"\n","    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ\n","    best_model = YOLO(os.path.join(get_path_modeling_release(), 'yolo_20250906_205051','weights','best.pt'))\n","\n","    # ê²€ì¦ ìˆ˜í–‰\n","    val_results = best_model.val(\n","        data=yaml_path,\n","        imgsz=640,\n","        batch=16,\n","        device=device\n","    )\n","\n","    print(\"\\n=== ê²€ì¦ ê²°ê³¼ ===\")\n","    print(f\"mAP@0.5: {val_results.box.map50:.3f}\")\n","    print(f\"mAP@0.5:0.95: {val_results.box.map:.3f}\")\n","    print(f\"Precision: {val_results.box.mp:.3f}\")\n","    print(f\"Recall: {val_results.box.mr:.3f}\")\n","\n","    # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥\n","    if hasattr(val_results.box, 'maps'):\n","        class_names = ['cat', 'dog']  # ì¶”ì •\n","        for i, class_name in enumerate(class_names):\n","            if i < len(val_results.box.maps):\n","                print(f\"{class_name} mAP@0.5: {val_results.box.maps[i]:.3f}\")\n","\n","    return best_model, val_results\n","\n","# ëª¨ë¸ ê²€ì¦\n","print(\"\\n=== ëª¨ë¸ ê²€ì¦ ì‹œì‘ ===\")\n","best_model, validation_results = validate_model()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ihx241b4MlGv"},"outputs":[],"source":["print_dir_tree(yolo_dataset_path)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mgv2dIlAMlGv"},"outputs":[],"source":["from pathlib import Path\n","\n","def test_on_samples(best_model):\n","    \"\"\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì—ì„œ ìƒ˜í”Œ ì˜ˆì¸¡\"\"\"\n","    test_dir = os.path.join(yolo_dataset_path, 'images', 'test')\n","    test_images = list(Path(test_dir).glob(\"*.jpg\"))[:12]  # ì²˜ìŒ 12ê°œë§Œ\n","\n","    if not test_images:\n","        print(\"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","        return\n","\n","    print(f\"\\n=== {len(test_images)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ì˜ˆì¸¡ ===\")\n","\n","    # ì˜ˆì¸¡ ìˆ˜í–‰\n","    results = best_model(test_images)\n","\n","    # ê²°ê³¼ ì‹œê°í™”\n","    fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n","    axes = axes.flatten()\n","\n","    class_names = ['cat', 'dog']\n","\n","    for idx, (result, ax) in enumerate(zip(results, axes)):\n","        img = result.orig_img\n","        annotated = result.plot()\n","        ax.imshow(annotated)\n","        ax.axis('off')\n","        if len(result.boxes) > 0:\n","            conf = result.boxes.conf[0].item()\n","            cls = int(result.boxes.cls[0].item())\n","            pred_class = class_names[cls] if cls < len(class_names) else 'unknown'\n","            ax.set_title(f'{pred_class} ({conf:.2f})')\n","        else:\n","            ax.set_title('No Detection')\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","# í…ŒìŠ¤íŠ¸ ìƒ˜í”Œ ì˜ˆì¸¡\n","test_on_samples(best_model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vJW2px3eMlGv"},"outputs":[],"source":["\n","# ============================================================================\n","# 7. ì„±ëŠ¥ ìš”ì•½ ë° ê°œì„  ë°©ì•ˆ\n","# ============================================================================\n","\n","def performance_summary():\n","    \"\"\"ì„±ëŠ¥ ìš”ì•½ ë° ë¶„ì„\"\"\"\n","    print(\"\\n\" + \"=\"*60)\n","    print(\"                    ì„±ëŠ¥ ìš”ì•½\")\n","    print(\"=\"*60)\n","\n","    # ë°ì´í„°ì…‹ ì •ë³´\n","    print(f\"ğŸ“Š ë°ì´í„°ì…‹ ê·œëª¨:\")\n","    print(f\"   - í›ˆë ¨: 2,564ê°œ\")\n","    print(f\"   - ê²€ì¦: 1,100ê°œ\")\n","    print(f\"   - í…ŒìŠ¤íŠ¸: 3,659ê°œ\")\n","    print(f\"   - ì´ í´ë˜ìŠ¤: 2ê°œ (ê³ ì–‘ì´/ê°•ì•„ì§€)\")\n","    print(f\"   - í’ˆì¢… ìˆ˜: 37ê°œ (ê³ ì–‘ì´ 12ê°œ, ê°•ì•„ì§€ 25ê°œ)\")\n","\n","    print(f\"\\nğŸ¯ ëª¨ë¸ ì„±ëŠ¥:\")\n","    if 'validation_results' in globals():\n","        print(f\"   - mAP@0.5: {validation_results.box.map50:.1%}\")\n","        print(f\"   - mAP@0.5:0.95: {validation_results.box.map:.1%}\")\n","        print(f\"   - Precision: {validation_results.box.mp:.1%}\")\n","        print(f\"   - Recall: {validation_results.box.mr:.1%}\")\n","\n","    print(f\"\\nğŸ’¡ ê°œì„  ë°©ì•ˆ:\")\n","    print(\"   1. ì—í¬í¬ ìˆ˜ ì¦ê°€ (100-200 epochs)\")\n","    print(\"   2. ë” í° ëª¨ë¸ ì‚¬ìš© (YOLOv8s, YOLOv8m)\")\n","    print(\"   3. ë°ì´í„° ì¦ê°• ê¸°ë²• ì ìš©\")\n","    print(\"   4. í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹\")\n","    print(\"   5. ì•™ìƒë¸” ëª¨ë¸ ì ìš©\")\n","\n","performance_summary()\n","\n","# ============================================================================\n","# 8. ì¶”ê°€ ë¶„ì„ í•¨ìˆ˜ë“¤\n","# ============================================================================\n","\n","from pathlib import Path\n","def analyze_class_distribution():\n","    \"\"\"í´ë˜ìŠ¤ë³„ ë°ì´í„° ë¶„í¬ ë¶„ì„\"\"\"\n","    train_label_dir = Path(os.path.join(yolo_dataset_path, 'labels', 'train'))\n","\n","    cat_count = 0\n","    dog_count = 0\n","\n","    for label_file in train_label_dir.glob(\"*.txt\"):\n","        with open(label_file, 'r') as f:\n","            lines = f.readlines()\n","            for line in lines:\n","                class_id = int(line.split()[0])\n","                if class_id == 0:  # ê³ ì–‘ì´ (ì¶”ì •)\n","                    cat_count += 1\n","                elif class_id == 1:  # ê°•ì•„ì§€ (ì¶”ì •)\n","                    dog_count += 1\n","\n","    print(f\"\\n=== í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬ ===\")\n","    print(f\"ê³ ì–‘ì´ ê°ì²´ ìˆ˜: {cat_count}ê°œ\")\n","    print(f\"ê°•ì•„ì§€ ê°ì²´ ìˆ˜: {dog_count}ê°œ\")\n","    print(f\"ì´ ê°ì²´ ìˆ˜: {cat_count + dog_count}ê°œ\")\n","\n","    # ë¶„í¬ ì‹œê°í™”\n","    plt.figure(figsize=(8, 6))\n","    plt.bar(['Cat', 'Dog'], [cat_count, dog_count],\n","            color=['orange', 'skyblue'], alpha=0.7)\n","    plt.title('í›ˆë ¨ ë°ì´í„° í´ë˜ìŠ¤ ë¶„í¬')\n","    plt.ylabel('ê°ì²´ ìˆ˜')\n","    plt.show()\n","\n","# í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„ ì‹¤í–‰\n","analyze_class_distribution()\n","\n","print(\"\\nğŸ‰ YOLO í…ŒìŠ¤íŠ¸ ì™„ë£Œ!\")\n","print(\"ë” ìì„¸í•œ ê²°ê³¼ëŠ” 'yolo_pet_detection/cat_dog_v1' í´ë”ë¥¼ í™•ì¸í•˜ì„¸ìš”.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2TagaMdpMlGv"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","ret, frame = cap.read()\n","cap.release()\n","\n","if ret and frame is not None:\n","    plt.imshow(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n","    plt.axis('off')\n","    plt.show()\n","else:\n","    print(\"ì¹´ë©”ë¼ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1R4i4XDuMlGv"},"outputs":[],"source":["def yolo_live_cam_counter(yolo_best_model_path=yolo_best_model_path):\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    frame_count = 0\n","\n","    print(\"íƒì§€ ì¹´ìš´í„° ëª¨ë“œ (ESCë¡œ ì¢…ë£Œ)\")\n","    print(\"10ì´ˆë§ˆë‹¤ ê²°ê³¼ë¥¼ ìš”ì•½í•´ì„œ ì¶œë ¥í•©ë‹ˆë‹¤.\")\n","\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        results = model(frame, verbose=False, conf=0.6)\n","        annotated_frame = results[0].plot()\n","\n","        # íƒì§€ ê²°ê³¼ ì¹´ìš´íŠ¸\n","        if len(results[0].boxes) > 0:\n","            cls = int(results[0].boxes.cls[0].item())\n","            detected_class = class_names[cls]\n","            detection_counts[detected_class] += 1\n","        else:\n","            detection_counts['none'] += 1\n","\n","        frame_count += 1\n","\n","        # 10ì´ˆë§ˆë‹¤ (300í”„ë ˆì„) ìš”ì•½ ì¶œë ¥\n","        if frame_count % 300 == 0:\n","            total = sum(detection_counts.values())\n","            print(f\"\\n=== {frame_count//30}ì´ˆ ê²½ê³¼ ===\")\n","            print(f\"ê³ ì–‘ì´: {detection_counts['cat']}íšŒ ({detection_counts['cat']/total*100:.1f}%)\")\n","            print(f\"ê°•ì•„ì§€: {detection_counts['dog']}íšŒ ({detection_counts['dog']/total*100:.1f}%)\")\n","            print(f\"ë¯¸íƒì§€: {detection_counts['none']}íšŒ ({detection_counts['none']/total*100:.1f}%)\")\n","\n","        cv2.imshow('YOLO ì¹´ìš´í„°', annotated_frame)\n","\n","        if cv2.waitKey(1) & 0xFF == 27:\n","            break\n","\n","    cap.release()\n","    cv2.destroyAllWindows()\n","\n","    # ìµœì¢… ê²°ê³¼\n","    print(\"\\n=== ìµœì¢… ê²°ê³¼ ===\")\n","    total = sum(detection_counts.values())\n","    for class_name, count in detection_counts.items():\n","        print(f\"{class_name}: {count}íšŒ ({count/total*100:.1f}%)\")\n","\n","# ì¹´ìš´í„° ë²„ì „ ì‹¤í–‰\n","yolo_live_cam_counter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3XS-XquGMlGv"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output, HTML\n","import time\n","from ultralytics import YOLO\n","import threading\n","import base64\n","from io import BytesIO\n","\n","# ë°©ë²• 1: ì£¼ê¸°ì  ì—…ë°ì´íŠ¸ ë°©ì‹\n","def yolo_live_cam_notebook(yolo_best_model_path=yolo_best_model_path, duration=30):\n","    \"\"\"\n","    ë…¸íŠ¸ë¶ì—ì„œ ì‹¤ì‹œê°„ YOLO íƒì§€ (ì£¼ê¸°ì  í™”ë©´ ê°±ì‹ )\n","    duration: ì‹¤í–‰ ì‹œê°„(ì´ˆ)\n","    \"\"\"\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(1, cv2.CAP_DSHOW)\n","    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)\n","    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    start_time = time.time()\n","    frame_count = 0\n","\n","    print(f\"YOLO ì‹¤ì‹œê°„ íƒì§€ ì‹œì‘ ({duration}ì´ˆê°„ ì‹¤í–‰)\")\n","\n","    try:\n","        results = None\n","        while time.time() - start_time < duration:\n","            ret, frame = cap.read()\n","            if not ret:\n","                break\n","\n","            # YOLO íƒì§€ (ë§¤ 5í”„ë ˆì„ë§ˆë‹¤)\n","            if frame_count % 10 == 0:\n","                results = model(frame, verbose=False, conf=0.6)\n","                annotated_frame = results[0].plot()\n","\n","                # íƒì§€ ê²°ê³¼ ì¹´ìš´íŠ¸\n","                if len(results[0].boxes) > 0:\n","                    cls = int(results[0].boxes.cls[0].item())\n","                    detected_class = class_names[cls]\n","                    detection_counts[detected_class] += 1\n","                    conf = results[0].boxes.conf[0].item()\n","                    current_detection = f\"{detected_class} ({conf:.2f})\"\n","                else:\n","                    detection_counts['none'] += 1\n","                    current_detection = \"ë¯¸íƒì§€\"\n","\n","                # 2ì´ˆë§ˆë‹¤ í™”ë©´ ì—…ë°ì´íŠ¸ (60í”„ë ˆì„ë§ˆë‹¤)\n","            if results is not None:\n","                if frame_count % 2 == 0:\n","                    clear_output(wait=True)\n","\n","                    # í˜„ì¬ í”„ë ˆì„ í‘œì‹œ\n","                    plt.figure(figsize=(12, 8))\n","\n","                    plt.subplot(2, 2, 1)\n","                    plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n","                    plt.title(f'í˜„ì¬ íƒì§€: {current_detection}')\n","                    plt.axis('off')\n","\n","                    # í†µê³„ ê·¸ë˜í”„\n","                    plt.subplot(2, 2, 2)\n","                    total = sum(detection_counts.values())\n","                    if total > 0:\n","                        labels = list(detection_counts.keys())\n","                        values = [detection_counts[k] for k in labels]\n","                        colors = ['orange', 'skyblue', 'lightgray']\n","\n","                        plt.pie(values, labels=labels, colors=colors, autopct='%1.1f%%')\n","                        plt.title(f'íƒì§€ ë¶„í¬ (ì´ {total}í”„ë ˆì„)')\n","\n","                    # ì‹œê°„ë³„ í†µê³„\n","                    plt.subplot(2, 1, 2)\n","                    elapsed = time.time() - start_time\n","                    remaining = duration - elapsed\n","\n","                    bars = plt.bar(labels, [detection_counts[k] for k in labels], color=colors)\n","                    plt.title(f'íƒì§€ íšŸìˆ˜ (ê²½ê³¼: {elapsed:.1f}s, ë‚¨ìŒ: {remaining:.1f}s)')\n","                    plt.ylabel('íšŸìˆ˜')\n","\n","                    # ê°’ í‘œì‹œ\n","                    for bar, value in zip(bars, [detection_counts[k] for k in labels]):\n","                        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                               str(value), ha='center', va='bottom')\n","\n","                    plt.tight_layout()\n","                    plt.show()\n","\n","\n","            frame_count += 1\n","            # ESC ë˜ëŠ” q í‚¤ ì…ë ¥ ì‹œ ì¤‘ë‹¨\n","            key = cv2.waitKey(1) & 0xFF\n","            if key == 27 or key == ord('q'):\n","                print(\"ì‚¬ìš©ì ì…ë ¥(q ë˜ëŠ” ESC)ìœ¼ë¡œ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n","                break\n","            # duration ì´ˆ ê²½ê³¼ ì‹œ ìë™ ì¤‘ë‹¨\n","            if time.time() - start_time > duration:\n","                print(\"ì„¤ì •ëœ ì‹œê°„ì´ ê²½ê³¼í•˜ì—¬ ìë™ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n","                break\n","            time.sleep(0.03)  # ì•½ 30 FPS\n","\n","    except KeyboardInterrupt:\n","        print(\"\\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","    finally:\n","        cap.release()\n","\n","        # ìµœì¢… ê²°ê³¼\n","        print(f\"\\n=== ìµœì¢… ê²°ê³¼ ===\")\n","        total = sum(detection_counts.values())\n","        for class_name, count in detection_counts.items():\n","            if total > 0:\n","                percentage = count/total*100\n","                print(f\"{class_name}: {count}íšŒ ({percentage:.1f}%)\")\n","\n","# ì‹¤í–‰\n","yolo_live_cam_notebook(duration=20)  # 30ì´ˆê°„ ì‹¤í–‰"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LUpx28KtMlGv"},"outputs":[],"source":["yolo_live_cam_notebook(duration=10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fs1KSs1KMlGw"},"outputs":[],"source":["import cv2\n","import matplotlib.pyplot as plt\n","from IPython.display import display, clear_output\n","import time\n","from ultralytics import YOLO\n","\n","def yolo_mp4_notebook(mp4_path, yolo_best_model_path=yolo_best_model_path, max_frames=500):\n","    \"\"\"\n","    mp4 ë™ì˜ìƒì—ì„œ YOLO íƒì§€ ê²°ê³¼ë¥¼ ë…¸íŠ¸ë¶ì—ì„œ ì‹œê°í™”\n","    mp4_path: ë™ì˜ìƒ íŒŒì¼ ê²½ë¡œ\n","    max_frames: ìµœëŒ€ ì²˜ë¦¬ í”„ë ˆì„ ìˆ˜ (Noneì´ë©´ ì „ì²´)\n","    \"\"\"\n","    model = YOLO(yolo_best_model_path)\n","    class_names = ['cat', 'dog']\n","\n","    cap = cv2.VideoCapture(mp4_path)\n","    if not cap.isOpened():\n","        print(f\"ë™ì˜ìƒ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {mp4_path}\")\n","        return\n","\n","    detection_counts = {'cat': 0, 'dog': 0, 'none': 0}\n","    frame_count = 0\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","    print(f\"YOLO mp4 íƒì§€ ì‹œì‘ (ì´ {total_frames}í”„ë ˆì„, ìµœëŒ€ {max_frames if max_frames else total_frames}í”„ë ˆì„)\")\n","\n","    try:\n","        while True:\n","            ret, frame = cap.read()\n","            if not ret:\n","                print(\"ë™ì˜ìƒ í”„ë ˆì„ì„ ë” ì´ìƒ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","                break\n","\n","            results = model(frame, verbose=False, conf=0.6)\n","            annotated_frame = results[0].plot()\n","\n","            # íƒì§€ ê²°ê³¼ ì¹´ìš´íŠ¸\n","            if len(results[0].boxes) > 0:\n","                for box in results[0].boxes:\n","                    cls = int(box.cls.item())\n","                    detected_class = class_names[cls]\n","                    detection_counts[detected_class] += 1\n","                conf = results[0].boxes.conf[0].item()\n","                current_detection = f\"{detected_class} ({conf:.2f})\"\n","            else:\n","                detection_counts['none'] += 1\n","                current_detection = \"ë¯¸íƒì§€\"\n","\n","            # 10í”„ë ˆì„ë§ˆë‹¤ í™”ë©´ ì—…ë°ì´íŠ¸\n","            if frame_count % 10 == 0:\n","                clear_output(wait=True)\n","                plt.figure(figsize=(12, 8))\n","                plt.subplot(2, 2, 1)\n","                plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n","                plt.title(f'í˜„ì¬ íƒì§€: {current_detection} (í”„ë ˆì„ {frame_count}/{total_frames})')\n","                plt.axis('off')\n","\n","                # í†µê³„ ê·¸ë˜í”„\n","                plt.subplot(2, 2, 2)\n","                total = sum(detection_counts.values())\n","                labels = list(detection_counts.keys())\n","                values = [detection_counts[k] for k in labels]\n","                colors = ['orange', 'skyblue', 'lightgray']\n","                if total > 0:\n","                    plt.pie(values, labels=labels, colors=colors, autopct='%1.1f%%')\n","                    plt.title(f'íƒì§€ ë¶„í¬ (ì´ {total}í”„ë ˆì„)')\n","\n","                # ì‹œê°„ë³„ í†µê³„\n","                plt.subplot(2, 1, 2)\n","                bars = plt.bar(labels, values, color=colors)\n","                plt.title(f'íƒì§€ íšŸìˆ˜ (í”„ë ˆì„: {frame_count})')\n","                plt.ylabel('íšŸìˆ˜')\n","                for bar, value in zip(bars, values):\n","                    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,\n","                             str(value), ha='center', va='bottom')\n","                plt.tight_layout()\n","                plt.show()\n","\n","            frame_count += 1\n","            if max_frames and frame_count >= max_frames:\n","                print(\"ìµœëŒ€ í”„ë ˆì„ ìˆ˜ì— ë„ë‹¬í•˜ì—¬ ì¤‘ë‹¨í•©ë‹ˆë‹¤.\")\n","                break\n","\n","            time.sleep(0.01)  # ë„ˆë¬´ ë¹ ë¥¸ ì²˜ë¦¬ ë°©ì§€\n","\n","    except KeyboardInterrupt:\n","        print(\"\\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n","    finally:\n","        cap.release()\n","        print(f\"\\n=== ìµœì¢… ê²°ê³¼ ===\")\n","        total = sum(detection_counts.values())\n","        for class_name, count in detection_counts.items():\n","            if total > 0:\n","                percentage = count/total*100\n","                print(f\"{class_name}: {count}íšŒ ({percentage:.1f}%)\")\n","\n","# ì‚¬ìš© ì˜ˆì‹œ\n","mp4_path = r\"dog.mp4\"\n","yolo_mp4_notebook(mp4_path, max_frames=300)"]}],"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"L4"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"24816e0122cf4c058127b5a4e2cee908":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d5676358062d41e39a3734d658d52a37","IPY_MODEL_e0a75d1cd56e44788b3b4eb575d2ae2c","IPY_MODEL_b098f041193a4882b2f8dad7815deb7d"],"layout":"IPY_MODEL_d2a93d522b3f44c1a5bfaaab6b0e29ef"}},"d5676358062d41e39a3734d658d52a37":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_71d5cc6214c243d9ba22fd2982b157bf","placeholder":"â€‹","style":"IPY_MODEL_d60d3d229d1f43de9808f6cf19d61d97","value":"Creatingâ€‡YOLOâ€‡dataset:â€‡100%"}},"e0a75d1cd56e44788b3b4eb575d2ae2c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_761c6eaa6d8b440a9225f6d6ed61117c","max":5369,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8a9be69c35014cbe85c96d4392265fc9","value":5369}},"b098f041193a4882b2f8dad7815deb7d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1e7961a59b744823b460a16a4d59193a","placeholder":"â€‹","style":"IPY_MODEL_fd638b147d944be69005e5897720d3f4","value":"â€‡5369/5369â€‡[00:01&lt;00:00,â€‡2988.47it/s,â€‡K-003544-010221-016551-021026_0_2_0_2_90_000_200.png]"}},"d2a93d522b3f44c1a5bfaaab6b0e29ef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71d5cc6214c243d9ba22fd2982b157bf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d60d3d229d1f43de9808f6cf19d61d97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"761c6eaa6d8b440a9225f6d6ed61117c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8a9be69c35014cbe85c96d4392265fc9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1e7961a59b744823b460a16a4d59193a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fd638b147d944be69005e5897720d3f4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fe8aeea207ed441d9aa2773db23c97d6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c419bc980fec415a944c6e6e2dd8ad98","IPY_MODEL_d5086a914578434fb4a31403b5792a03","IPY_MODEL_a8ebacd7e8e040328ff249ff891a601d"],"layout":"IPY_MODEL_a42111a1c71c4cd28ec4394699586313"}},"c419bc980fec415a944c6e6e2dd8ad98":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f83dd9a5bdd443f5b518d386a69eb075","placeholder":"â€‹","style":"IPY_MODEL_e7e1efdc57684c219d9caf7b3f13c375","value":"Creatingâ€‡label-onlyâ€‡YOLOâ€‡dataset:â€‡100%"}},"d5086a914578434fb4a31403b5792a03":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e71aa091bc7647c79b74ce754f3ad404","max":2332,"min":0,"orientation":"horizontal","style":"IPY_MODEL_27add70b337647dca61c36c66fa8a943","value":2332}},"a8ebacd7e8e040328ff249ff891a601d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1549aadb94ce422ebddabfde483ec2b4","placeholder":"â€‹","style":"IPY_MODEL_fe60a5cc55d84ea0b86b03cf43e21caa","value":"â€‡2332/2332â€‡[04:45&lt;00:00,â€‡â€‡6.13it/s,â€‡K-003544-010221-016548-029451_0_2_0_2_75_000_200.png]"}},"a42111a1c71c4cd28ec4394699586313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f83dd9a5bdd443f5b518d386a69eb075":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7e1efdc57684c219d9caf7b3f13c375":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e71aa091bc7647c79b74ce754f3ad404":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"27add70b337647dca61c36c66fa8a943":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1549aadb94ce422ebddabfde483ec2b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe60a5cc55d84ea0b86b03cf43e21caa":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}