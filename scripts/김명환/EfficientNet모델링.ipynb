{"cells":[{"cell_type":"markdown","metadata":{"id":"G3tb146HKUGS"},"source":["# [ì´ˆê¸‰ í”„ë¡œì íŠ¸] 4íŒ€_ê¹€ëª…í™˜"]},{"cell_type":"markdown","metadata":{"id":"hmaVeBaGKUGW"},"source":["---\n","---"]},{"cell_type":"markdown","metadata":{"id":"KzN8SzLMKgH1"},"source":["# í”„ë¡œê·¸ë˜ë°"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":52826,"status":"ok","timestamp":1757943744415,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"ECzUDN-OzK99","outputId":"9f32de4e-3824-4f69-adc7-fc4b9a05e941"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m88.7/88.7 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hë¡œë”©ì™„ë£Œ\n"]}],"source":["!pip install -q gdown\n","!pip install -q albumentations\n","!pip install -q ultralytics\n","!pip install -q -U ultralytics\n","!pip install -q nbformat\n","!pip install -q roboflow\n","!pip install -q opencv-python\n","!pip install -q opencv-python-headless\n","!pip install -q wandb\n","!pip install -q timm\n","!pip install -q torchvision\n","#!pip install -q torch torchvision tqdm pillow matplotlib\n","\n","print(\"ë¡œë”©ì™„ë£Œ\")"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2816,"status":"ok","timestamp":1757943747239,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"OAK5c2b2zK9-","outputId":"82c564a9-fee6-441e-bc47-9d6f0421b06c"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]}],"source":["!wandb login 86a7b8c07184b2efdfb116546a17b1905e41cb5d"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14938,"status":"ok","timestamp":1757943762211,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"47-Qf8TYKUGW","outputId":"b522af5b-6a0b-45f5-ebb9-627c84cf6395"},"outputs":[{"output_type":"stream","name":"stdout","text":["ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜: cuda\n"]}],"source":["# ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ (ì¤‘ë³µ ì œê±° ë° ì •ë¦¬)\n","\n","# --- Scikit-learn: ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸, í‰ê°€ ---\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.datasets import (\n","    fetch_california_housing, load_iris, make_moons, make_circles,\n","    load_breast_cancer, load_wine\n",")\n","from sklearn import datasets\n","from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier, plot_tree\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, mean_squared_error, average_precision_score\n","\n","# --- ì´ë¯¸ì§€ ì²˜ë¦¬ ---\n","import cv2\n","from PIL import Image, ImageFilter, ImageDraw\n","import albumentations as A\n","\n","# --- PyTorch: ë”¥ëŸ¬ë‹ ê´€ë ¨ ---\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader, Subset\n","# ë¬¸ì œ ìˆëŠ” v2 import ì œê±°í•˜ê³  í•„ìš”ì‹œì—ë§Œ ê°œë³„ì ìœ¼ë¡œ import\n","# from torchvision.transforms import v2, functional as TF\n","from torchvision.transforms import functional as TF\n","from torchvision.datasets import CocoDetection\n","from torch.nn import CrossEntropyLoss\n","from collections import OrderedDict\n","\n","# --- COCO ë°ì´í„°ì…‹ ê´€ë ¨ ---\n","from pycocotools.coco import COCO\n","from pycocotools import mask as coco_mask\n","\n","# --- ë”¥ëŸ¬ë‹ ëª¨ë¸ ---\n","import timm\n","\n","# --- ê¸°ë³¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ---\n","import os\n","import sys\n","import re\n","import csv\n","import copy\n","import json\n","import math\n","import random\n","import yaml\n","import shutil\n","import requests\n","import xml.etree.ElementTree as ET\n","from pathlib import Path\n","\n","# --- ë°ì´í„° ë¶„ì„ ë° ì‹œê°í™” ---\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","# --- ì‹œê°„ ê´€ë ¨ ---\n","from datetime import datetime, timezone, timedelta\n","import pytz\n","\n","# --- ì§„í–‰ë¥  í‘œì‹œ ---\n","import IPython.display\n","from tqdm.notebook import tqdm\n","\n","# --- ì‹œê°„ëŒ€ ì„¤ì • ---\n","__kst = pytz.timezone('Asia/Seoul')\n","\n","# --- GPU ì„¤ì • ---\n","__device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","__device_cpu = torch.device('cpu')\n","\n","# --- ì¬í˜„ ê°€ëŠ¥í•œ ê²°ê³¼ë¥¼ ìœ„í•œ ì‹œë“œ ì„¤ì • ---\n","np.random.seed(42)\n","torch.manual_seed(42)\n","if __device.type == 'cuda':\n","    torch.cuda.manual_seed_all(42)\n","\n","print(f\"ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œë“œ ì™„ë£Œ ì‚¬ìš©ì¥ì¹˜: {__device}\")"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":198847,"status":"ok","timestamp":1757943961060,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"gDTmqQCCrBWm","outputId":"a0505bf8-148a-462f-a051-93f7b6b6cb69"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","install fonts-nanum...\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n"]},{"output_type":"execute_result","data":{"text/plain":["<module 'helper_c0z0c_dev' from '/content/helper_c0z0c_dev.py'>"]},"metadata":{},"execution_count":4}],"source":["from urllib.request import urlretrieve; urlretrieve(\"https://raw.githubusercontent.com/c0z0c/jupyter_hangul/refs/heads/beta/helper_c0z0c_dev.py\", \"helper_c0z0c_dev.py\")\n","import importlib\n","import helper_c0z0c_dev as helper\n","importlib.reload(helper)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12337,"status":"ok","timestamp":1757943973407,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"WE6336hF11C5","outputId":"42cfe43d-2517-48ce-8757-a9a06d46b293"},"outputs":[{"output_type":"stream","name":"stdout","text":["utils_dir: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\n","sys.path: ['/content', '/env/python', '/usr/lib/python312.zip', '/usr/lib/python3.12', '/usr/lib/python3.12/lib-dynload', '', '/usr/local/lib/python3.12/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.12/dist-packages/IPython/extensions', '/root/.ipython', '/tmp/tmpt44uublu', '/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils']\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","ğŸŒ https://c0z0c.github.io/jupyter_hangul\n","â„¹ï¸ NumPy 2.0.2 (v2.x+): í˜¸í™˜ì„± ëª¨ë“œ ì ìš©ë¨\n","Mounted at /content/drive\n","âœ… ì„¤ì • ì™„ë£Œ: í•œê¸€ í°íŠ¸, plt ì „ì—­ ë“±ë¡, pandas í™•ì¥, ìºì‹œ ê¸°ëŠ¥\n","pd commit ì €ì¥ ê²½ë¡œ = /content/drive/MyDrive\n","helper.__file__: /content/helper_c0z0c_dev.py\n","health_ea_utils.__file__: /content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils/health_ea_utils.py\n"]}],"source":["import os, sys\n","from pathlib import Path\n","\n","utils_dir = None\n","if helper.is_colab:\n","    utils_dir = \"/content/drive/MyDrive/codeit_ai_health_eat/src/python_modules/utils\"\n","else:\n","    utils_dir = os.path.join(Path.cwd().drive + '\\\\', 'GoogleDrive', \"codeit_ai_health_eat\", \"src\", \"python_modules\", \"utils\")\n","\n","print(\"utils_dir:\", utils_dir)\n","\n","sys.path.append(str(utils_dir))\n","print(\"sys.path:\", sys.path)\n","import importlib\n","import health_ea_utils as heu\n","importlib.reload(heu)\n","from health_ea_utils import *\n","\n","print(\"helper.__file__:\", helper.__file__)\n","print(\"health_ea_utils.__file__:\", heu.__file__)\n"]},{"cell_type":"markdown","metadata":{"id":"20rBdRxvKUGZ"},"source":["# 1. í•™ìŠµìš© ë°ì´íƒ€ ë‹¤ìš´ë¡œë“œ ë° ì••ì¶• í’€ê¸°"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1757943973508,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"A3JHrVMkzK9_","outputId":"71dc2372-9660-4907-ea23-f079840b95e6"},"outputs":[{"output_type":"stream","name":"stdout","text":["ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\n"]}],"source":["def get_tqdm_kwargs():\n","    \"\"\"Widget ì˜¤ë¥˜ë¥¼ ë°©ì§€í•˜ëŠ” ì•ˆì „í•œ tqdm ì„¤ì •\"\"\"\n","    return {\n","        'disable': False,\n","        'leave': True,\n","        'file': sys.stdout,\n","        'ascii': True,  # ASCII ë¬¸ìë§Œ ì‚¬ìš©\n","        'dynamic_ncols': False,\n","#        'ncols': 80  # ê³ ì • í­\n","    }\n","\n","def drive_root():\n","    root_path = os.path.join(\"D:\\\\\", \"GoogleDrive\")\n","    if helper.is_colab:\n","        root_path = os.path.join(\"/content/drive/MyDrive\")\n","    return root_path\n","\n","def get_path_modeling(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def get_path_modeling_release(add_path = None):\n","    modeling_path = \"modeling_yolo\"\n","    path = os.path.join(drive_root(),modeling_path)\n","    if add_path is not None:\n","        path = os.path.join(path,add_path)\n","    return path\n","\n","def print_dir_tree(root, max_depth=2, list_count=3, indent=\"\"):\n","    import os\n","    if max_depth < 0:\n","        return\n","    try:\n","        items = os.listdir(root)\n","    except Exception as e:\n","        print(indent + f\"[Error] {e}\")\n","        return\n","\n","    img_count = len([f for f in os.listdir(root) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","    for item in items:\n","        path = os.path.join(root, item)\n","        if os.path.isdir(path):\n","            print(indent + \"|-- \"+ item)\n","            # ì´ë¯¸ì§€ íŒŒì¼ ê°œìˆ˜ë§Œ ì¶œë ¥\n","            img_count = len([f for f in os.listdir(path) if f.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt'))])\n","            if img_count > list_count:\n","                print(indent + \"   \"+ f\"[ë°ì´í„°íŒŒì¼: {img_count}ê°œ]\")\n","            print_dir_tree(root=path, max_depth=max_depth-1, list_count=list_count, indent=indent + \"   \")\n","        else:\n","            if list_count < img_count and item.lower().endswith(('.jpg', '.jpeg', '.png', '.xml', '.inf', '.txt')):\n","                continue\n","            print(indent + \"|-- \"+ item)\n","\n","def save_model_dict(model, path, pth_name, kwargs=None):\n","    \"\"\"ëª¨ë¸ state_dictì™€ ì¶”ê°€ ì •ë³´ë¥¼ ì €ì¥\"\"\"\n","    def safe_makedirs(path):\n","        \"\"\"ì•ˆì „í•œ ë””ë ‰í† ë¦¬ ìƒì„±\"\"\"\n","        if os.path.exists(path) and not os.path.isdir(path):\n","            os.remove(path)  # íŒŒì¼ì´ë©´ ì‚­ì œ\n","        os.makedirs(path, exist_ok=True)\n","\n","    # ë””ë ‰í† ë¦¬ ìƒì„±\n","    safe_makedirs(path)\n","\n","    # ëª¨ë¸ êµ¬ì¡° ì •ë³´ ì¶”ì¶œ\n","    model_info = {\n","        'class_name': model.__class__.__name__,\n","        'init_args': {},\n","        'str': str(model),\n","        'repr': repr(model),\n","        'modules': [m.__class__.__name__ for m in model.modules()],\n","    }\n","\n","    # ìƒì„±ì ì¸ì ìë™ ì¶”ì¶œ(ê°€ëŠ¥í•œ ê²½ìš°)\n","    if hasattr(model, '__dict__'):\n","        for key in ['in_ch', 'base_ch', 'num_classes', 'out_ch']:\n","            if hasattr(model, key):\n","                model_info['init_args'][key] = getattr(model, key)\n","\n","    # kwargs ì²˜ë¦¬\n","    extra_info = {}\n","    if kwargs is not None:\n","        if isinstance(kwargs, str):\n","            extra_info = json.loads(kwargs)\n","        elif isinstance(kwargs, dict):\n","            extra_info = kwargs\n","\n","    model_info.update(extra_info)\n","\n","    # ì €ì¥í•  dict êµ¬ì„±\n","    save_dict = {\n","        'model_state': model.state_dict(),\n","        'class_name': model.__class__.__name__,\n","        'model_info': model_info,\n","    }\n","\n","    save_path = os.path.join(path, f\"{pth_name}.pth\")\n","    torch.save(save_dict, save_path)\n","    return save_path\n","\n","def load_model_dict(path, pth_name=None):\n","    \"\"\"\n","    save_model_dictë¡œ ì €ì¥í•œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜\n","    ë°˜í™˜ê°’: (model_state, model_info)\n","    \"\"\"\n","    import torch\n","    load_path = path\n","    if pth_name is not None:\n","        load_path = os.path.join(path, f\"{pth_name}.pth\")\n","    checkpoint = torch.load(load_path, map_location='cpu', weights_only=False)  # <-- ì—¬ê¸° ì¶”ê°€\n","    model_state = checkpoint.get('model_state')\n","    model_info = checkpoint.get('model_info')\n","    model_info['file_name'] = os.path.basename(load_path)\n","    return model_state, model_info\n","\n","\n","def search_pth_files(base_path):\n","    \"\"\"\n","    ì…ë ¥ëœ ê²½ë¡œì˜ í•˜ìœ„ í´ë”ë“¤ì—ì„œ pth íŒŒì¼ë“¤ì„ ê²€ìƒ‰\n","    \"\"\"\n","    pth_files = []\n","\n","    if not os.path.exists(base_path):\n","        print(f\"ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {base_path}\")\n","        return pth_files\n","\n","    print(f\"pth íŒŒì¼ ê²€ìƒ‰ ì‹œì‘: {base_path}\")\n","\n","    # í•˜ìœ„ í´ë”ë“¤ì„ ìˆœíšŒí•˜ë©° pth íŒŒì¼ ê²€ìƒ‰\n","    for root, dirs, files in os.walk(base_path):\n","        for file in files:\n","            if file.endswith('.pth'):\n","                pth_path = os.path.join(root, file)\n","                pth_files.append(pth_path)\n","\n","    # ê²°ê³¼ ì •ë¦¬ ë° ì¶œë ¥\n","    if pth_files:\n","        print(f\"\\në°œê²¬ëœ pth íŒŒì¼ë“¤ ({len(pth_files)}ê°œ):\")\n","        for i, pth_file in enumerate(pth_files, 1):\n","            # ìƒëŒ€ ê²½ë¡œë¡œ í‘œì‹œ (base_path ê¸°ì¤€)\n","            rel_path = os.path.relpath(pth_file, base_path)\n","            print(f\" {i:2d}. {rel_path}\")\n","    else:\n","        print(\"pth íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","\n","    return pth_files\n","\n","def print_json_tree(data, indent=\"\", max_depth=4, _depth=0, list_count=2, print_value=True):\n","    \"\"\"\n","    JSON ê°ì²´ë¥¼ ì§€ì •í•œ ë‹¨ê³„(max_depth)ê¹Œì§€ íŠ¸ë¦¬ í˜•íƒœë¡œ ì¶œë ¥\n","    - list íƒ€ì…ì€ 3ê°œ ì´ìƒì¼ ë•Œ ê°œìˆ˜ë§Œ ì¶œë ¥\n","    - í•˜ìœ„ ë…¸ë“œê°€ ê°’ì¼ ê²½ìš° key(type) í˜•íƒœë¡œ ì¶œë ¥\n","    - print_value=Trueì¼ ë•Œ key(type): ê°’ í˜•íƒœë¡œ ì¶œë ¥\n","    \"\"\"\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            if isinstance(value, (dict, list)):\n","                print(f\"{indent}|-- {key}\")\n","                print_json_tree(value, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","            else:\n","                if print_value:\n","                    print(f\"{indent}|-- {key}({type(value).__name__}): {value if len(str(value)) < 100 else f'{str(value)[:30]}...'}\")\n","                else:\n","                    print(f\"{indent}|-- {key}({type(value).__name__})\")\n","    elif isinstance(data, list):\n","        if len(data) > list_count:\n","            print(f\"{indent}|-- [list] ({len(data)} items)\")\n","        else:\n","            for i, item in enumerate(data):\n","                if isinstance(item, (dict, list)):\n","                    print(f\"{indent}|-- [{i}]\")\n","                    print_json_tree(item, indent + \"    \", max_depth, _depth + 1, list_count, print_value)\n","                else:\n","                    if print_value:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__}): {item if len(str(item)) < 100 else f'{str(item)[:30]}...'}\")\n","                    else:\n","                        print(f\"{indent}|-- [{i}]({type(item).__name__})\")\n","    else:\n","        if print_value:\n","            print(f\"{indent}{type(data).__name__}: {data if len(str(data)) < 100 else f'{str(data)[:30]}...'}\")\n","        else:\n","            print(f\"{indent}{type(data).__name__}\")\n","\n","def print_git_tree(data, indent=\"\", max_depth=3, _depth=0):\n","    \"\"\"\n","    PyTorch tensor/ë”•ì…”ë„ˆë¦¬/ë¦¬ìŠ¤íŠ¸ë¥¼ git tree ìŠ¤íƒ€ì¼ë¡œ ì¶œë ¥\n","    \"\"\"\n","    import torch\n","    import numpy as np\n","\n","    if _depth > max_depth:\n","        return\n","    if isinstance(data, dict):\n","        for key, value in data.items():\n","            print(f\"{indent}â”œâ”€ {key} [{type(value).__name__}]\")\n","            print_git_tree(value, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif isinstance(data, (list, tuple)):\n","        for i, item in enumerate(data):\n","            print(f\"{indent}â”œâ”€ [{i}] [{type(item).__name__}]\")\n","            print_git_tree(item, indent + \"â”‚  \", max_depth, _depth + 1)\n","    elif torch.is_tensor(data):\n","        shape = tuple(data.shape)\n","        dtype = str(data.dtype)\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ Tensor shape={shape} dtype={dtype} preview={preview_str}\")\n","    elif isinstance(data, np.ndarray):\n","        shape = data.shape\n","        dtype = data.dtype\n","        preview = str(data)\n","        preview_str = preview[:80] + (\"...\" if len(preview) > 80 else \"\")\n","        print(f\"{indent}â””â”€ ndarray shape={shape} dtype={dtype} preview={preview_str}\")\n","    else:\n","        val_str = str(data)\n","        print(f\"{indent}â””â”€ {type(data).__name__}: {val_str[:80]}{'...' if len(val_str)>80 else ''}\")\n","\n","\n","print(\"ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ ë¡œë“œ ì™„ë£Œ\")"]},{"cell_type":"markdown","metadata":{"id":"1B4qELHp5E9D"},"source":["# ë°ì´íƒ€ ë‹¤ìš´ë¡œë“œ"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1757943973523,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"0o9rB50tzK-A"},"outputs":[],"source":["# download_files={\n","#     'yolo_label_one_class' : r'https://drive.google.com/file/d/177_86k4BuT6JnFnq7ZHJtEjp7jaRbCl2/view?usp=sharing',\n","#     'yolo_label' : r'https://drive.google.com/file/d/1nc-WFcw7lCS7s7VGzN9Kxh80PiBBggez/view?usp=sharing',\n","#     'yolo_resize_one_class' : r'https://drive.google.com/file/d/1Ak0EvkMnuwvcAFvTO-zovIgVcNlROjsS/view?usp=sharing',\n","#     'yolo_resize' : r'https://drive.google.com/file/d/1kpo57qOJhEhrkuzUCEh57ILB5xSPVoFv/view?usp=sharing',\n","# }\n","\n","# download_files={\n","#     'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n","#     'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n","#     'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n","#     'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n","# }\n","\n","download_files={\n","    # 'yolo_label' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODU5OTkzNTMyOHxGfDA&svcType=MYBOX-WEB&time=1757776010785',\n","    # 'yolo_label_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODYzOTg5NDExMnxGfDA&svcType=MYBOX-WEB&time=1757776673721',\n","    # 'yolo_resize_one_class' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODgwNjk2NDMyMHxGfDA&svcType=MYBOX-WEB&time=1757780142635',\n","    # 'yolo_resize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc1ODY4MDc2MjQ2NHxGfDA&svcType=MYBOX-WEB&time=1757780177672',\n","    'yolo_noresize' : r'https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107',\n","}\n","# yolo_noresize = https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107\n","\n","\n"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18849,"status":"ok","timestamp":1757943992379,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"pdLVsfpwzK-A","outputId":"b6f4ee42-cbd2-4c59-c5f2-4ca2e539b93a"},"outputs":[{"output_type":"stream","name":"stdout","text":["local_code_it_ai04: /content/code_it_ai04\n","yolo_noresize: https://fs.mybox.naver.com/file/download.api?resourceKey=YzB6MGN8MzQ3MjU5Nzc2NDA0ODY2ODI1NnxGfDA&svcType=MYBOX-WEB&time=1757851996107\n"]},{"output_type":"stream","name":"stderr","text":["Downloading yolo_noresize.zip: 100%|##########| 611M/611M [00:15<00:00, 40.6MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: /content/code_it_ai04/yolo_noresize.zip\n"]},{"output_type":"stream","name":"stderr","text":["ì••ì¶• í•´ì œ ì¤‘: yolo_noresize.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3822/3822 [00:02<00:00, 1766.80file/s]"]},{"output_type":"stream","name":"stdout","text":["ì••ì¶• í•´ì œ ì™„ë£Œ: /content/code_it_ai04/yolo_noresize.zip.unzip\n","unzip_path_list: ['/content/code_it_ai04/yolo_noresize.zip.unzip']\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["import gdown\n","def download_gdrive_file(url, output_path, ignore=True):\n","    # ê³µìœ  ë§í¬ì—ì„œ íŒŒì¼ ID ì¶”ì¶œ\n","    if os.path.exists(output_path):\n","        if ignore:\n","            os.remove(output_path)\n","        else:\n","            return\n","\n","    file_id_match = re.search(r'/d/([a-zA-Z0-9_-]+)', url)\n","    if not file_id_match:\n","        raise ValueError(\"Google Drive íŒŒì¼ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n","    file_id = file_id_match.group(1)\n","    gdown.download(f\"https://drive.google.com/uc?id={file_id}\", output_path, quiet=False)\n","\n","def download_http(url, target, ignore=True):\n","    \"\"\"\n","    HTTP íŒŒì¼ ë‹¤ìš´ë¡œë“œ í•¨ìˆ˜ (ì§„í–‰ë¥  í‘œì‹œ)\n","    url: ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ URL\n","    target: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ\n","    ignore: Trueë©´ ê¸°ì¡´ íŒŒì¼ ì‚­ì œ í›„ ë‹¤ìš´ë¡œë“œ, Falseë©´ íŒŒì¼ ìˆìœ¼ë©´ ê±´ë„ˆëœ€\n","    \"\"\"\n","    if os.path.exists(target):\n","        if ignore:\n","            os.remove(target)\n","        else:\n","            print(f\"ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•©ë‹ˆë‹¤: {target}\")\n","            return target\n","\n","    response = requests.get(url, stream=True)\n","    total = int(response.headers.get('content-length', 0))\n","    with open(target, 'wb') as file, tqdm(\n","        desc=f\"Downloading {os.path.basename(target)}\",\n","        total=total,\n","        unit='B',\n","        unit_scale=True,\n","        unit_divisor=1024,\n","        ascii=True\n","    ) as bar:\n","        for data in response.iter_content(chunk_size=1024):\n","            size = file.write(data)\n","            bar.update(size)\n","    print(f\"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {target}\")\n","    return target\n","\n","# local_code_it_ai04 = os.path.join( '~/.cache/' if helper.is_colab else Path.cwd().drive + '\\\\'\n","#                                   ,'temp'\n","#                                   , 'code_it_ai04')\n","\n","if helper.is_colab:\n","    local_code_it_ai04 = os.path.join( '/content/', 'code_it_ai04')\n","else:\n","    local_code_it_ai04 = os.path.join( Path.cwd().drive + '\\\\', 'temp', 'code_it_ai04')\n","\n","print(\"local_code_it_ai04:\", local_code_it_ai04)\n","\n","os.makedirs(local_code_it_ai04, exist_ok=True)  # í´ë” ìƒì„± ì½”ë“œ ì¶”ê°€\n","unzip_paths = []\n","for key, url in download_files.items():\n","    print(f\"{key}: {url}\")\n","    zipfile = os.path.join(local_code_it_ai04, f'{key}.zip')\n","    unzip_path = os.path.join(local_code_it_ai04, f'{key}.zip.unzip')\n","    if os.path.exists(unzip_path):\n","        print(f\"ì´ë¯¸ ì••ì¶•í•´ì œëœ í´ë”ê°€ ì¡´ì¬í•©ë‹ˆë‹¤: {unzip_path}\")\n","        print('unzipfile:', unzip_path)\n","        unzip_paths.append(unzip_path)\n","        continue\n","    #download_gdrive_file(url, os.path.join(local_code_it_ai04, f'{key}.zip'), ignore=False)\n","    download_http(url, zipfile, ignore=False)\n","    unzip_path_list = heu.unzip([os.path.join(local_code_it_ai04, f'{key}.zip')])\n","    # for p in unzip_path_list:\n","    #     unzip_paths.append(p)\n","    print('unzip_path_list:', unzip_path_list)\n","    unzip_paths.extend(unzip_path_list)\n"]},{"cell_type":"markdown","metadata":{"id":"JfapF4EsMlGp"},"source":["### > ì„¤ì • < í”Œë ˆê·¸"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1757943992440,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"PjxsUVjUMlGq","outputId":"b76b0ef0-cbb0-4748-8936-427e6edcf0b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì••ì¶•í•´ì œëœ í´ë”: /content/code_it_ai04/yolo_noresize.zip.unzip\n","yaml_path: /content/code_it_ai04/yolo_noresize.zip.unzip/dataset.yaml\n","get_path_data: /content/code_it_ai04/yolo_noresize.zip.unzip\n"]}],"source":["# google drive rootì— keggle.json íŒŒì¼ í•„ìš”í•©ë‹ˆë‹¤.\n","for path in unzip_paths:\n","    print(\"ì••ì¶•í•´ì œëœ í´ë”:\", path)\n","\n","#yolo_dataset_path = os.path.join(local_code_it_ai04, f'yolo_label_one_class.zip.unzip')\n","yolo_dataset_path =unzip_paths[0]\n","yaml_path = os.path.join(yolo_dataset_path, \"dataset.yaml\")\n","\n","def get_path_data():\n","    path = yolo_dataset_path\n","    return path\n","\n","print(\"yaml_path:\", yaml_path)\n","print(\"get_path_data:\", get_path_data())"]},{"cell_type":"markdown","metadata":{"id":"ZRk0o5CUMlGq"},"source":["## EfficientNet ëª¨ë¸ë§"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1757943992461,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Jv-fWI-wzK-B","outputId":"5afe2aa3-8f65-4bea-fb22-d8855626a7b9"},"outputs":[{"output_type":"stream","name":"stdout","text":["ì••ì¶•í•´ì œëœ í´ë”: /content/code_it_ai04/yolo_noresize.zip.unzip\n"]}],"source":["for path in unzip_paths:\n","    print(f\"ì••ì¶•í•´ì œëœ í´ë”: {path}\")\n"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":41,"status":"ok","timestamp":1757943992506,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"5Z6vnx9ANq4u"},"outputs":[],"source":["class YOLOToClassificationDataset(Dataset):\n","    \"\"\"YOLO í˜•ì‹ ë°ì´í„°ë¥¼ ë¶„ë¥˜ìš©ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ë°ì´í„°ì…‹\"\"\"\n","\n","    def __init__(self, yaml_path, split='train', transform=None, crop_objects=True):\n","        # yaml íŒŒì¼ ì½ê¸°\n","        with open(yaml_path, 'r') as f:\n","            yaml_data = yaml.safe_load(f)\n","\n","        self.yaml_data_path = yaml_data['path']\n","        self.nc = yaml_data['nc']\n","        self.names = yaml_data['names']\n","        self.yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n","        self.yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n","        self.yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n","\n","        #print(\"nc:\", self.nc)\n","        #print(\"names:\", self.names)\n","        print(\"yaml_data_path:\", self.yaml_data_path)\n","        #print(\"yaml_data_train:\", self.yaml_data_train)\n","        #print(\"yaml_data_val:\", self.yaml_data_val)\n","        #print(\"yaml_data_test:\", self.yaml_data_test)\n","\n","        # splitì— ë”°ë¼ ê²½ë¡œ ì„ íƒ\n","        if split == 'train':\n","            image_dir = self.yaml_data_train\n","        elif split == 'val':\n","            image_dir = self.yaml_data_val\n","        elif split == 'test':\n","            image_dir = self.yaml_data_test\n","        else:\n","            raise ValueError(f\"split ê°’ì´ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤: {split}\")\n","\n","        label_dir = image_dir.replace('images', 'labels')\n","        self.image_dir = image_dir\n","        self.label_dir = label_dir\n","        self.class_names = self.names\n","        self.transform = transform\n","        self.crop_objects = crop_objects\n","        self.data = []\n","\n","        self._load_data()\n","\n","    def _load_data(self):\n","        if not os.path.exists(self.label_dir):\n","            #print(f\"ë¼ë²¨ í´ë”ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {self.label_dir}\")\n","            return  # ë¼ë²¨ í´ë” ì—†ìœ¼ë©´ ë¹ˆ ë°ì´í„°ì…‹\n","        for label_file in os.listdir(self.label_dir):\n","            if not label_file.endswith('.txt'):\n","                continue\n","            image_file = label_file.replace('.txt', '.jpg')\n","            image_path = os.path.join(self.image_dir, image_file)\n","            label_path = os.path.join(self.label_dir, label_file)\n","            if not os.path.exists(image_path):\n","                continue\n","            with open(label_path, 'r') as f:\n","                lines = f.readlines()\n","            for line in lines:\n","                parts = line.strip().split()\n","                if len(parts) >= 5:\n","                    class_id = int(parts[0])\n","                    x_center, y_center, width, height = map(float, parts[1:5])\n","                    self.data.append({\n","                        'image_path': image_path,\n","                        'class_id': class_id,\n","                        'bbox': (x_center, y_center, width, height)\n","                    })\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        item = self.data[idx]\n","        image = Image.open(item['image_path']).convert('RGB')\n","        if self.crop_objects and 'bbox' in item:\n","            img_w, img_h = image.size\n","            x_center, y_center, width, height = item['bbox']\n","            x1 = int((x_center - width/2) * img_w)\n","            y1 = int((y_center - height/2) * img_h)\n","            x2 = int((x_center + width/2) * img_w)\n","            y2 = int((y_center + height/2) * img_h)\n","            # ì¢Œí‘œê°€ ì˜¬ë°”ë¥¸ì§€ ì²´í¬\n","            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= img_w and y2 <= img_h:\n","                image = image.crop((x1, y1, x2, y2))\n","            # else: ì˜ëª»ëœ bboxëŠ” cropí•˜ì§€ ì•ŠìŒ\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, item['class_id']\n","    def get_item(self, idx):\n","        item = self.data[idx]\n","        image = Image.open(item['image_path']).convert('RGB')\n","        if self.crop_objects and 'bbox' in item:\n","            img_w, img_h = image.size\n","            x_center, y_center, width, height = item['bbox']\n","            x1 = int((x_center - width/2) * img_w)\n","            y1 = int((y_center - height/2) * img_h)\n","            x2 = int((x_center + width/2) * img_w)\n","            y2 = int((y_center + height/2) * img_h)\n","            # ì¢Œí‘œê°€ ì˜¬ë°”ë¥¸ì§€ ì²´í¬\n","            if x2 > x1 and y2 > y1 and x1 >= 0 and y1 >= 0 and x2 <= img_w and y2 <= img_h:\n","                image = image.crop((x1, y1, x2, y2))\n","            # else: ì˜ëª»ëœ bboxëŠ” cropí•˜ì§€ ì•ŠìŒ\n","        return image, item['class_id'], item['image_path'], [x1, y1, x2, y2]\n"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1757943992515,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"Lj7vfQNHNq4v"},"outputs":[],"source":["\n","# ë°ì´í„° ì „ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸\n","def get_transforms():\n","    train_transform = transforms.Compose([\n","        transforms.Resize((300, 300)),  # EfficientNet-B3 ì ì ˆí•œ í¬ê¸°\n","        transforms.RandomHorizontalFlip(0.5),\n","        transforms.RandomRotation(10),\n","        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                           std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    val_transform = transforms.Compose([\n","        transforms.Resize((300, 300)),\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                           std=[0.229, 0.224, 0.225])\n","    ])\n","\n","    return train_transform, val_transform\n","\n","# EfficientNet-B3 ëª¨ë¸ ìƒì„±\n","def create_efficientnet_model(num_classes, pretrained=True):\n","    \"\"\"ì‚¬ì „ í•™ìŠµëœ EfficientNet-B3 ëª¨ë¸ ë¡œë“œ\"\"\"\n","    model = timm.create_model('efficientnet_b3',\n","                             pretrained=pretrained,\n","                             num_classes=num_classes)\n","    return model\n","\n","# í•™ìŠµ í•¨ìˆ˜\n","def train_epoch(model, dataloader, criterion, optimizer, device):\n","    model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    pbar = tqdm(dataloader, desc='Training')\n","    for images, labels in pbar:\n","        images, labels = images.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item()\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","        pbar.set_postfix({\n","            'Loss': f'{running_loss/len(dataloader):.4f}',\n","            'Acc': f'{100*correct/total:.2f}%'\n","        })\n","\n","    return running_loss/len(dataloader), 100*correct/total\n","\n","# ê²€ì¦ í•¨ìˆ˜\n","def validate(model, dataloader, criterion, device):\n","    model.eval()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for images, labels in tqdm(dataloader, desc='Validating'):\n","            images, labels = images.to(device), labels.to(device)\n","            outputs = model(images)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item()\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    return running_loss/len(dataloader), 100*correct/total\n"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1757943992536,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"h0UX5QuCUPiM","outputId":"a781d781-3ae4-44eb-e159-82746893b305"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['names', 'nc', 'path', 'test', 'train', 'val'])\n","nc: 73\n","names: [1899, 2482, 3350, 3482, 3543, 3742, 3831, 4377, 4542, 5093, 5885, 6191, 6562, 10220, 12080, 12246, 12419, 12777, 13394, 13899, 16231, 16261, 16547, 16550, 16687, 18109, 18146, 18356, 19231, 19551, 19606, 19860, 20013, 20237, 20876, 21025, 21324, 21770, 22073, 22346, 22361, 22626, 23202, 23222, 24849, 25366, 25437, 25468, 27652, 27732, 27776, 27925, 27992, 28762, 29344, 29450, 29666, 29870, 30307, 31704, 31862, 31884, 32309, 33008, 33207, 33877, 33879, 34596, 35205, 36636, 38161, 41767, 44198]\n","yaml_data_path: /content/code_it_ai04/yolo_noresize.zip.unzip\n","yaml_data_train: /content/code_it_ai04/yolo_noresize.zip.unzip/images/train\n","yaml_data_val: /content/code_it_ai04/yolo_noresize.zip.unzip/images/val\n","yaml_data_test: /content/code_it_ai04/yolo_noresize.zip.unzip/images/test\n"]}],"source":["def update_yaml_paths_to_absolute(yaml_path):\n","    with open(yaml_path, 'r') as f:\n","        data = yaml.safe_load(f)\n","\n","    yaml_dir = os.path.dirname(yaml_path)\n","    data['path'] = os.path.normpath(os.path.join(yaml_dir, data['path']))\n","    # for key in ['train', 'val', 'test']:\n","    #     if key in data and not os.path.isabs(data[key]):\n","    #         data[key] = os.path.normpath(os.path.join(yaml_dir, data[key]))\n","\n","    with open(yaml_path, 'w') as f:\n","        yaml.dump(data, f, allow_unicode=True)\n","\n","    return data\n","\n","yaml_data = update_yaml_paths_to_absolute(yaml_path)\n","print(yaml_data.keys())\n","yaml_data_path = yaml_data['path']\n","nc = yaml_data['nc']\n","names = yaml_data['names']\n","yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n","yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n","yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n","\n","print(\"nc:\", nc)\n","print(\"names:\", names)\n","print(\"yaml_data_path:\", yaml_data_path)\n","print(\"yaml_data_train:\", yaml_data_train)\n","print(\"yaml_data_val:\", yaml_data_val)\n","print(\"yaml_data_test:\", yaml_data_test)\n"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1757943992547,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"gth-UMvZUPiN"},"outputs":[],"source":["# raise ValueError(\"ì¤‘ë‹¨\")"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1757943992553,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"UDJCLAC2z4q9"},"outputs":[],"source":["# sample image\n","def save_sample(dataset, save_dir, type, num_samples=5):\n","    os.makedirs(save_dir, exist_ok=True)\n","    pbar = tqdm(range(min(num_samples, len(dataset))), desc=\"ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ ì¤‘\")\n","    for i in pbar:\n","        image, label, class_image_path, bbox = dataset.get_item(i)\n","        base_file_name = os.path.basename(class_image_path).split('.')[0]\n","        class_name = dataset.class_names[label]\n","        image_path = os.path.join(save_dir, 'images', type, f'{base_file_name}_{class_name}.jpg')\n","        os.makedirs(os.path.dirname(image_path), exist_ok=True)  # í´ë” ìƒì„± ì¶”ê°€\n","        # í…ì„œë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜\n","        if isinstance(image, torch.Tensor):\n","            image = TF.to_pil_image(image)\n","        image.save(image_path)\n","        label_path = os.path.join(save_dir, 'labels', type, f'{base_file_name}_{class_name}.txt')\n","        os.makedirs(os.path.dirname(label_path), exist_ok=True)  # í´ë” ìƒì„± ì¶”ê°€\n","        with open(label_path, 'w') as f:\n","            f.write(f\"{label}\\n\")\n","        pbar.set_postfix_str(f'{base_file_name}_{class_name}')\n","\n","def save_classification_yaml(save_dir, class_names):\n","    yaml_dict = {\n","        'path': '.',\n","        'train': 'images/train',\n","        'val': 'images/val',\n","        'test': 'images/test',\n","        'nc': len(class_names),\n","        'names': class_names\n","    }\n","    yaml_path = os.path.join(save_dir, 'dataset.yaml')\n","    with open(yaml_path, 'w', encoding='utf-8') as f:\n","        yaml.dump(yaml_dict, f, allow_unicode=True)\n","    print(f'dataset.yaml ì €ì¥: {yaml_path}')\n","\n","def save_yaml_sample_images():\n","    yaml_data = update_yaml_paths_to_absolute(yaml_path)\n","    print(yaml_data.keys())\n","    yaml_data_path = yaml_data['path']\n","    nc = yaml_data['nc']\n","    names = yaml_data['names']\n","    yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n","    yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n","    yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n","\n","\n","    CLASS_NAMES = names\n","    NUM_CLASSES = len(CLASS_NAMES)\n","    BATCH_SIZE = 16\n","    LEARNING_RATE = 0.001\n","    NUM_EPOCHS = 10\n","    # ========================================\n","\n","    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n","    train_transform, val_transform = get_transforms()\n","\n","    # ì „ì²´ ë°ì´í„°ì…‹ (ì‹¤ì œë¡œëŠ” train/val ë¶„í•  í•„ìš”)\n","    train_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='train',\n","        transform=train_transform\n","    )\n","    val_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='val',\n","        transform=val_transform\n","    )\n","    test_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='test',\n","        transform=val_transform\n","    )\n","    yaml_data_sample_images_train_path = os.path.join(f\"{yaml_data_path}_one\")\n","    yaml_data_sample_images_val_path = os.path.join(f\"{yaml_data_path}_one\")\n","    save_sample(train_dataset, yaml_data_sample_images_train_path, 'train', num_samples=len(train_dataset))\n","    save_sample(val_dataset, yaml_data_sample_images_val_path, 'val', num_samples=len(val_dataset))\n","    save_classification_yaml(yaml_data_sample_images_train_path, CLASS_NAMES)\n","    print(\"ìƒ˜í”Œ ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ\")\n","\n","# ì•Œì•½ ë³„ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¦¬í•œ í›„ ì €ì¥\n","# save_yaml_sample_images()"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1757943992569,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"U6j6R7sLz4q9"},"outputs":[],"source":["# raise ValueError(\"ì¤‘ë‹¨\")"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1757943992578,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"HC2UYJQvNq4v"},"outputs":[],"source":["\n","# ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜\n","def main_efficientnet():\n","    # ========== ì„¤ì • ë¶€ë¶„ (ìˆ˜ì • í•„ìš”) ==========\n","    yaml_data = update_yaml_paths_to_absolute(yaml_path)\n","    print(yaml_data.keys())\n","    yaml_data_path = yaml_data['path']\n","    nc = yaml_data['nc']\n","    names = yaml_data['names']\n","    yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n","    yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n","    yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n","\n","    CLASS_NAMES = names\n","    NUM_CLASSES = len(CLASS_NAMES)\n","    BATCH_SIZE = 16\n","    LEARNING_RATE = 0.001\n","    NUM_EPOCHS = 3\n","\n","    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (YOLOì™€ ë™ì¼í•œ êµ¬ì¡°)\n","    model_save_name = f\"efficientnet_b3_cls_{NUM_CLASSES}classes\"\n","    model_save_dir = get_path_modeling()\n","    model_project_dir = os.path.join(model_save_dir, model_save_name)\n","    os.makedirs(model_project_dir, exist_ok=True)\n","\n","    print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_project_dir}\")\n","    print(f\"CLASS_NAMES: {CLASS_NAMES}\")\n","    # ========================================\n","\n","    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n","    train_transform, val_transform = get_transforms()\n","\n","    train_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='train',\n","        transform=train_transform\n","    )\n","    val_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='val',\n","        transform=val_transform\n","    )\n","    test_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='test',\n","        transform=val_transform\n","    )\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    print(f\"Training samples: {len(train_dataset)}\")\n","    print(f\"Validation samples: {len(val_dataset)}\")\n","    print(f\"Test samples: {len(test_dataset)}\")\n","\n","    # ëª¨ë¸ ìƒì„±\n","    model = create_efficientnet_model(NUM_CLASSES, pretrained=True)\n","    model = model.to(__device)\n","\n","    # ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    # í•™ìŠµ ë£¨í”„\n","    best_val_acc = 0.0\n","    train_losses, train_accs = [], []\n","    val_losses, val_accs = [], []\n","\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n","        print(\"-\" * 50)\n","\n","        # í•™ìŠµ\n","        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, __device)\n","        train_losses.append(train_loss)\n","        train_accs.append(train_acc)\n","\n","        # ê²€ì¦\n","        val_loss, val_acc = validate(model, val_loader, criterion, __device)\n","        val_losses.append(val_loss)\n","        val_accs.append(val_acc)\n","\n","        scheduler.step()\n","\n","        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n","        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","\n","        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ (YOLO ìŠ¤íƒ€ì¼ë¡œ ìˆ˜ì •)\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","\n","            # ëª¨ë¸ ì •ë³´ êµ¬ì„±\n","            model_info = {\n","                'model_name': 'efficientnet_b3',\n","                'num_classes': NUM_CLASSES,\n","                'class_names': CLASS_NAMES,\n","                'best_val_acc': val_acc,\n","                'epoch': epoch + 1,\n","                'learning_rate': LEARNING_RATE,\n","                'batch_size': BATCH_SIZE,\n","                'train_samples': len(train_dataset),\n","                'val_samples': len(val_dataset),\n","                'test_samples': len(test_dataset),\n","            }\n","\n","            # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥\n","            best_model_path = save_model_dict(\n","                model=model,\n","                path=model_project_dir,\n","                pth_name='best',\n","                kwargs=model_info\n","            )\n","\n","            print(f\"Best model saved! Val Acc: {val_acc:.2f}%\")\n","            print(f\"ì €ì¥ ê²½ë¡œ: {best_model_path}\")\n","\n","    # ìµœì¢… ëª¨ë¸ë„ ì €ì¥\n","    final_model_info = model_info.copy()\n","    final_model_info.update({\n","        'final_val_acc': val_acc,\n","        'final_epoch': NUM_EPOCHS,\n","        'training_completed': True\n","    })\n","\n","    final_model_path = save_model_dict(\n","        model=model,\n","        path=model_project_dir,\n","        pth_name='final',\n","        kwargs=final_model_info\n","    )\n","\n","    print(f\"Final model saved: {final_model_path}\")\n","\n","    # ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥\n","    plt.figure(figsize=(12, 4))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_losses, label='Val Loss')\n","    plt.title('Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(train_accs, label='Train Acc')\n","    plt.plot(val_accs, label='Val Acc')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","\n","    # ì°¨íŠ¸ë„ ê°™ì€ í´ë”ì— ì €ì¥\n","    chart_path = os.path.join(model_project_dir, 'training_results.png')\n","    plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n","    print(f\"Training chart saved: {chart_path}\")\n","\n","    plt.show()\n","\n","    return model_project_dir, best_val_acc"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1757943992618,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"_LmtT_cp14nQ"},"outputs":[],"source":["import wandb\n","\n","def main_efficientnet_with_wandb(project_name=\"codeit-ai-04-01\", run_name=None):\n","    # ========== ì„¤ì • ë¶€ë¶„ (ìˆ˜ì • í•„ìš”) ==========\n","    yaml_data = update_yaml_paths_to_absolute(yaml_path)\n","    print(yaml_data.keys())\n","    yaml_data_path = yaml_data['path']\n","    nc = yaml_data['nc']\n","    names = yaml_data['names']\n","    yaml_data_train = os.path.join(yaml_data['path'], yaml_data['train'])\n","    yaml_data_val = os.path.join(yaml_data['path'], yaml_data['val'])\n","    yaml_data_test = os.path.join(yaml_data['path'], yaml_data['test'])\n","\n","    CLASS_NAMES = names\n","    NUM_CLASSES = len(CLASS_NAMES)\n","    BATCH_SIZE = 16\n","    LEARNING_RATE = 0.001\n","    NUM_EPOCHS = 30\n","\n","    # ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì • (YOLOì™€ ë™ì¼í•œ êµ¬ì¡°)\n","    #model_save_name = f\"efficientnet_b3_cls_{NUM_CLASSES}classes\"\n","    model_save_dir = get_path_modeling()\n","    model_project_dir = os.path.join(model_save_dir, run_name)\n","    os.makedirs(model_project_dir, exist_ok=True)\n","\n","    print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {model_project_dir}\")\n","\n","    # wandb ì´ˆê¸°í™”\n","    wandb_config = {\n","        'model_name': 'efficientnet_b3',\n","        'num_classes': NUM_CLASSES,\n","        'class_names': CLASS_NAMES,\n","        'batch_size': BATCH_SIZE,\n","        'learning_rate': LEARNING_RATE,\n","        'num_epochs': NUM_EPOCHS,\n","        'image_size': 300,\n","        'optimizer': 'Adam',\n","        'scheduler': 'StepLR',\n","        'pretrained': True\n","    }\n","\n","    run = wandb.init(\n","        project=project_name,\n","        name=run_name or f\"efficientnet_b3_{NUM_CLASSES}classes_{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n","        config=wandb_config,\n","        tags=['efficientnet', 'classification', 'pytorch']\n","    )\n","    # ========================================\n","\n","    # ë°ì´í„°ì…‹ ë° ë°ì´í„°ë¡œë” ìƒì„±\n","    train_transform, val_transform = get_transforms()\n","\n","    train_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='train',\n","        transform=train_transform\n","    )\n","    val_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='val',\n","        transform=val_transform\n","    )\n","    test_dataset = YOLOToClassificationDataset(\n","        yaml_path = yaml_path,\n","        split='test',\n","        transform=val_transform\n","    )\n","\n","    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","    print(f\"Training samples: {len(train_dataset)}\")\n","    print(f\"Validation samples: {len(val_dataset)}\")\n","    print(f\"Test samples: {len(test_dataset)}\")\n","\n","    # wandbì— ë°ì´í„°ì…‹ ì •ë³´ ë¡œê¹…\n","    wandb.log({\n","        'dataset/train_samples': len(train_dataset),\n","        'dataset/val_samples': len(val_dataset),\n","        'dataset/test_samples': len(test_dataset),\n","        'dataset/total_samples': len(train_dataset) + len(val_dataset) + len(test_dataset)\n","    })\n","\n","    # ëª¨ë¸ ìƒì„±\n","    model = create_efficientnet_model(NUM_CLASSES, pretrained=True)\n","    model = model.to(__device)\n","\n","    # wandbì— ëª¨ë¸ êµ¬ì¡° ë¡œê¹…\n","    wandb.watch(model, log='all', log_freq=100)\n","\n","    # ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n","    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n","\n","    # í•™ìŠµ ë£¨í”„\n","    best_val_acc = 0.0\n","    train_losses, train_accs = [], []\n","    val_losses, val_accs = [], []\n","\n","    for epoch in range(NUM_EPOCHS):\n","        print(f\"\\nEpoch {epoch+1}/{NUM_EPOCHS}\")\n","        print(\"-\" * 50)\n","\n","        # í•™ìŠµ\n","        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, __device)\n","        train_losses.append(train_loss)\n","        train_accs.append(train_acc)\n","\n","        # ê²€ì¦\n","        val_loss, val_acc = validate(model, val_loader, criterion, __device)\n","        val_losses.append(val_loss)\n","        val_accs.append(val_acc)\n","\n","        model_project_dir_result = os.path.join(model_project_dir, 'results')\n","        os.makedirs(model_project_dir_result, exist_ok=True)\n","\n","        scheduler.step()\n","\n","        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n","        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n","\n","        # wandbì— ë©”íŠ¸ë¦­ ë¡œê¹…\n","        wandb.log({\n","            'epoch': epoch + 1,\n","            'train/loss': train_loss,\n","            'train/accuracy': train_acc,\n","            'val/loss': val_loss,\n","            'val/accuracy': val_acc,\n","            'learning_rate': optimizer.param_groups[0]['lr']\n","        }, step=epoch)\n","\n","        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","\n","            # ëª¨ë¸ ì •ë³´ êµ¬ì„±\n","            model_info = {\n","                'model_name': 'efficientnet_b3',\n","                'num_classes': NUM_CLASSES,\n","                'class_names': CLASS_NAMES,\n","                'best_val_acc': val_acc,\n","                'epoch': epoch + 1,\n","                'learning_rate': LEARNING_RATE,\n","                'batch_size': BATCH_SIZE,\n","                'train_samples': len(train_dataset),\n","                'val_samples': len(val_dataset),\n","                'test_samples': len(test_dataset),\n","            }\n","\n","            # ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥\n","            best_model_path = save_model_dict(\n","                model=model,\n","                path=model_project_dir,\n","                pth_name='best',\n","                kwargs=model_info\n","            )\n","\n","            print(f\"Best model saved! Val Acc: {val_acc:.2f}%\")\n","            print(f\"ì €ì¥ ê²½ë¡œ: {best_model_path}\")\n","\n","            # wandbì— ë² ìŠ¤íŠ¸ ëª¨ë¸ ì €ì¥\n","            wandb.log({'best_val_accuracy': val_acc, 'best_epoch': epoch + 1})\n","\n","    # ìµœì¢… ëª¨ë¸ë„ ì €ì¥\n","    final_model_info = model_info.copy()\n","    final_model_info.update({\n","        'final_val_acc': val_acc,\n","        'final_epoch': NUM_EPOCHS,\n","        'training_completed': True\n","    })\n","\n","    final_model_path = save_model_dict(\n","        model=model,\n","        path=model_project_dir,\n","        pth_name='final',\n","        kwargs=final_model_info\n","    )\n","\n","    print(f\"Final model saved: {final_model_path}\")\n","\n","    # ê²°ê³¼ ì‹œê°í™” ë° ì €ì¥\n","    plt.figure(figsize=(12, 4))\n","\n","    plt.subplot(1, 2, 1)\n","    plt.plot(train_losses, label='Train Loss')\n","    plt.plot(val_losses, label='Val Loss')\n","    plt.title('Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    plt.subplot(1, 2, 2)\n","    plt.plot(train_accs, label='Train Acc')\n","    plt.plot(val_accs, label='Val Acc')\n","    plt.title('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Accuracy (%)')\n","    plt.legend()\n","\n","    plt.tight_layout()\n","\n","    # ì°¨íŠ¸ë„ ê°™ì€ í´ë”ì— ì €ì¥\n","    chart_path = os.path.join(model_project_dir, 'training_results.png')\n","    plt.savefig(chart_path, dpi=150, bbox_inches='tight')\n","    print(f\"Training chart saved: {chart_path}\")\n","\n","    # wandbì— ì°¨íŠ¸ ì—…ë¡œë“œ\n","    wandb.log({\"training_results\": wandb.Image(chart_path)})\n","\n","    plt.show()\n","\n","    # ìµœì¢… ìš”ì•½ ë©”íŠ¸ë¦­\n","    wandb.log({\n","        'final/best_val_accuracy': best_val_acc,\n","        'final/final_val_accuracy': val_acc,\n","        'final/total_epochs': NUM_EPOCHS\n","    })\n","\n","    # ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥\n","    artifact = wandb.Artifact(\n","        name=f\"efficientnet_b3_model_{run.id}\",\n","        type=\"model\",\n","        description=f\"EfficientNet-B3 model trained on {NUM_CLASSES} classes\"\n","    )\n","    artifact.add_file(best_model_path)\n","    artifact.add_file(final_model_path)\n","    artifact.add_file(chart_path)\n","    wandb.log_artifact(artifact)\n","\n","    # wandb ì‹¤í–‰ ì¢…ë£Œ\n","    wandb.finish()\n","\n","    return model_project_dir, best_val_acc\n","\n","# ì‹¤í–‰ í•¨ìˆ˜\n","def run_efficientnet_with_wandb():\n","    try:\n","        project_dir, best_acc = main_efficientnet_with_wandb(\n","            project_name=\"codeit-ai-04-01\",\n","            run_name=f\"efficientnet_b3_experiment_{datetime.now(__kst).strftime('%Y%m%d_%H%M%S')}\"\n","        )\n","        print(f\"í•™ìŠµ ì™„ë£Œ! ìµœê³  ê²€ì¦ ì •í™•ë„: {best_acc:.2f}%\")\n","        print(f\"ëª¨ë¸ ì €ì¥ ê²½ë¡œ: {project_dir}\")\n","        return project_dir, best_acc\n","    except Exception as e:\n","        print(f\"í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n","        wandb.finish()\n","        raise"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1757943992633,"user":{"displayName":"dev c0z0c","userId":"08071297324787696567"},"user_tz":-540},"id":"AFUs6ByDN0ll"},"outputs":[],"source":["# raise ValueError('stop end')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["7e7718b30c4d4736a4361c377527d8a8","7e147081cf3c4cb8870e2fda28c54f75","c94961db730248a8b2f41960d94db216","1cac6596dbfb40c19abd2dc41bf1e5af","7e30cbeab8794bccb888830f8e317082","f426d075355241d897db541d99d39263","56cf2b55b4f447789f3414e01f991b43","b97110770f11433b9793efd4f746693d","af8ec45de08244a78acc2f2000698201","1feb9d1a988a4ab29b470438fa2dfcfb","64d18c6df0074d0197bf1cf31242e976"]},"id":"nUHwajzLNq4v","outputId":"79180c76-c5fb-406f-ca66-2b73f49dbf55"},"outputs":[{"output_type":"stream","name":"stdout","text":["dict_keys(['names', 'nc', 'path', 'test', 'train', 'val'])\n","ëª¨ë¸ ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/modeling_yolo/efficientnet_b3_experiment_20250915_224641\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mc0z0c-dev\u001b[0m (\u001b[33mc0z0c-dev-home\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["creating run (0.3s)"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.21.3"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/wandb/run-20250915_134643-x2z0riyt</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href='https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01/runs/x2z0riyt' target=\"_blank\">efficientnet_b3_experiment_20250915_224641</a></strong> to <a href='https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View project at <a href='https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01' target=\"_blank\">https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01</a>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[" View run at <a href='https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01/runs/x2z0riyt' target=\"_blank\">https://wandb.ai/c0z0c-dev-home/codeit-ai-04-01/runs/x2z0riyt</a>"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["yaml_data_path: /content/code_it_ai04/yolo_noresize.zip.unzip\n","yaml_data_path: /content/code_it_ai04/yolo_noresize.zip.unzip\n","yaml_data_path: /content/code_it_ai04/yolo_noresize.zip.unzip\n","Training samples: 3134\n","Validation samples: 1392\n","Test samples: 0\n"]},{"output_type":"display_data","data":{"text/plain":["model.safetensors:   0%|          | 0.00/49.3M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e7718b30c4d4736a4361c377527d8a8"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["\n","Epoch 1/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [01:16<00:00,  2.55it/s, Loss=0.5820, Acc=86.73%]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:19<00:00,  4.53it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.5820, Train Acc: 86.73%\n","Val Loss: 0.1989, Val Acc: 95.62%\n","Best model saved! Val Acc: 95.62%\n","ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/modeling_yolo/efficientnet_b3_experiment_20250915_224641/best.pth\n","\n","Epoch 2/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training:   3%|â–         | 5/196 [00:02<01:25,  2.22it/s, Loss=0.0056, Acc=95.00%]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 0 that is less than the current step 1. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [01:15<00:00,  2.60it/s, Loss=0.1678, Acc=95.88%]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:18<00:00,  4.63it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1678, Train Acc: 95.88%\n","Val Loss: 0.1552, Val Acc: 98.20%\n","Best model saved! Val Acc: 98.20%\n","ì €ì¥ ê²½ë¡œ: /content/drive/MyDrive/modeling_yolo/efficientnet_b3_experiment_20250915_224641/best.pth\n","\n","Epoch 3/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training:  10%|â–ˆ         | 20/196 [00:07<01:06,  2.63it/s, Loss=0.0090, Acc=97.81%]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 1 that is less than the current step 2. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [01:15<00:00,  2.58it/s, Loss=0.1114, Acc=97.51%]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:19<00:00,  4.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.1114, Train Acc: 97.51%\n","Val Loss: 0.9760, Val Acc: 90.73%\n","\n","Epoch 4/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training:   4%|â–         | 7/196 [00:02<01:12,  2.62it/s, Loss=0.0124, Acc=93.75%]\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 2 that is less than the current step 3. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n","Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [01:16<00:00,  2.58it/s, Loss=0.0799, Acc=98.25%]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:18<00:00,  4.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0799, Train Acc: 98.25%\n","Val Loss: 0.1854, Val Acc: 97.56%\n","\n","Epoch 5/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 196/196 [01:15<00:00,  2.60it/s, Loss=0.0939, Acc=97.80%]\n","Validating: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 87/87 [00:18<00:00,  4.59it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Train Loss: 0.0939, Train Acc: 97.80%\n","Val Loss: 0.3598, Val Acc: 94.32%\n","\n","Epoch 6/30\n","--------------------------------------------------\n"]},{"output_type":"stream","name":"stderr","text":["Training:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 70/196 [00:26<00:47,  2.65it/s, Loss=0.0283, Acc=98.12%]"]}],"source":["#main_efficientnet()\n","run_efficientnet_with_wandb()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"04KFMQG7z4q-"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oJLu81VDz4q-"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"env_colab_250827","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.18"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7e7718b30c4d4736a4361c377527d8a8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7e147081cf3c4cb8870e2fda28c54f75","IPY_MODEL_c94961db730248a8b2f41960d94db216","IPY_MODEL_1cac6596dbfb40c19abd2dc41bf1e5af"],"layout":"IPY_MODEL_7e30cbeab8794bccb888830f8e317082"}},"7e147081cf3c4cb8870e2fda28c54f75":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f426d075355241d897db541d99d39263","placeholder":"â€‹","style":"IPY_MODEL_56cf2b55b4f447789f3414e01f991b43","value":"model.safetensors:â€‡100%"}},"c94961db730248a8b2f41960d94db216":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b97110770f11433b9793efd4f746693d","max":49335454,"min":0,"orientation":"horizontal","style":"IPY_MODEL_af8ec45de08244a78acc2f2000698201","value":49335454}},"1cac6596dbfb40c19abd2dc41bf1e5af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1feb9d1a988a4ab29b470438fa2dfcfb","placeholder":"â€‹","style":"IPY_MODEL_64d18c6df0074d0197bf1cf31242e976","value":"â€‡49.3M/49.3Mâ€‡[00:00&lt;00:00,â€‡194MB/s]"}},"7e30cbeab8794bccb888830f8e317082":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f426d075355241d897db541d99d39263":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"56cf2b55b4f447789f3414e01f991b43":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b97110770f11433b9793efd4f746693d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"af8ec45de08244a78acc2f2000698201":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1feb9d1a988a4ab29b470438fa2dfcfb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"64d18c6df0074d0197bf1cf31242e976":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}